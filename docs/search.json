[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "orbit-generation",
    "section": "",
    "text": "The orbit dataset is organized within a three-dimensional numpy array with the following structure:\n\ndata.shape = (num_orbits, 6, num_time_points)\n\n\n\n\nnum_orbits: Total number of distinct orbits in the dataset.\n6: Represents the six scalar values for each orbit at each time point, typically including:\n\nposX, posY, posZ: Position components in the X, Y, and Z dimensions, respectively.\nvelX, velY, velZ: Velocity components in the X, Y, and Z dimensions, respectively.\n\nnum_time_points: Number of time instants at which the data for each orbit is recorded.\n\n\n\n\nFor an individual orbit \\(i\\), the data is represented as a matrix \\(O_i\\) of dimensions \\(6 \\times T\\), where \\(T\\) represents the total number of time points (\\(num\\_time\\_points\\)):\nThe orbit matrix \\(O_i\\) for each orbit \\(i\\) can be represented as:\n\\[\nO_i = \\left(\\begin{array}{cccc}\nposX_{1} & posX_{2} & \\ldots & posX_{T} \\\\\nposY_{1} & posY_{2} & \\ldots & posY_{T} \\\\\nposZ_{1} & posZ_{2} & \\ldots & posZ_{T} \\\\\nvelX_{1} & velX_{2} & \\ldots & velX_{T} \\\\\nvelY_{1} & velY_{2} & \\ldots & velY_{T} \\\\\nvelZ_{1} & velZ_{2} & \\ldots & velZ_{T} \\\\\n\\end{array}\\right)\n\\]\nAnd the state vector \\(vec{v}_{i,t}\\) for orbit \\(i\\) at time point \\(t\\) is:\n\\[\n\\vec{v}_{i,t} = \\left(\\begin{array}{c}\nposX_t \\\\\nposY_t \\\\\nposZ_t \\\\\nvelX_t \\\\\nvelY_t \\\\\nvelZ_t \\\\\n\\end{array}\\right)\n\\]\nThus, the dataset can be envisioned as an assembly of matrices, each encapsulating the trajectory and dynamical state of an orbit over time.\n\n\n\n\nTo retrieve the complete data for a specific orbit \\(i\\), use data[i, :, :].\nFor all data points of a specific scalar measurement \\(j\\) across all orbits and time points, use data[:, j, :].\nTo access data for a specific scalar measurement \\(j\\) at a given time point \\(t\\) across all orbits, the syntax is data[:, j, t].\n\nThis structured approach facilitates efficient data storage and retrieval, allowing for comprehensive and detailed analyses of the orbits.",
    "crumbs": [
      "orbit-generation"
    ]
  },
  {
    "objectID": "index.html#orbit-dataset-structure",
    "href": "index.html#orbit-dataset-structure",
    "title": "orbit-generation",
    "section": "",
    "text": "The orbit dataset is organized within a three-dimensional numpy array with the following structure:\n\ndata.shape = (num_orbits, 6, num_time_points)\n\n\n\n\nnum_orbits: Total number of distinct orbits in the dataset.\n6: Represents the six scalar values for each orbit at each time point, typically including:\n\nposX, posY, posZ: Position components in the X, Y, and Z dimensions, respectively.\nvelX, velY, velZ: Velocity components in the X, Y, and Z dimensions, respectively.\n\nnum_time_points: Number of time instants at which the data for each orbit is recorded.\n\n\n\n\nFor an individual orbit \\(i\\), the data is represented as a matrix \\(O_i\\) of dimensions \\(6 \\times T\\), where \\(T\\) represents the total number of time points (\\(num\\_time\\_points\\)):\nThe orbit matrix \\(O_i\\) for each orbit \\(i\\) can be represented as:\n\\[\nO_i = \\left(\\begin{array}{cccc}\nposX_{1} & posX_{2} & \\ldots & posX_{T} \\\\\nposY_{1} & posY_{2} & \\ldots & posY_{T} \\\\\nposZ_{1} & posZ_{2} & \\ldots & posZ_{T} \\\\\nvelX_{1} & velX_{2} & \\ldots & velX_{T} \\\\\nvelY_{1} & velY_{2} & \\ldots & velY_{T} \\\\\nvelZ_{1} & velZ_{2} & \\ldots & velZ_{T} \\\\\n\\end{array}\\right)\n\\]\nAnd the state vector \\(vec{v}_{i,t}\\) for orbit \\(i\\) at time point \\(t\\) is:\n\\[\n\\vec{v}_{i,t} = \\left(\\begin{array}{c}\nposX_t \\\\\nposY_t \\\\\nposZ_t \\\\\nvelX_t \\\\\nvelY_t \\\\\nvelZ_t \\\\\n\\end{array}\\right)\n\\]\nThus, the dataset can be envisioned as an assembly of matrices, each encapsulating the trajectory and dynamical state of an orbit over time.\n\n\n\n\nTo retrieve the complete data for a specific orbit \\(i\\), use data[i, :, :].\nFor all data points of a specific scalar measurement \\(j\\) across all orbits and time points, use data[:, j, :].\nTo access data for a specific scalar measurement \\(j\\) at a given time point \\(t\\) across all orbits, the syntax is data[:, j, t].\n\nThis structured approach facilitates efficient data storage and retrieval, allowing for comprehensive and detailed analyses of the orbits.",
    "crumbs": [
      "orbit-generation"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "orbit-generation",
    "section": "Install",
    "text": "Install\npip install orbit_generation_testing",
    "crumbs": [
      "orbit-generation"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "orbit-generation",
    "section": "How to use",
    "text": "How to use\n\nfrom orbit_generation.data import get_example_orbit_data\nfrom orbit_generation.processing import resample_3d_array\nfrom orbit_generation.stats import plot_histograms_position\nfrom orbit_generation.visualize import visualize_static_orbits, export_dynamic_orbits_html\nfrom orbit_generation.constants import EM_POINTS\n\n/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n2024-06-07 10:40:48.295769: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n\n\n\nData\n\norbit_data = get_example_orbit_data()\norbit_data.shape\n\n(200, 6, 300)\n\n\n\nNumber of orbits: 200\nTime instants: 300\n\n\n\nProcessing\n\nresampled_orbit_data = resample_3d_array(data=orbit_data, axis=2, target_size= 100)\nresampled_orbit_data.shape\n\n(200, 6, 100)\n\n\n\nInitial time instants: 300\nTime instants after Resampling: 100\n\n\n\nStatistics\n\nplot_histograms_position(orbit_data)\n\n\n\n\n\n\n\n\n\n\nVisualization\n\nvisualize_static_orbits(resampled_orbit_data, orbit_indices=[15,20,70,140,190], point_dict=EM_POINTS)\n\n\n\n\n\n\n\n\n\nvisualize_static_orbits(data= orbit_data,time_instants=[0,50], orbit_indices=[0,20,40])\n\n\n\n\n\n\n\n\n\nvisualize_static_orbits(orbit_data, show_legend=False)\n\n\n\n\n\n\n\n\n\nexport_dynamic_orbits_html(data=orbit_data, filename='../data/example_data/example_orbits.html')\n\nVisualization saved to ../data/example_data/example_orbits.html",
    "crumbs": [
      "orbit-generation"
    ]
  },
  {
    "objectID": "processing.html",
    "href": "processing.html",
    "title": "Processing",
    "section": "",
    "text": "def downsample_3d_array(data: np.ndarray,     # The original 3D array to be downsampled.\n                        axis: int,            # The axis along which to perform the downsampling.\n                        hop: int = None,      # The interval at which to keep elements.\n                        target_size: int = None  # The target size for the specified axis.\n                       ) -&gt; np.ndarray:\n    \"\"\"\n    Downsample a 3D numpy array along a specified axis by keeping only every hop-th element or \n    to a target size.\n    \"\"\"\n    if axis not in [0, 1, 2]:  # Validate the axis to ensure it's within the correct range.\n        raise ValueError(\"Invalid axis. Axis must be 0, 1, or 2.\")\n\n    if hop is not None and hop &lt; 1:\n        raise ValueError(\"Hop must be a positive integer greater than or equal to 1.\")\n\n    if target_size is not None and (target_size &lt; 1 or target_size &gt; data.shape[axis]):\n        raise ValueError(\"Target size must be a positive integer and less than or equal to the size of the axis.\")\n    \n    if hop is not None:\n        # Create slices for each axis\n        slices = [slice(None)] * 3\n        slices[axis] = slice(None, None, hop)\n        # Use the slices to downsample the array\n        downsampled_data = data[tuple(slices)]\n    \n    elif target_size is not None:\n        # Calculate the hop based on the target size\n        original_size = data.shape[axis]\n        hop = max(original_size // target_size, 1)\n        slices = [slice(None)] * 3\n        slices[axis] = slice(None, None, hop)\n        downsampled_data = data[tuple(slices)]\n        # Adjust if the resulting size does not match the target size due to rounding\n        if downsampled_data.shape[axis] != target_size:\n            indices = np.round(np.linspace(0, downsampled_data.shape[axis] - 1, target_size)).astype(int)\n            downsampled_data = np.take(downsampled_data, indices, axis=axis)\n    \n    else:\n        raise ValueError(\"Either hop or target_size must be specified.\")\n    \n    return downsampled_data\n\n\n\n\n\nsource\n\n\n\n\n resample_3d_array (data:numpy.ndarray, axis:int, target_size:int)\n\nResample a 3D numpy array along a specified axis using linear interpolation.\n\n\n\n\nType\nDetails\n\n\n\n\ndata\nndarray\nThe original 3D array to be resampled.\n\n\naxis\nint\nThe axis along which to perform the interpolation.\n\n\ntarget_size\nint\nThe new size of the axis after resampling.\n\n\nReturns\nndarray\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n average_downsample_3d_array (data:numpy.ndarray, axis:int,\n                              target_size:int)\n\nDownsample a 3D numpy array along a specified axis using averaging.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndata\nndarray\nThe original 3D array to be downsampled.\n\n\naxis\nint\nThe axis along which to perform the downsampling (0, 1, or 2).\n\n\ntarget_size\nint\nThe desired size of the specified axis after downsampling.\n\n\nReturns\nndarray",
    "crumbs": [
      "Processing"
    ]
  },
  {
    "objectID": "processing.html#resampling",
    "href": "processing.html#resampling",
    "title": "Processing",
    "section": "",
    "text": "def downsample_3d_array(data: np.ndarray,     # The original 3D array to be downsampled.\n                        axis: int,            # The axis along which to perform the downsampling.\n                        hop: int = None,      # The interval at which to keep elements.\n                        target_size: int = None  # The target size for the specified axis.\n                       ) -&gt; np.ndarray:\n    \"\"\"\n    Downsample a 3D numpy array along a specified axis by keeping only every hop-th element or \n    to a target size.\n    \"\"\"\n    if axis not in [0, 1, 2]:  # Validate the axis to ensure it's within the correct range.\n        raise ValueError(\"Invalid axis. Axis must be 0, 1, or 2.\")\n\n    if hop is not None and hop &lt; 1:\n        raise ValueError(\"Hop must be a positive integer greater than or equal to 1.\")\n\n    if target_size is not None and (target_size &lt; 1 or target_size &gt; data.shape[axis]):\n        raise ValueError(\"Target size must be a positive integer and less than or equal to the size of the axis.\")\n    \n    if hop is not None:\n        # Create slices for each axis\n        slices = [slice(None)] * 3\n        slices[axis] = slice(None, None, hop)\n        # Use the slices to downsample the array\n        downsampled_data = data[tuple(slices)]\n    \n    elif target_size is not None:\n        # Calculate the hop based on the target size\n        original_size = data.shape[axis]\n        hop = max(original_size // target_size, 1)\n        slices = [slice(None)] * 3\n        slices[axis] = slice(None, None, hop)\n        downsampled_data = data[tuple(slices)]\n        # Adjust if the resulting size does not match the target size due to rounding\n        if downsampled_data.shape[axis] != target_size:\n            indices = np.round(np.linspace(0, downsampled_data.shape[axis] - 1, target_size)).astype(int)\n            downsampled_data = np.take(downsampled_data, indices, axis=axis)\n    \n    else:\n        raise ValueError(\"Either hop or target_size must be specified.\")\n    \n    return downsampled_data\n\n\n\n\n\nsource\n\n\n\n\n resample_3d_array (data:numpy.ndarray, axis:int, target_size:int)\n\nResample a 3D numpy array along a specified axis using linear interpolation.\n\n\n\n\nType\nDetails\n\n\n\n\ndata\nndarray\nThe original 3D array to be resampled.\n\n\naxis\nint\nThe axis along which to perform the interpolation.\n\n\ntarget_size\nint\nThe new size of the axis after resampling.\n\n\nReturns\nndarray\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n average_downsample_3d_array (data:numpy.ndarray, axis:int,\n                              target_size:int)\n\nDownsample a 3D numpy array along a specified axis using averaging.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndata\nndarray\nThe original 3D array to be downsampled.\n\n\naxis\nint\nThe axis along which to perform the downsampling (0, 1, or 2).\n\n\ntarget_size\nint\nThe desired size of the specified axis after downsampling.\n\n\nReturns\nndarray",
    "crumbs": [
      "Processing"
    ]
  },
  {
    "objectID": "processing.html#reorder-orbit-with-time",
    "href": "processing.html#reorder-orbit-with-time",
    "title": "Processing",
    "section": "Reorder Orbit with Time",
    "text": "Reorder Orbit with Time\n\nsource\n\nreorder_orbits\n\n reorder_orbits (orbit_dataset:numpy.ndarray)\n\nReorders the time steps of each orbit in the dataset such that the time values are always incrementally increasing. Returns the reordered dataset and metrics indicating the quality of the original ordering.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\norbit_dataset\nndarray\nThe original 3D numpy array representing the orbits.\n\n\nReturns\ntyping.Tuple[numpy.ndarray, typing.Dict[str, float]]\n3D numpy array of reordered orbits.",
    "crumbs": [
      "Processing"
    ]
  },
  {
    "objectID": "processing.html#reshaping-arrays",
    "href": "processing.html#reshaping-arrays",
    "title": "Processing",
    "section": "Reshaping Arrays",
    "text": "Reshaping Arrays\n\nsource\n\npad_and_convert_to_3d\n\n pad_and_convert_to_3d (orbits:Dict[int,numpy.ndarray], timesteps:int)\n\nTruncate and pad each orbit to a uniform length and convert to a 3D numpy array.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\norbits\ntyping.Dict[int, numpy.ndarray]\nDictionary of orbits with numerical keys.\n\n\ntimesteps\nint\nDesired number of timesteps.\n\n\nReturns\nndarray\n3D numpy array of padded orbits.\n\n\n\n\nsource\n\n\nsegment_and_convert_to_3d\n\n segment_and_convert_to_3d (orbits:Dict[int,numpy.ndarray],\n                            segment_length:int)\n\nDivide each orbit into segments of a given length and convert to a 3D numpy array.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\norbits\ntyping.Dict[int, numpy.ndarray]\nDictionary of orbits with numerical keys.\n\n\nsegment_length\nint\nDesired length of each segment.\n\n\nReturns\ntyping.Tuple[numpy.ndarray, typing.List[int]]\n3D numpy array of segments.\n\n\n\n\norbits = {\n    1: np.array([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n                    [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24],\n                    [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36],\n                    [37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48],\n                    [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60],\n                    [61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72]]),\n    2: np.array([[73, 74, 75, 76, 77, 78, 79],\n                    [81, 82, 83, 84, 85, 86, 87],\n                    [89, 90, 91, 92, 93, 94, 95],\n                    [97, 98, 99, 100, 101, 102, 103],\n                    [105, 106, 107, 108, 109, 110, 111],\n                    [113, 114, 115, 116, 117, 118, 119]])\n}\nsegment_length = 4\n\n# Expected segments and IDs\nexpected_segments = np.array([\n    [[1, 2, 3, 4], [13, 14, 15, 16], [25, 26, 27, 28], [37, 38, 39, 40], [49, 50, 51, 52], [61, 62, 63, 64]],\n    [[5, 6, 7, 8], [17, 18, 19, 20], [29, 30, 31, 32], [41, 42, 43, 44], [53, 54, 55, 56], [65, 66, 67, 68]],\n    [[9, 10, 11, 12], [21, 22, 23, 24], [33, 34, 35, 36], [45, 46, 47, 48], [57, 58, 59, 60], [69, 70, 71, 72]],\n    [[73, 74, 75, 76], [81, 82, 83, 84], [89, 90, 91, 92], [97, 98, 99, 100], [105, 106, 107, 108], [113, 114, 115, 116]]\n])\nexpected_ids = [1, 1, 1, 2]\n\n# Call the function\nsegments_3d, segment_ids = segment_and_convert_to_3d(orbits, segment_length)\n\n# Use test_eq to check the results\ntest_eq(segments_3d.tolist(), expected_segments.tolist())\ntest_eq(segment_ids, expected_ids)",
    "crumbs": [
      "Processing"
    ]
  },
  {
    "objectID": "processing.html#add-time-vector",
    "href": "processing.html#add-time-vector",
    "title": "Processing",
    "section": "Add Time Vector",
    "text": "Add Time Vector\n\nsource\n\nadd_time_vector_to_orbits\n\n add_time_vector_to_orbits (orbits:Dict[int,numpy.ndarray],\n                            propagated_periods:List[float],\n                            periods:List[float])\n\nAdd a time vector to each orbit in the dictionary.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\norbits\ntyping.Dict[int, numpy.ndarray]\nDictionary of orbits with numerical keys.\n\n\npropagated_periods\ntyping.List[float]\nList of propagated periods for each orbit.\n\n\nperiods\ntyping.List[float]\nList of periods for each orbit.\n\n\nReturns\ntyping.Dict[int, numpy.ndarray]\nDictionary of updated orbits with time vectors added.",
    "crumbs": [
      "Processing"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "source\n\n\n\n load_orbit_data (file_path:str, variable_name:Union[str,NoneType]=None,\n                  dataset_path:Union[str,NoneType]=None)\n\nLoad orbit data from MATLAB .mat files, HDF5 .h5 files, or NumPy .npy files.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfile_path\nstr\n\nThe path to the .mat, .h5, or .npy file.\n\n\nvariable_name\ntyping.Union[str, NoneType]\nNone\nName of the variable in the .mat file, optional.\n\n\ndataset_path\ntyping.Union[str, NoneType]\nNone\nPath to the dataset in the .h5 file, optional.\n\n\nReturns\ntyping.Any\n\nThe loaded orbit data.\n\n\n\n\nsource\n\n\n\n\n load_memmap_array (file_path:str, mode:str='c')\n\n*Load a .npy file as a memory-mapped array using numpy.memmap.\nArgs: file_path: A string representing the path to the .npy file. mode: The mode in which the file is to be opened. Valid options are: - ‘r’ : Read-only, no data can be modified. - ‘r+’ : Read/write, modifications to the data are written to the file. - ‘w+’ : Read/write, file is created if it does not exist, overwritten if it does. - ‘c’ : Copy-on-write, data can be modified in memory but changes are not saved to the file.\nReturns: A numpy.memmap object that behaves like a numpy array but with data stored on disk instead of in memory.*\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfile_path\nstr\n\nThe path to the .npy file as a string.\n\n\nmode\nstr\nc\nMode for memory-mapping (‘r’, ‘r+’, ‘w+’, ‘c’).\n\n\nReturns\nmemmap\n\nReturns a memory-mapped array.\n\n\n\n\nsource\n\n\n\n\n get_orbit_features (file_path:str,\n                     variable_name:Union[str,NoneType]=None,\n                     dataset_path:Union[str,NoneType]=None)\n\nLoad orbit feature data from a specified file and convert it to a DataFrame.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfile_path\nstr\n\nThe path to the file (can be .mat, .h5, or .npy).\n\n\nvariable_name\ntyping.Union[str, NoneType]\nNone\nName of the variable in the .mat file, optional.\n\n\ndataset_path\ntyping.Union[str, NoneType]\nNone\nPath to the dataset in the .h5 file, optional.\n\n\nReturns\nDataFrame\n\nDataFrame with detailed orbit features.",
    "crumbs": [
      "Data"
    ]
  },
  {
    "objectID": "data.html#loading-data",
    "href": "data.html#loading-data",
    "title": "Data",
    "section": "",
    "text": "source\n\n\n\n load_orbit_data (file_path:str, variable_name:Union[str,NoneType]=None,\n                  dataset_path:Union[str,NoneType]=None)\n\nLoad orbit data from MATLAB .mat files, HDF5 .h5 files, or NumPy .npy files.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfile_path\nstr\n\nThe path to the .mat, .h5, or .npy file.\n\n\nvariable_name\ntyping.Union[str, NoneType]\nNone\nName of the variable in the .mat file, optional.\n\n\ndataset_path\ntyping.Union[str, NoneType]\nNone\nPath to the dataset in the .h5 file, optional.\n\n\nReturns\ntyping.Any\n\nThe loaded orbit data.\n\n\n\n\nsource\n\n\n\n\n load_memmap_array (file_path:str, mode:str='c')\n\n*Load a .npy file as a memory-mapped array using numpy.memmap.\nArgs: file_path: A string representing the path to the .npy file. mode: The mode in which the file is to be opened. Valid options are: - ‘r’ : Read-only, no data can be modified. - ‘r+’ : Read/write, modifications to the data are written to the file. - ‘w+’ : Read/write, file is created if it does not exist, overwritten if it does. - ‘c’ : Copy-on-write, data can be modified in memory but changes are not saved to the file.\nReturns: A numpy.memmap object that behaves like a numpy array but with data stored on disk instead of in memory.*\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfile_path\nstr\n\nThe path to the .npy file as a string.\n\n\nmode\nstr\nc\nMode for memory-mapping (‘r’, ‘r+’, ‘w+’, ‘c’).\n\n\nReturns\nmemmap\n\nReturns a memory-mapped array.\n\n\n\n\nsource\n\n\n\n\n get_orbit_features (file_path:str,\n                     variable_name:Union[str,NoneType]=None,\n                     dataset_path:Union[str,NoneType]=None)\n\nLoad orbit feature data from a specified file and convert it to a DataFrame.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfile_path\nstr\n\nThe path to the file (can be .mat, .h5, or .npy).\n\n\nvariable_name\ntyping.Union[str, NoneType]\nNone\nName of the variable in the .mat file, optional.\n\n\ndataset_path\ntyping.Union[str, NoneType]\nNone\nPath to the dataset in the .h5 file, optional.\n\n\nReturns\nDataFrame\n\nDataFrame with detailed orbit features.",
    "crumbs": [
      "Data"
    ]
  },
  {
    "objectID": "data.html#save-data",
    "href": "data.html#save-data",
    "title": "Data",
    "section": "Save Data",
    "text": "Save Data\n\nsource\n\nsave_data\n\n save_data (data:numpy.ndarray, file_name:str)\n\nSave a numpy array to a file based on the file extension specified in file_name. Supports saving to HDF5 (.hdf5) or NumPy (.npy) file formats.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndata\nndarray\nThe numpy array data to save.\n\n\nfile_name\nstr\nThe name of the file to save the data in, including the extension.\n\n\nReturns\nNone",
    "crumbs": [
      "Data"
    ]
  },
  {
    "objectID": "data.html#get-example-data",
    "href": "data.html#get-example-data",
    "title": "Data",
    "section": "Get Example Data",
    "text": "Get Example Data\n\nsource\n\nget_example_orbit_data\n\n get_example_orbit_data ()\n\n*Load orbit data from a hardcoded MAT file located in the data directory.\nThe function is specifically designed to load the ‘Xarray’ variable from the ‘1_L2_S_200_EM_CR3BP.mat’ file. This setup is intended for demonstration or testing purposes, where the data file and the variable of interest are known ahead of time.\n:return: A numpy.ndarray containing the transposed data from the MAT file.*\n\ndata = get_example_orbit_data()\ndata.shape\n\n(200, 6, 300)",
    "crumbs": [
      "Data"
    ]
  },
  {
    "objectID": "data.html#random-sampler",
    "href": "data.html#random-sampler",
    "title": "Data",
    "section": "Random Sampler",
    "text": "Random Sampler\n\nsource\n\nsample_orbits\n\n sample_orbits (orbit_data:numpy.ndarray, sample_spec:dict,\n                labels:numpy.ndarray=None)\n\n*Randomly sample orbits from the provided dataset.\nParameters: orbit_data (np.ndarray): Array of orbit data with shape (num_orbits, 6, num_time_points). sample_spec (dict or int): If int, it is the total number of orbits to sample. If dict, it specifies the number of samples for each class. labels (np.ndarray, optional): Array of labels for each orbit.\nReturns: tuple: A tuple containing the sampled orbit data and corresponding labels (if provided).*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\norbit_data\nndarray\n\nOrbit data array\n\n\nsample_spec\ndict\n\nNumber of samples per class (dict) or total number of samples (int)\n\n\nlabels\nndarray\nNone\nOptional: Array of labels corresponding to each orbit\n\n\nReturns\n(&lt;class ‘numpy.ndarray’&gt;, &lt;class ‘numpy.ndarray’&gt;)",
    "crumbs": [
      "Data"
    ]
  },
  {
    "objectID": "model.html",
    "href": "model.html",
    "title": "Model",
    "section": "",
    "text": "import os\nimport tsgm\n\ndef get_model(params, data_path):\n    model_name = params['model_name']\n    data_used = os.path.splitext(os.path.basename(data_path))[0]\n\n    if model_name == 'vae_conv5':\n        # Accessing model configuration from the zoo using parameters from the dictionary\n        architecture = tsgm.models.zoo[model_name](\n            seq_len=params['seq_len'], \n            feat_dim=params['feature_dim'], \n            latent_dim=params['latent_dim']\n        )\n\n        # Extracting encoder and decoder from the architecture\n        encoder, decoder = architecture.encoder, architecture.decoder\n\n        # Build the VAE\n        vae = tsgm.models.cvae.BetaVAE(encoder, decoder)\n        vae.compile(optimizer=params['optimizer']['name'], learning_rate=params['optimizer']['learning_rate'])\n        return vae\n\n    elif model_name == 'timeGAN':\n        model = tsgm.models.timeGAN.TimeGAN(\n            seq_len=params['seq_len'],\n            module=\"gru\",\n            hidden_dim=24,\n            n_features=params['feature_dim'],\n            n_layers=3,\n            batch_size=params['batch_size'],\n            gamma=1.0,\n        )\n        # .compile() sets all optimizers to Adam by default\n        model.compile(optimizer=params['optimizer']['name'], learning_rate=params['optimizer']['learning_rate'])\n        return model\n\n    else:\n        raise ValueError(f\"Unsupported model_name: {model_name}\")\n\n\nsource\n\nget_model\n\n get_model (params)\n\n\nsource\n\n\nget_optimizer\n\n get_optimizer (optimizer_config)\n\n\nsource\n\n\nextract_plot_and_return_metrics\n\n extract_plot_and_return_metrics (history, validation=True)\n\n*Extracts the metrics from the training history, plots the training and validation loss over epochs if validation is True, and returns the metrics.\nParameters: - history: History object returned by model.fit(). - validation: Boolean flag to control whether to extract and plot validation metrics.\nReturns: - metrics: Dictionary containing the final training and validation metrics.*",
    "crumbs": [
      "Model"
    ]
  },
  {
    "objectID": "visualization.html",
    "href": "visualization.html",
    "title": "Visualization",
    "section": "",
    "text": "source\n\n\n\n\n visualize_static_orbits (data:numpy.ndarray,\n                          time_instants:Union[List[int],NoneType]=None,\n                          orbit_indices:Union[List[int],NoneType]=None,\n                          point_dict:Union[Dict[str,tuple],NoneType]=None,\n                          show_legend:bool=True,\n                          save_path:Union[str,NoneType]=None,\n                          plot_reference_box:bool=True)\n\nVisualizes orbits in 3D space and highlights specified time instants for each selected orbit.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nndarray\n\nThe orbit data with shape (num_orbits, 6, num_time_points).\n\n\ntime_instants\ntyping.Union[typing.List[int], NoneType]\nNone\nTime points to highlight; defaults to None.\n\n\norbit_indices\ntyping.Union[typing.List[int], NoneType]\nNone\nIndices of orbits to visualize; defaults to all.\n\n\npoint_dict\ntyping.Union[typing.Dict[str, tuple], NoneType]\nNone\nDictionary of extra points to plot.\n\n\nshow_legend\nbool\nTrue\nFlag to indicate whether to show a legend.\n\n\nsave_path\ntyping.Union[str, NoneType]\nNone\nPath to save the figure; defaults to None.\n\n\nplot_reference_box\nbool\nTrue\nFlag to indicate whether to plot the reference box.\n\n\nReturns\nNone\n\n\n\n\n\n\nfrom orbit_generation.data import get_example_orbit_data\nfrom orbit_generation.constants import EM_POINTS\n\n\norbit_data= get_example_orbit_data()\norbit_data.shape\n\n(200, 6, 300)\n\n\n\nvisualize_static_orbits(data= orbit_data, orbit_indices=[15,20,70,140,190], point_dict=EM_POINTS)\n\n\n\n\n\n\n\n\n\nvisualize_static_orbits(data= orbit_data,time_instants=[0,50], orbit_indices=[0,20,40], plot_reference_box=False)\n\n\n\n\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n export_dynamic_orbits_html (data:numpy.ndarray,\n                             time_instants:Union[List[int],NoneType]=None,\n                             orbit_indices:Union[List[int],NoneType]=None,\n                             point_dict:Union[Dict[str,tuple],NoneType]=No\n                             ne, filename:str='orbits.html')\n\nGenerates an interactive 3D visualization of orbits and saves it as an HTML file, including the ability to highlight specific time instants and show named points.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nndarray\n\nOrbit data as a 3D numpy array (num_orbits, 6, num_time_points).\n\n\ntime_instants\ntyping.Union[typing.List[int], NoneType]\nNone\nTime instants to highlight.\n\n\norbit_indices\ntyping.Union[typing.List[int], NoneType]\nNone\nIndices of orbits to visualize.\n\n\npoint_dict\ntyping.Union[typing.Dict[str, tuple], NoneType]\nNone\nNamed points as a dict with 3D coordinates.\n\n\nfilename\nstr\norbits.html\nPath and name of the file to save the HTML plot.\n\n\nReturns\nNone\n\n\n\n\n\n\nexport_dynamic_orbits_html(data=orbit_data, filename='../data/example_data/example_orbits.html')\n\nVisualization saved to ../data/example_data/example_orbits.html\n\n\nView Orbit Visualization",
    "crumbs": [
      "Visualization"
    ]
  },
  {
    "objectID": "visualization.html#orbits",
    "href": "visualization.html#orbits",
    "title": "Visualization",
    "section": "",
    "text": "source\n\n\n\n\n visualize_static_orbits (data:numpy.ndarray,\n                          time_instants:Union[List[int],NoneType]=None,\n                          orbit_indices:Union[List[int],NoneType]=None,\n                          point_dict:Union[Dict[str,tuple],NoneType]=None,\n                          show_legend:bool=True,\n                          save_path:Union[str,NoneType]=None,\n                          plot_reference_box:bool=True)\n\nVisualizes orbits in 3D space and highlights specified time instants for each selected orbit.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nndarray\n\nThe orbit data with shape (num_orbits, 6, num_time_points).\n\n\ntime_instants\ntyping.Union[typing.List[int], NoneType]\nNone\nTime points to highlight; defaults to None.\n\n\norbit_indices\ntyping.Union[typing.List[int], NoneType]\nNone\nIndices of orbits to visualize; defaults to all.\n\n\npoint_dict\ntyping.Union[typing.Dict[str, tuple], NoneType]\nNone\nDictionary of extra points to plot.\n\n\nshow_legend\nbool\nTrue\nFlag to indicate whether to show a legend.\n\n\nsave_path\ntyping.Union[str, NoneType]\nNone\nPath to save the figure; defaults to None.\n\n\nplot_reference_box\nbool\nTrue\nFlag to indicate whether to plot the reference box.\n\n\nReturns\nNone\n\n\n\n\n\n\nfrom orbit_generation.data import get_example_orbit_data\nfrom orbit_generation.constants import EM_POINTS\n\n\norbit_data= get_example_orbit_data()\norbit_data.shape\n\n(200, 6, 300)\n\n\n\nvisualize_static_orbits(data= orbit_data, orbit_indices=[15,20,70,140,190], point_dict=EM_POINTS)\n\n\n\n\n\n\n\n\n\nvisualize_static_orbits(data= orbit_data,time_instants=[0,50], orbit_indices=[0,20,40], plot_reference_box=False)\n\n\n\n\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n export_dynamic_orbits_html (data:numpy.ndarray,\n                             time_instants:Union[List[int],NoneType]=None,\n                             orbit_indices:Union[List[int],NoneType]=None,\n                             point_dict:Union[Dict[str,tuple],NoneType]=No\n                             ne, filename:str='orbits.html')\n\nGenerates an interactive 3D visualization of orbits and saves it as an HTML file, including the ability to highlight specific time instants and show named points.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nndarray\n\nOrbit data as a 3D numpy array (num_orbits, 6, num_time_points).\n\n\ntime_instants\ntyping.Union[typing.List[int], NoneType]\nNone\nTime instants to highlight.\n\n\norbit_indices\ntyping.Union[typing.List[int], NoneType]\nNone\nIndices of orbits to visualize.\n\n\npoint_dict\ntyping.Union[typing.Dict[str, tuple], NoneType]\nNone\nNamed points as a dict with 3D coordinates.\n\n\nfilename\nstr\norbits.html\nPath and name of the file to save the HTML plot.\n\n\nReturns\nNone\n\n\n\n\n\n\nexport_dynamic_orbits_html(data=orbit_data, filename='../data/example_data/example_orbits.html')\n\nVisualization saved to ../data/example_data/example_orbits.html\n\n\nView Orbit Visualization",
    "crumbs": [
      "Visualization"
    ]
  },
  {
    "objectID": "visualization.html#orbit-features",
    "href": "visualization.html#orbit-features",
    "title": "Visualization",
    "section": "Orbit Features",
    "text": "Orbit Features\n\nsource\n\nplot_grouped_features\n\n plot_grouped_features (df:pandas.core.frame.DataFrame, columns:List[str],\n                        group_col:str, plot_type:str)\n\nGroup the DataFrame by a specified column and plot the specified type of plot for each column for each group.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nDataFrame containing the data.\n\n\ncolumns\ntyping.List[str]\nList of column names to plot.\n\n\ngroup_col\nstr\nColumn name to group by.\n\n\nplot_type\nstr\nType of plot: ‘violin’, ‘box’, ‘facetgrid’, or ‘histogram’\n\n\nReturns\nNone\n\n\n\n\n\nsource\n\n\nplot_value_proportions\n\n plot_value_proportions (data:Union[List[int],numpy.ndarray,NoneType],\n                         classification_df:pandas.core.frame.DataFrame,\n                         id_col_classification:Union[str,NoneType]=None,\n                         grid:Union[str,NoneType]='horizontal',\n                         show_percentages:Union[bool,List[bool]]=True,\n                         show_labels:Union[bool,List[bool]]=True,\n                         percentage_font_size:int=10,\n                         label_distance:float=1.1,\n                         pct_distance:float=0.85,\n                         explode_factor:float=0.1)\n\nCount occurrences of each unique value in data, map those counts to the DataFrame, and plot the proportions in pie charts for each column except the ID column.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\ntyping.Union[typing.List[int], numpy.ndarray, NoneType]\n\nList or array of ID values to filter the DataFrame.\n\n\nclassification_df\nDataFrame\n\nDataFrame containing the data.\n\n\nid_col_classification\ntyping.Union[str, NoneType]\nNone\nColumn name to be used as ID.\n\n\ngrid\ntyping.Union[str, NoneType]\nhorizontal\nOption to plot in grid (horizontal, vertical, or square) or separate images.\n\n\nshow_percentages\ntyping.Union[bool, typing.List[bool]]\nTrue\nOption to print or not print percentages.\n\n\nshow_labels\ntyping.Union[bool, typing.List[bool]]\nTrue\nOption to print or not print labels.\n\n\npercentage_font_size\nint\n10\nFont size for percentages.\n\n\nlabel_distance\nfloat\n1.1\nDistance of labels from center.\n\n\npct_distance\nfloat\n0.85\nDistance of percentages from center.\n\n\nexplode_factor\nfloat\n0.1\nFactor to separate slices.\n\n\nReturns\nNone",
    "crumbs": [
      "Visualization"
    ]
  },
  {
    "objectID": "visualization.html#latent-space",
    "href": "visualization.html#latent-space",
    "title": "Visualization",
    "section": "Latent Space",
    "text": "Latent Space\n\nsource\n\nplot_latent_space_2d\n\n plot_latent_space_2d (latent_representations:numpy.ndarray,\n                       labels:numpy.ndarray, figsize:tuple=(12, 9),\n                       save_path:Union[str,NoneType]=None,\n                       many_classes:bool=False, **kwargs:Any)\n\nPlots and optionally saves the latent space representations assuming they are already in 2D.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlatent_representations\nndarray\n\nPrecomputed latent representations (numpy array).\n\n\nlabels\nndarray\n\nLabels for the data points, used for coloring in the plot.\n\n\nfigsize\ntuple\n(12, 9)\nSize of the figure for the plot.\n\n\nsave_path\ntyping.Union[str, NoneType]\nNone\nOptional path to save the plot image.\n\n\nmany_classes\nbool\nFalse\nFlag to use enhanced plotting for many classes.\n\n\nkwargs\ntyping.Any\n\n\n\n\nReturns\nNone\n\nAdditional keyword arguments for the plotting.\n\n\n\n\nsource\n\n\nplot_combined_latent_space_2d\n\n plot_combined_latent_space_2d (real_data:numpy.ndarray,\n                                synthetic_data:numpy.ndarray, encoder, syn\n                                thetic_labels:Union[int,List[int],NoneType\n                                ]=1, figsize:tuple=(12, 9),\n                                save_path:Union[str,NoneType]=None,\n                                many_classes:bool=False,\n                                show_legend:bool=True,\n                                annotation_mode:str='legend')\n\nPlots the combined latent space of real and synthetic data. Assumes the latent space is already 2D.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nreal_data\nndarray\n\nReal data samples.\n\n\nsynthetic_data\nndarray\n\nSynthetic data samples generated by a model.\n\n\nencoder\n\n\nEncoder function or model that predicts latent space representations.\n\n\nsynthetic_labels\ntyping.Union[int, typing.List[int], NoneType]\n1\nLabels for synthetic data. Can be a single label or a list of labels.\n\n\nfigsize\ntuple\n(12, 9)\nSize of the figure.\n\n\nsave_path\ntyping.Union[str, NoneType]\nNone\nOptional path to save the plot image.\n\n\nmany_classes\nbool\nFalse\nFlag to use enhanced plotting for many classes.\n\n\nshow_legend\nbool\nTrue\nFlag to show or hide the legend.\n\n\nannotation_mode\nstr\nlegend\nMode for annotation: ‘legend’ for colored dots, ‘numbers’ for numeric annotations.\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nplot_latent_space_with_feature_distributions\n\n plot_latent_space_with_feature_distributions\n                                               (latent_representations:num\n                                               py.ndarray,\n                                               labels:numpy.ndarray, featu\n                                               res:Union[numpy.ndarray,Non\n                                               eType]=None, feature_names:\n                                               Union[list,NoneType]=None,\n                                               figsize:tuple=(12, 12), sav\n                                               e_path:Union[str,NoneType]=\n                                               None,\n                                               many_classes:bool=False,\n                                               show_legend:bool=True,\n                                               legend_fontsize:int=8,\n                                               **kwargs:Any)\n\nPlots the latent space with class colors and normalized vertical and horizontal feature distributions in separate subplots.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlatent_representations\nndarray\n\n\n\n\nlabels\nndarray\n\n\n\n\nfeatures\ntyping.Union[numpy.ndarray, NoneType]\nNone\n\n\n\nfeature_names\ntyping.Union[list, NoneType]\nNone\n\n\n\nfigsize\ntuple\n(12, 12)\nAdjusted to be a square\n\n\nsave_path\ntyping.Union[str, NoneType]\nNone\n\n\n\nmany_classes\nbool\nFalse\n\n\n\nshow_legend\nbool\nTrue\n\n\n\nlegend_fontsize\nint\n8\n\n\n\nkwargs\ntyping.Any\n\n\n\n\nReturns\nNone",
    "crumbs": [
      "Visualization"
    ]
  },
  {
    "objectID": "experiment.html",
    "href": "experiment.html",
    "title": "Experiment",
    "section": "",
    "text": "source\n\n\n\n setup_new_experiment (params:Dict[str,Any], experiments_folder:str,\n                       json_file:Union[str,NoneType]=None)\n\nSets up a new experiment by creating a new folder and updating the JSON file with experiment parameters.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nparams\ntyping.Dict[str, typing.Any]\n\nDictionary of parameters for the new experiment.\n\n\nexperiments_folder\nstr\n\nPath to the folder containing all experiments.\n\n\njson_file\ntyping.Union[str, NoneType]\nNone\nOptional path to the JSON file tracking experiment parameters.\n\n\nReturns\nstr\n\nThe path to the newly created experiment folder.",
    "crumbs": [
      "Experiment"
    ]
  },
  {
    "objectID": "experiment.html#setup",
    "href": "experiment.html#setup",
    "title": "Experiment",
    "section": "",
    "text": "source\n\n\n\n setup_new_experiment (params:Dict[str,Any], experiments_folder:str,\n                       json_file:Union[str,NoneType]=None)\n\nSets up a new experiment by creating a new folder and updating the JSON file with experiment parameters.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nparams\ntyping.Dict[str, typing.Any]\n\nDictionary of parameters for the new experiment.\n\n\nexperiments_folder\nstr\n\nPath to the folder containing all experiments.\n\n\njson_file\ntyping.Union[str, NoneType]\nNone\nOptional path to the JSON file tracking experiment parameters.\n\n\nReturns\nstr\n\nThe path to the newly created experiment folder.",
    "crumbs": [
      "Experiment"
    ]
  },
  {
    "objectID": "experiment.html#add-metrics",
    "href": "experiment.html#add-metrics",
    "title": "Experiment",
    "section": "Add metrics",
    "text": "Add metrics\n\nsource\n\nconvert_numpy_types\n\n convert_numpy_types (obj)\n\nRecursively convert numpy types to native Python types for JSON serialization.\n\nsource\n\n\nadd_experiment_metrics\n\n add_experiment_metrics (experiments_folder:str,\n                         params:Union[Dict[str,Any],NoneType]=None,\n                         experiment_id:Union[int,NoneType]=None,\n                         metrics:Union[Dict[str,Any],NoneType]=None,\n                         json_file:Union[str,NoneType]=None)\n\nAdds metrics to an existing experiment in the JSON file based on the given parameters or ID.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nexperiments_folder\nstr\n\nPath to the folder containing all experiments.\n\n\nparams\ntyping.Union[typing.Dict[str, typing.Any], NoneType]\nNone\nOptional dictionary of parameters identifying the experiment.\n\n\nexperiment_id\ntyping.Union[int, NoneType]\nNone\nOptional ID to identify the experiment.\n\n\nmetrics\ntyping.Union[typing.Dict[str, typing.Any], NoneType]\nNone\nOptional dictionary of metrics to be added to the experiment.\n\n\njson_file\ntyping.Union[str, NoneType]\nNone\nOptional path to the JSON file tracking experiment parameters and metrics.\n\n\nReturns\nNone",
    "crumbs": [
      "Experiment"
    ]
  },
  {
    "objectID": "experiment.html#get-metrics",
    "href": "experiment.html#get-metrics",
    "title": "Experiment",
    "section": "Get metrics",
    "text": "Get metrics\n\nsource\n\nget_experiment_parameters\n\n get_experiment_parameters (experiments_folder:str, experiment_id:int,\n                            json_file:Union[str,NoneType]=None)\n\nRetrieves the parameters of an experiment from the JSON file based on the given ID.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nexperiments_folder\nstr\n\nPath to the folder containing all experiments.\n\n\nexperiment_id\nint\n\nID to identify the experiment.\n\n\njson_file\ntyping.Union[str, NoneType]\nNone\nOptional path to the JSON file tracking experiment parameters and metrics.\n\n\nReturns\ntyping.Dict[str, typing.Any]",
    "crumbs": [
      "Experiment"
    ]
  },
  {
    "objectID": "experiment.html#convert-notebook",
    "href": "experiment.html#convert-notebook",
    "title": "Experiment",
    "section": "Convert notebook",
    "text": "Convert notebook\n\nsource\n\nconvert_notebook\n\n convert_notebook (notebook_path:str, output_folder:str,\n                   output_filename:str, format:str='html')\n\n*Convert the specified Jupyter notebook to HTML or PDF.\n\nparam notebook_path: The path to the notebook to convert. :param output_folder: The folder to save the converted file. :param output_filename: The name of the output file. :param format: The format to convert the notebook to (‘html’ or ‘pdf’).*\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnotebook_path\nstr\n\nThe path to the notebook to convert.\n\n\noutput_folder\nstr\n\nThe folder to save the converted file.\n\n\noutput_filename\nstr\n\nThe name of the output file.\n\n\nformat\nstr\nhtml\nThe format to convert the notebook to (‘html’ or ‘pdf’).\n\n\nReturns\nNone\n\nThis function does not return a value.\n\n\n\n\nsource\n\n\nread_json_to_dataframe\n\n read_json_to_dataframe (json_path:str)\n\n*Reads a JSON file containing experiment results and returns a DataFrame.\nArgs: - json_path (str): The path to the JSON file.\nReturns: - pd.DataFrame: A DataFrame containing the experiment results.*\n\nsource\n\n\ncreate_experiment_image_grid\n\n create_experiment_image_grid (experiments_folder, image_suffix,\n                               crop_length, font_size=12, save_path=None,\n                               grid_size=(3, 2), experiment_indices=None,\n                               hspace=-0.37)\n\n\nsource\n\n\nplot_corr_matrix\n\n plot_corr_matrix (dataframe:pandas.core.frame.DataFrame, figsize=(14,\n                   10), cmap='coolwarm',\n                   save_path:Union[str,NoneType]=None)\n\n*Plots a correlation matrix heatmap with annotations.\nParameters: dataframe (pd.DataFrame): The DataFrame containing the data to be analyzed. figsize (tuple): The size of the figure (width, height). cmap (str): The color map to be used for the heatmap. save_path (Optional[str]): The path to save the plot image. If None, the plot is not saved.\nReturns: None: Displays the correlation matrix heatmap.*",
    "crumbs": [
      "Experiment"
    ]
  },
  {
    "objectID": "constants.html",
    "href": "constants.html",
    "title": "Constants",
    "section": "",
    "text": "MU_BY_SYSTEM\n\n{'SaE': 1.901109735892602e-07,\n 'MP': 1.611081404409632e-08,\n 'SaT': 0.0002366393158331484,\n 'EM': 0.01215058560962404,\n 'JE': 2.52801752854e-05,\n 'SE': 3.0542e-06,\n 'SM': 3.227154996101724e-07}\n\n\n\nEM_POINTS\n\n{'Moon': (0.987849414390376, 0, 0),\n 'Earth': (-0.01215058560962404, 0, 0),\n 'Lagrange 1': (0.8369, 0, 0),\n 'Lagrange 2': (1.1557, 0, 0),\n 'Lagrange 3': (-1.0051, 0, 0),\n 'Lagrange 4': (0.4879, 0.866, 0),\n 'Lagrange 5': (0.4879, -0.866, 0)}\n\n\n\nORBIT_CLASS_DF\n\n\n\n\n\n\n\n\nId\nLabel\nType\nSubtype\nDirection\n\n\n\n\n0\n1\nS_BN\nSystem-wide\nButterfly\nNorth\n\n\n1\n2\nS_BS\nSystem-wide\nButterfly\nSouth\n\n\n2\n3\nS_DN\nSystem-wide\nDragonfly\nNorth\n\n\n3\n4\nS_DPO\nSystem-wide\nDistant Prograde\nPlanar\n\n\n4\n5\nS_DRO\nSystem-wide\nDistant Retrograde\nPlanar\n\n\n5\n6\nS_DS\nSystem-wide\nDragonfly\nSouth\n\n\n6\n7\nS_L1_A\nL1\nAxial\nNo specification\n\n\n7\n8\nS_L1_HN\nL1\nHalo\nNorth\n\n\n8\n9\nS_L1_HS\nL1\nHalo\nSouth\n\n\n9\n10\nS_L1_L\nL1\nLyapunov\nPlanar\n\n\n10\n11\nS_L1_V\nL1\nVertical\nNo specification\n\n\n11\n12\nS_L2_A\nL2\nAxial\nNo specification\n\n\n12\n13\nS_L2_HN\nL2\nHalo\nNorth\n\n\n13\n14\nS_L2_HS\nL2\nHalo\nSouth\n\n\n14\n15\nS_L2_L\nL2\nLyapunov\nPlanar\n\n\n15\n16\nS_L2_V\nL2\nVertical\nNo specification\n\n\n16\n17\nS_L3_A\nL3\nAxial\nNo specification\n\n\n17\n18\nS_L3_HN\nL3\nHalo\nNorth\n\n\n18\n19\nS_L3_HS\nL3\nHalo\nSouth\n\n\n19\n20\nS_L3_L\nL3\nLyapunov\nPlanar\n\n\n20\n21\nS_L3_V\nL3\nVertical\nNo specification\n\n\n21\n22\nS_L4_A\nL4\nAxial\nNo specification\n\n\n22\n23\nS_L4_LP\nL4\nLong Period\nNo specification\n\n\n23\n24\nS_L4_SP\nL4\nShort Period\nNo specification\n\n\n24\n25\nS_L4_V\nL4\nVertical\nNo specification\n\n\n25\n26\nS_L5_A\nL5\nAxial\nNo specification\n\n\n26\n27\nS_L5_LP\nL5\nLong Period\nNo specification\n\n\n27\n28\nS_L5_SP\nL5\nShort Period\nNo specification\n\n\n28\n29\nS_L5_V\nL5\nVertical\nNo specification\n\n\n29\n30\nS_LPOE\nSystem-wide\nLow Prograde\nEast\n\n\n30\n31\nS_LPOW\nSystem-wide\nLow Prograde\nWest\n\n\n31\n32\nS_R11\nResonant\nResonant 1,1\nPlanar\n\n\n32\n33\nS_R12\nResonant\nResonant 1,2\nPlanar\n\n\n33\n34\nS_R13\nResonant\nResonant 1,3\nPlanar\n\n\n34\n35\nS_R14\nResonant\nResonant 1,4\nPlanar\n\n\n35\n36\nS_R21\nResonant\nResonant 2,1\nPlanar\n\n\n36\n37\nS_R23\nResonant\nResonant 2,3\nPlanar\n\n\n37\n38\nS_R31\nResonant\nResonant 3,1\nPlanar\n\n\n38\n39\nS_R32\nResonant\nResonant 3,2\nPlanar\n\n\n39\n40\nS_R34\nResonant\nResonant 3,4\nPlanar\n\n\n40\n41\nS_R41\nResonant\nResonant 4,1\nPlanar\n\n\n41\n42\nS_R43\nResonant\nResonant 4,3\nPlanar",
    "crumbs": [
      "Constants"
    ]
  },
  {
    "objectID": "dataset.html",
    "href": "dataset.html",
    "title": "Dataset",
    "section": "",
    "text": "source\n\n\n\n get_orbit_data_from_hdf5 (file_path:str)\n\nLoad orbit data from an HDF5 file.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nfile_path\nstr\nPath to the HDF5 file.\n\n\nReturns\ntyping.Tuple[typing.Dict[int, numpy.ndarray], pandas.core.frame.DataFrame, typing.Dict[str, float]]\nDictionary of orbits with numerical keys.",
    "crumbs": [
      "Dataset"
    ]
  },
  {
    "objectID": "dataset.html#read-data",
    "href": "dataset.html#read-data",
    "title": "Dataset",
    "section": "",
    "text": "source\n\n\n\n get_orbit_data_from_hdf5 (file_path:str)\n\nLoad orbit data from an HDF5 file.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nfile_path\nstr\nPath to the HDF5 file.\n\n\nReturns\ntyping.Tuple[typing.Dict[int, numpy.ndarray], pandas.core.frame.DataFrame, typing.Dict[str, float]]\nDictionary of orbits with numerical keys.",
    "crumbs": [
      "Dataset"
    ]
  },
  {
    "objectID": "dataset.html#get-features",
    "href": "dataset.html#get-features",
    "title": "Dataset",
    "section": "Get Features",
    "text": "Get Features\n\nOrbit Features\n\nsource\n\n\nget_orbit_features_from_hdf5\n\n get_orbit_features_from_hdf5 (file_path:str)\n\nLoad orbit DataFrame from an HDF5 file.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nfile_path\nstr\nPath to the HDF5 file.\n\n\nReturns\nDataFrame\nDataFrame containing orbit features.\n\n\n\n\nsource\n\n\nget_orbit_features_from_folder\n\n get_orbit_features_from_folder (folder_path:str)\n\nConcatenate orbit DataFrames from all HDF5 files in a folder, preserving original index and adding system column.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nfolder_path\nstr\nPath to the folder\n\n\nReturns\nDataFrame\nDataFrame containing concatenated orbit features.\n\n\n\n\n\nSystem Features\n\ndef get_system_data_from_hdf5(file_path: str              # Path to the HDF5 file.\n                             ) -&gt; Dict[str, float]:       # Dictionary containing system features.\n    \"\"\"\n    Load system data from an HDF5 file.\n    \"\"\"\n    with h5py.File(file_path, 'r') as file:\n        # Extract system features and labels\n        system_features = file['system_features'][:]\n        system_labels = file['system_labels'][:].astype(str)\n        \n        # Create a dictionary for system\n        system_dict = {label: feature[0] for label, feature in zip(system_labels.flatten().tolist(), system_features)}\n        \n    return system_dict\n\n\ndef get_system_features_from_folder(folder_path: str    # Path to the folder\n                                   ) -&gt; pd.DataFrame:   # DataFrame containing concatenated system features.\n    \"\"\"\n    Concatenate system DataFrames from all HDF5 files in a folder, preserving original index and adding system column.\n    \"\"\"\n    all_systems = []  # List to store individual system dictionaries\n\n    # Iterate over all files in the folder\n    for file_name in os.listdir(folder_path):\n        file_path = os.path.join(folder_path, file_name)\n\n        # Check if the file is an HDF5 file\n        if file_name.endswith('.h5') or file_name.endswith('.hdf5'):\n            # Get the system dictionary from the HDF5 file\n            system_dict = get_system_data_from_hdf5(file_path)\n            \n            # Add a new entry to the dictionary for the system name\n            system_dict['system'] = os.path.splitext(file_name)[0].split('_')[0]\n            \n            # Append the dictionary to the list\n            all_systems.append(system_dict)\n\n    # Convert the list of dictionaries to a DataFrame\n    concatenated_df = pd.DataFrame(all_systems)\n    \n    return concatenated_df",
    "crumbs": [
      "Dataset"
    ]
  },
  {
    "objectID": "dataset.html#get-classes",
    "href": "dataset.html#get-classes",
    "title": "Dataset",
    "section": "Get Classes",
    "text": "Get Classes\n\nsource\n\nsubstitute_values_from_df\n\n substitute_values_from_df (values:List[Any],\n                            df:pandas.core.frame.DataFrame,\n                            goal_column:str, id_column:str='Id')\n\n*Substitute values in the given list based on the mapping from a DataFrame’s id column to goal column.\nParameters: values (List[Any]): List of values to be substituted. df (pd.DataFrame): DataFrame containing the mapping from id_column to goal_column. goal_column (str): Column in the DataFrame to get the substitution values from. id_column (str, optional): Column in the DataFrame to match the values with. Default is ‘Id’.\nReturns: List[Any]: A list with substituted values from the DataFrame’s goal_column.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nvalues\ntyping.List[typing.Any]\n\nList of values to be substituted.\n\n\ndf\nDataFrame\n\nDataFrame containing the mapping.\n\n\ngoal_column\nstr\n\nColumn in the DataFrame to get the substitution values from.\n\n\nid_column\nstr\nId\nColumn in the DataFrame to match the values with. Default is ‘Id’.\n\n\nReturns\ntyping.List[typing.Any]\n\n\n\n\n\n\nsource\n\n\nget_orbit_classes\n\n get_orbit_classes (values:List[Any])\n\n*Get orbit classes based on the given values and DataFrame. Returns four lists corresponding to ‘Label’, ‘Type’, ‘Subtype’, and ‘Direction’ columns.\nParameters: values (List[Any]): List of values to be substituted.\nReturns: Tuple[List[Any], List[Any], List[Any], List[Any]]: Four lists with substituted values from ‘Label’, ‘Type’, ‘Subtype’, and ‘Direction’ columns.*\n\nvalues = [1,7,23]\nget_orbit_classes(values)\n\n(['S_BN', 'S_L1_A', 'S_L4_LP'],\n ['System-wide', 'L1', 'L4'],\n ['Butterfly', 'Axial', 'Long Period'],\n ['North', 'No specification', 'No specification'])",
    "crumbs": [
      "Dataset"
    ]
  },
  {
    "objectID": "dataset.html#get-periods",
    "href": "dataset.html#get-periods",
    "title": "Dataset",
    "section": "Get Periods",
    "text": "Get Periods\n\nsource\n\nget_periods_of_orbit_dict\n\n get_periods_of_orbit_dict (orbits:Dict[int,numpy.ndarray],\n                            propagated_periods:Dict[int,int],\n                            desired_periods:int)\n\nProcess the orbits to extract the desired periods and print the percentage of the dataset returned.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\norbits\ntyping.Dict[int, numpy.ndarray]\nDictionary of orbits with numerical keys.\n\n\npropagated_periods\ntyping.Dict[int, int]\nDictionary of propagated periods for each orbit.\n\n\ndesired_periods\nint\nDesired number of periods.\n\n\nReturns\ntyping.Dict[int, numpy.ndarray]\nProcessed dictionary of orbits.",
    "crumbs": [
      "Dataset"
    ]
  },
  {
    "objectID": "dataset.html#get-dataset",
    "href": "dataset.html#get-dataset",
    "title": "Dataset",
    "section": "Get Dataset",
    "text": "Get Dataset\n\nFixed Period\n\nsource\n\n\nget_first_period_of_fixed_period_dataset\n\n get_first_period_of_fixed_period_dataset (file_path:str)\n\nLoad and process orbit data from an HDF5 file for the first period.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nfile_path\nstr\nPath to the HDF5 file.\n\n\nReturns\ntyping.Tuple[numpy.ndarray, pandas.core.frame.DataFrame, typing.Dict[str, float]]\n3D numpy array of padded orbits.\n\n\n\n\n\nFixed Step\n\nsource\n\n\nget_full_fixed_step_dataset\n\n get_full_fixed_step_dataset (file_path:str, segment_length:int)\n\nLoad and process orbit data from an HDF5 file, segmenting each orbit into specified length.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nfile_path\nstr\nPath to the HDF5 file.\n\n\nsegment_length\nint\nDesired length of each segment.\n\n\nReturns\ntyping.Tuple[numpy.ndarray, pandas.core.frame.DataFrame, numpy.ndarray, typing.Dict[str, float]]\n3D numpy array of segmented orbits.\n\n\n\n\nsource\n\n\nget_first_period_fixed_step_dataset\n\n get_first_period_fixed_step_dataset (file_path:str, segment_length:int)\n\nLoad and process orbit data from an HDF5 file, segmenting each orbit into specified length.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nfile_path\nstr\nPath to the HDF5 file.\n\n\nsegment_length\nint\nDesired length of each segment.\n\n\nReturns\ntyping.Tuple[numpy.ndarray, pandas.core.frame.DataFrame, numpy.ndarray, typing.Dict[str, float]]\n3D numpy array of segmented orbits.\n\n\n\n\n\nFirst Period\n\nsource\n\n\nget_first_period_dataset\n\n get_first_period_dataset (file_path:str,\n                           segment_length:Union[int,NoneType]=None)\n\nLoad orbit data based on the file path. Calls the appropriate function depending on the name of the file.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfile_path\nstr\n\nPath to the HDF5 file.\n\n\nsegment_length\ntyping.Union[int, NoneType]\nNone\nDesired length of each segment, optional.\n\n\nReturns\ntyping.Tuple[numpy.ndarray, pandas.core.frame.DataFrame, numpy.ndarray, typing.Dict[str, float]]\n\n3D numpy array of orbits.",
    "crumbs": [
      "Dataset"
    ]
  },
  {
    "objectID": "evaluation.html",
    "href": "evaluation.html",
    "title": "Evaluation",
    "section": "",
    "text": "source\n\nevaluate_clustering_multiple_labels\n\n evaluate_clustering_multiple_labels\n                                      (latent_representations:numpy.ndarra\n                                      y, list_of_labels:list,\n                                      clustering_method:str='kmeans',\n                                      label_names:list=None, **kwargs)\n\nEvaluates the clustering quality of the latent representations for one or multiple sets of labels.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlatent_representations\nndarray\n\nThe latent space data.\n\n\nlist_of_labels\nlist\n\nList of true labels or a single true labels array.\n\n\nclustering_method\nstr\nkmeans\nThe clustering algorithm to use (‘kmeans’, ‘gmm’, ‘dbscan’).\n\n\nlabel_names\nlist\nNone\nOptional names for the label sets.\n\n\nkwargs\n\n\n\n\n\nReturns\ndict\n\nReturns a dictionary with clustering metrics.\n\n\n\n\nsource\n\n\nfind_non_matching_elements\n\n find_non_matching_elements (main_array, check_array)\n\n*Finds elements in check_array that are not present in main_array.\nParameters: main_array (numpy.ndarray): The main array with larger set of elements. check_array (numpy.ndarray): The array with elements to check against the main array.\nReturns: numpy.ndarray: Elements in check_array that are not in main_array.*",
    "crumbs": [
      "Evaluation"
    ]
  },
  {
    "objectID": "statistics.html",
    "href": "statistics.html",
    "title": "Statistics",
    "section": "",
    "text": "from orbit_generation.data import get_example_orbit_data\norbit_data = get_example_orbit_data()\norbit_data.shape\n\n(200, 6, 300)",
    "crumbs": [
      "Statistics"
    ]
  },
  {
    "objectID": "statistics.html#simple-statistics",
    "href": "statistics.html#simple-statistics",
    "title": "Statistics",
    "section": "Simple statistics",
    "text": "Simple statistics\n\nsource\n\ncalculate_overall_statistics\n\n calculate_overall_statistics (orbits:numpy.ndarray)\n\n*Calculate the overall min, mean, max, and percentile statistics for each scalar (position and velocity in X, Y, Z) across all time instants and orbits.\nParameters: - orbits (np.ndarray): A numpy array of shape (number_of_orbits, 6, number_of_time_instants) containing orbit data.\nReturns: - Dict[str, Dict[str, float]]: A dictionary with statistics (‘min’, ‘mean’, ‘max’, ‘25%’, ‘50%’, ‘75%’) for each scalar.*\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\norbits\nndarray\nThe array containing orbit data of shape (number_of_orbits, 6, number_of_time_instants).\n\n\nReturns\ntyping.Dict[str, typing.Dict[str, float]]\n\n\n\n\n\norbits = np.array([\n    [[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8]],  # Orbit 1\n    [[4, 4, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9]]   # Orbit 2\n])\n\n# Call the function to calculate statistics\nstats = calculate_overall_statistics(orbits)\n\n# Using test_eq to perform tests\ntest_eq(stats['posx']['min'], 1)\ntest_eq(stats['posx']['mean'], 3)\ntest_eq(stats['posx']['max'], 4)\ntest_eq(stats['posx']['25%'], 2.25)\ntest_eq(stats['posx']['50%'], 3.5)\ntest_eq(stats['posx']['75%'], 4)",
    "crumbs": [
      "Statistics"
    ]
  },
  {
    "objectID": "statistics.html#plot-time",
    "href": "statistics.html#plot-time",
    "title": "Statistics",
    "section": "Plot Time",
    "text": "Plot Time\n\nsource\n\nplot_time_increments\n\n plot_time_increments (orbit_dataset:numpy.ndarray,\n                       orbits_to_plot:List[int]=None,\n                       show_legend:bool=True)\n\n*Plots the time as a function to visualize how it increments for each orbit.\nParameters: orbit_dataset (np.ndarray): A 3D numpy array where the first dimension is the number of orbits, the second dimension contains 7 scalars (time, posx, posy, posz, velx, vely, velz), and the third dimension is the time steps. orbits_to_plot (list[int], optional): List of integers referring to the orbits to plot. If None, plots all orbits. show_legend (bool, optional): Whether to display the legend. Default is True.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\norbit_dataset\nndarray\n\nThe 3D numpy array representing the orbits\n\n\norbits_to_plot\ntyping.List[int]\nNone\nOptional list of integers referring to the orbits to plot\n\n\nshow_legend\nbool\nTrue\nBoolean to control the display of the legend\n\n\nReturns\nNone",
    "crumbs": [
      "Statistics"
    ]
  },
  {
    "objectID": "statistics.html#plot-histograms",
    "href": "statistics.html#plot-histograms",
    "title": "Statistics",
    "section": "Plot Histograms",
    "text": "Plot Histograms\n\nsource\n\nplot_orbit_data_lengths\n\n plot_orbit_data_lengths (orbit_data, key_range=(1, 36072), dimension=0,\n                          bins=30, color='blue', plot=True,\n                          title='Histogram of Orbits Time Steps')\n\n\nsource\n\n\nplot_histograms_position\n\n plot_histograms_position (data:numpy.ndarray, save_path:str=None,\n                           last_time_elements:bool=True)\n\n*Plots histograms for the scalar values (position and velocity in X, Y, Z, and optionally time) across all orbits and time points. Handles arrays with 6 or 7 scalar dimensions, with the 7th being ‘time’.\nParameters: - data (np.ndarray): The orbit data array. - save_path (str, optional): If provided, the plot will be saved to this file path. - last_time_elements (bool): If True, plot only the last elements of the time vectors for the time histogram.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nndarray\n\nThe orbit data array of shape (num_orbits, num_scalars, num_time_points).\n\n\nsave_path\nstr\nNone\nOptional path to save the plot image.\n\n\nlast_time_elements\nbool\nTrue\nWhether to plot only the last elements of the time vectors.\n\n\nReturns\nNone\n\n\n\n\n\n\nplot_histograms_position(orbit_data)\n\n\n\n\n\n\n\n\n\nsource\n\n\nplot_histograms_comparison\n\n plot_histograms_comparison (data1:numpy.ndarray, data2:numpy.ndarray,\n                             label1:str='Dataset 1', label2:str='Dataset\n                             2', save_path:str=None, normalize:bool=False)\n\nPlots histograms for scalar values (position, velocity in X, Y, Z, and optionally time) from two datasets on the same chart with different colors. Supports both 6 and 7 scalar dimensions, with the 7th being ‘time’. Optionally saves the plot to a specified file path and can normalize histograms for relative comparison.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata1\nndarray\n\nFirst orbit data array of shape (num_orbits, num_scalars, num_time_points).\n\n\ndata2\nndarray\n\nSecond orbit data array of shape (num_orbits, num_scalars, num_time_points).\n\n\nlabel1\nstr\nDataset 1\nLabel for the first dataset.\n\n\nlabel2\nstr\nDataset 2\nLabel for the second dataset.\n\n\nsave_path\nstr\nNone\nOptional path to save the plot image.\n\n\nnormalize\nbool\nFalse\nNormalize histograms to show relative frequencies.\n\n\nReturns\nNone\n\n\n\n\n\n\norbit_data1 = orbit_data[:100]\norbit_data2 = orbit_data[100:]\n\nplot_histograms_comparison(orbit_data1, orbit_data2)\n\n\n\n\n\n\n\n\n\norbit_data3 = orbit_data2[:5]\n\nplot_histograms_comparison(orbit_data1, orbit_data3, normalize=True)",
    "crumbs": [
      "Statistics"
    ]
  },
  {
    "objectID": "statistics.html#latent-space",
    "href": "statistics.html#latent-space",
    "title": "Statistics",
    "section": "Latent Space",
    "text": "Latent Space\n\nsource\n\nreduce_dimensions_plot_latent_space\n\n reduce_dimensions_plot_latent_space\n                                      (latent_representations:numpy.ndarra\n                                      y, labels:numpy.ndarray,\n                                      techniques:List[str]=['PCA'],\n                                      n_components:int=2,\n                                      figsize:tuple=(12, 9),\n                                      save_path:Union[str,NoneType]=None,\n                                      many_classes:bool=False,\n                                      grid_view:bool=True, class_names:Uni\n                                      on[List[str],NoneType]=None,\n                                      show_legend:bool=True, **kwargs:Any)\n\nPlots and optionally saves the latent space representations using specified dimensionality reduction techniques. Each technique’s plot is handled in a separate figure, supporting 1D, 2D, or 3D visualizations.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlatent_representations\nndarray\n\nPrecomputed latent representations (numpy array).\n\n\nlabels\nndarray\n\nLabels for the data points, used for coloring in the plot.\n\n\ntechniques\ntyping.List[str]\n[‘PCA’]\nTechniques to use for reduction (‘PCA’, ‘t-SNE’, ‘UMAP’, ‘LDA’).\n\n\nn_components\nint\n2\nNumber of dimensions to reduce to (1, 2, or 3).\n\n\nfigsize\ntuple\n(12, 9)\nSize of the figure for each subplot.\n\n\nsave_path\ntyping.Union[str, NoneType]\nNone\nOptional path to save the plot image.\n\n\nmany_classes\nbool\nFalse\nFlag to use enhanced plotting for many classes.\n\n\ngrid_view\nbool\nTrue\nFlag to plot all techniques in a single grid view.\n\n\nclass_names\ntyping.Union[typing.List[str], NoneType]\nNone\nOptional class names for the legend\n\n\nshow_legend\nbool\nTrue\nFlag to show or hide the legend\n\n\nkwargs\ntyping.Any\n\n\n\n\nReturns\nNone\n\nAdditional keyword arguments for dimensionality reduction methods.\n\n\n\n\n# Reshape data to 2D (num_orbits, 6 * num_time_points)\norbit_data_reshaped = orbit_data.reshape(200, -1)\n\n# Use PCA to reduce to a lower-dimensional space (e.g., 10 dimensions)\npca = PCA(n_components=10)\nlatent_representations = pca.fit_transform(orbit_data_reshaped)\n\nlabels = np.random.randint(0, 5, size=200)  # 5 different classes\n\nreduce_dimensions_plot_latent_space(latent_representations, labels, techniques=['UMAP','LDA'])\n\n\n\n\n\n\n\n\n\nreduce_dimensions_plot_latent_space(latent_representations, labels, techniques=['PCA'], n_components=1, many_classes=True)\n\n\n\n\n\n\n\n\n\nreduce_dimensions_plot_latent_space(latent_representations, labels, techniques=['t-SNE'], n_components=3)",
    "crumbs": [
      "Statistics"
    ]
  },
  {
    "objectID": "statistics.html#latent-space-synthetic-vs-real",
    "href": "statistics.html#latent-space-synthetic-vs-real",
    "title": "Statistics",
    "section": "Latent Space Synthetic vs Real",
    "text": "Latent Space Synthetic vs Real\n\nsource\n\nreduce_dimensions_plot_combined_latent_space\n\n reduce_dimensions_plot_combined_latent_space (real_data:numpy.ndarray,\n                                               synthetic_data:numpy.ndarra\n                                               y, encoder, techniques:List\n                                               [str]=['PCA'],\n                                               n_components:int=2,\n                                               figsize:tuple=(12, 9), save\n                                               _path:Union[str,NoneType]=N\n                                               one,\n                                               many_classes:bool=False,\n                                               grid_view:bool=False,\n                                               **kwargs:Any)\n\nPlots the combined latent space of real and synthetic data using specified dimensionality reduction techniques.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nreal_data\nndarray\n\nReal data samples.\n\n\nsynthetic_data\nndarray\n\nSynthetic data samples generated by a model.\n\n\nencoder\n\n\nEncoder function or model that predicts latent space representations.\n\n\ntechniques\ntyping.List[str]\n[‘PCA’]\nTechniques to use for reduction (‘PCA’, ‘t-SNE’, ‘UMAP’, ‘LDA’).\n\n\nn_components\nint\n2\nNumber of dimensions to reduce to.\n\n\nfigsize\ntuple\n(12, 9)\nSize of the figure for each subplot.\n\n\nsave_path\ntyping.Union[str, NoneType]\nNone\nOptional path to save the plot image.\n\n\nmany_classes\nbool\nFalse\nFlag to use enhanced plotting for many classes.\n\n\ngrid_view\nbool\nFalse\nFlag to plot all techniques in a single grid view.\n\n\nkwargs\ntyping.Any\n\n\n\n\nReturns\nNone\n\nAdditional keyword arguments for dimensionality reduction methods.\n\n\n\n\nsource\n\n\nplot_combined_latent_space_with_labels\n\n plot_combined_latent_space_with_labels (real_data:numpy.ndarray,\n                                         synthetic_data:numpy.ndarray,\n                                         real_labels:numpy.ndarray,\n                                         encoder,\n                                         techniques:List[str]=['PCA'],\n                                         n_components:int=2,\n                                         figsize:tuple=(12, 9), real_color\n                                         s:Union[List[str],NoneType]=None,\n                                         synthetic_color:str='red', save_p\n                                         ath:Union[str,NoneType]=None,\n                                         **kwargs:Any)\n\nPlots the combined latent space of real and synthetic data using specified dimensionality reduction techniques. The real data points are colored according to their labels, and the synthetic data points are overlaid in a new color.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nreal_data\nndarray\n\nReal data samples.\n\n\nsynthetic_data\nndarray\n\nSynthetic data samples generated by a model.\n\n\nreal_labels\nndarray\n\nLabels for the real data samples.\n\n\nencoder\n\n\nEncoder function or model that predicts latent space representations.\n\n\ntechniques\ntyping.List[str]\n[‘PCA’]\nTechniques to use for reduction (‘PCA’, ‘t-SNE’, ‘UMAP’, ‘LDA’).\n\n\nn_components\nint\n2\nNumber of dimensions to reduce to.\n\n\nfigsize\ntuple\n(12, 9)\nSize of the figure for each subplot.\n\n\nreal_colors\ntyping.Union[typing.List[str], NoneType]\nNone\nOptional list of colors for the real data labels. If None, use random colors.\n\n\nsynthetic_color\nstr\nred\nColor for the synthetic data points.\n\n\nsave_path\ntyping.Union[str, NoneType]\nNone\nOptional path to save the plot image.\n\n\nkwargs\ntyping.Any\n\n\n\n\nReturns\nNone\n\nAdditional keyword arguments for dimensionality reduction methods.",
    "crumbs": [
      "Statistics"
    ]
  },
  {
    "objectID": "propagation.html",
    "href": "propagation.html",
    "title": "Propagation",
    "section": "",
    "text": "Propagation implemented by Walther Litteri",
    "crumbs": [
      "Propagation"
    ]
  },
  {
    "objectID": "propagation.html#tolerance-constants",
    "href": "propagation.html#tolerance-constants",
    "title": "Propagation",
    "section": "Tolerance Constants",
    "text": "Tolerance Constants",
    "crumbs": [
      "Propagation"
    ]
  },
  {
    "objectID": "propagation.html#jacobi-constant",
    "href": "propagation.html#jacobi-constant",
    "title": "Propagation",
    "section": "Jacobi Constant",
    "text": "Jacobi Constant\n\nsource\n\njacobi_constant\n\n jacobi_constant (X:numpy.ndarray, mu:float)\n\n*State-dependent Jacobi constant for a given state vector X and gravitational parameter mu.\nParameters: X (np.ndarray): Cartesian state vector with 6 components (x, y, z, xp, yp, zp). mu (float): Gravitational parameter.\nReturns: Tuple[float, float]: Jacobi constant (J) and total energy (E).*\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\nCartesian state vector with 6 components (x, y, z, xp, yp, zp)\n\n\nmu\nfloat\nGravitational parameter\n\n\nReturns\ntyping.Tuple[float, float]\n\n\n\n\n\norbit_data = get_example_orbit_data()\norbit_data.shape\n\n(200, 6, 300)\n\n\n\n# Calculate Jacobi constants and energies for all orbits at all time points\njacobi_constants = np.zeros((200, 300))\ntotal_energies = np.zeros((200, 300))\n\nfor orbit_index in range(200):\n    for time_index in range(300):\n        X = orbit_data[orbit_index, :, time_index]\n        J, E = jacobi_constant(X, EM_MU)\n        jacobi_constants[orbit_index, time_index] = J\n        total_energies[orbit_index, time_index] = E\n\n# Flatten the Jacobi constants array to plot the histogram of all values\njacobi_constants_all = jacobi_constants.flatten()\n\n# Plot histogram of Jacobi constants for all orbits\nplt.figure(figsize=(10, 5))\nplt.hist(jacobi_constants_all, bins=50, color='blue', alpha=0.7)\nplt.title('Histogram of Jacobi Constants for All Orbits')\nplt.xlabel('Jacobi Constant')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()\n\n# Plot histogram of Jacobi constants for the first orbit\njacobi_constants_first_orbit = jacobi_constants[0, :]\n\nplt.figure(figsize=(10, 5))\nplt.hist(jacobi_constants_first_orbit, bins=50, color='green', alpha=0.7)\nplt.title('Histogram of Jacobi Constants for the First Orbit')\nplt.xlabel('Jacobi Constant')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()",
    "crumbs": [
      "Propagation"
    ]
  },
  {
    "objectID": "propagation.html#equations-of-motion-cr3bp",
    "href": "propagation.html#equations-of-motion-cr3bp",
    "title": "Propagation",
    "section": "Equations of motion CR3BP",
    "text": "Equations of motion CR3BP\n\nsource\n\neom_cr3bp\n\n eom_cr3bp (t:float, X:numpy.ndarray, mu:float)\n\n*Equations of motion for the Circular Restricted 3 Body Problem (CR3BP). The form is X_dot = f(t, X, (parameters,)). This formulation is time-independent as it does not depend explicitly on t.\nParameters: t (float): Time variable (not used in this formulation). X (np.ndarray): State vector with 6 components (x, y, z, v_x, v_y, v_z). mu (float): Gravitational parameter.\nReturns: List[float]: Derivatives of the state vector.*\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nt\nfloat\nTime variable (not used in this formulation)\n\n\nX\nndarray\nState vector with 6 components (x, y, z, v_x, v_y, v_z)\n\n\nmu\nfloat\nGravitational parameter\n\n\nReturns\ntyping.List[float]\n\n\n\n\n\n# Select a random orbit from the dataset\nnum_orbits, num_components, num_time_points = orbit_data.shape\nrandom_orbit_index = np.random.randint(0, num_orbits)\nX0 = orbit_data[random_orbit_index, :, 0]\nmu = 0.01215058560962404\nT0 = 2.7430007981241529E+0  # Total time for the propagation, can be adjusted as needed\n\n# Propagate the orbit using solve_ivp\nsol = solve_ivp(eom_cr3bp, [0, T0], X0, args=(mu,), dense_output=True, rtol=1e-9, atol=1e-9, method='Radau')\ntvec = np.linspace(0, T0, num_time_points)\nz = sol.sol(tvec)\n\n# Compute derivatives using eom_cr3bp for a specific state in the propagated orbit\ntime_index = np.random.randint(0, num_time_points - 1)  # Choose a random time index\nt = tvec[time_index]\nX = z[:, time_index]\ncomputed_derivatives = eom_cr3bp(t, X, mu)\n\n# Compare with actual changes in state vector\ndelta_t = tvec[1] - tvec[0]\nactual_derivatives = (z[:, time_index + 1] - z[:, time_index]) / delta_t\n\n# Visualize the actual trajectory and computed derivatives\nfig, axs = plt.subplots(2, 1, figsize=(10, 12))\n\n# Plot the actual trajectory\naxs[0].plot(z[0], z[1], label='Trajectory')\naxs[0].scatter(z[0, time_index], z[1, time_index], color='red', label='Point of Interest')\naxs[0].set_xlabel('x')\naxs[0].set_ylabel('y')\naxs[0].set_title('Trajectory in the XY plane')\naxs[0].legend()\naxs[0].grid(True)\n\n# Plot computed vs. actual derivatives\nlabels = ['x_dot', 'y_dot', 'z_dot', 'x_ddot', 'y_ddot', 'z_ddot']\nwidth = 0.3  # width of the bars\nx = np.arange(len(labels))  # the label locations\n\naxs[1].bar(x - width/2, computed_derivatives, width, label='Computed')\naxs[1].bar(x + width/2, actual_derivatives, width, label='Actual')\naxs[1].set_xticks(x)\naxs[1].set_xticklabels(labels)\naxs[1].set_xlabel('Derivative')\naxs[1].set_ylabel('Value')\naxs[1].set_title('Computed vs Actual Derivatives')\naxs[1].legend()\naxs[1].grid(True)\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Propagation"
    ]
  },
  {
    "objectID": "propagation.html#propagation",
    "href": "propagation.html#propagation",
    "title": "Propagation",
    "section": "Propagation",
    "text": "Propagation\n\nsource\n\nprop_node\n\n prop_node (X:numpy.ndarray, dt:float, mu:float)\n\n*Return the state X after a given time step dt = T_end - T_start.\nParameters: X (np.ndarray): Initial state vector with 6 components (x, y, z, v_x, v_y, v_z). dt (float): Time step for propagation. mu (float): Gravitational parameter.\nReturns: np.ndarray: Final state vector after time step dt.*\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\nInitial state vector with 6 components (x, y, z, v_x, v_y, v_z)\n\n\ndt\nfloat\nTime step for propagation\n\n\nmu\nfloat\nGravitational parameter\n\n\nReturns\nndarray\n\n\n\n\n\n# Select a random orbit from the dataset\nnum_orbits, num_components, num_time_points = orbit_data.shape\nrandom_orbit_index = np.random.randint(0, num_orbits)\nX0 = orbit_data[random_orbit_index, :, 0]\nmu = 0.01215058560962404\ndt = 0.1  # Small time step for propagation\n\n# Propagate the state vector using prop_node\nX_final = prop_node(X0, dt, mu)\n\n# Print the initial and final state vectors\nprint(\"Initial state vector:\", X0)\nprint(\"Final state vector after time step dt:\", X_final)\n\n# To visualize the propagation, we can propagate over multiple time steps and plot the trajectory\nT_total = 2.0  # Total time for propagation\ntime_steps = int(T_total / dt)\ntrajectory = np.zeros((time_steps + 1, 6))\ntrajectory[0] = X0\n\n# Propagate step by step\nX_current = X0\nfor i in range(1, time_steps + 1):\n    X_current = prop_node(X_current, dt, mu)\n    trajectory[i] = X_current\n\n# Plot the trajectory\nfig = plt.figure(figsize=(10, 6))\nax = fig.add_subplot(111, projection='3d')\nax.plot(trajectory[:, 0], trajectory[:, 1], trajectory[:, 2], label='Propagated trajectory')\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.set_zlabel('Z')\nax.set_title('3D Trajectory Propagation using prop_node')\nax.legend()\nplt.show()\n\nInitial state vector: [ 1.10598208  0.         -0.19644872  0.         -0.21942519  0.        ]\nFinal state vector after time step dt: [ 1.10494964 -0.0218485  -0.1947948  -0.02060272 -0.21660401  0.03307732]",
    "crumbs": [
      "Propagation"
    ]
  },
  {
    "objectID": "propagation.html#compute-error",
    "href": "propagation.html#compute-error",
    "title": "Propagation",
    "section": "Compute Error",
    "text": "Compute Error\n\nsource\n\njacobi_test\n\n jacobi_test (X:numpy.ndarray, mu:float)\n\n*Compute the energy error. X can have either 6 columns (state vector) or 7 columns (time + state vector). The returned quantity is the cumulative error with respect to the initial value. If propagation is perfect, err = 0 (or very small).\nParameters: X (np.ndarray): State vector with shape (n, 6) or (n, 7), where n is the number of samples. mu (float): Gravitational parameter.\nReturns: float: Cumulative energy error with respect to the initial value.*\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\nState vector with shape (n, 6) or (n, 7), where n is the number of samples\n\n\nmu\nfloat\nGravitational parameter\n\n\nReturns\nfloat\n\n\n\n\n\nsource\n\n\ndynamics_defect\n\n dynamics_defect (X:numpy.ndarray, mu:float)\n\n*Compute the dynamical defect for the generated time-state sequence. The returned quantity is the cumulative error on the position and velocity components. The overall metrics can be a combination of these two last errors.\nParameters: X (np.ndarray): Time-state vector with shape (n, 7), where the first column is the time vector. mu (float): Gravitational parameter.\nReturns: Tuple[float, float]: Cumulative errors in position and velocity.*\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\nTime-state vector with shape (n, 7), where the first column is the time vector\n\n\nmu\nfloat\nGravitational parameter\n\n\nReturns\ntyping.Tuple[float, float]\n\n\n\n\n\n# Select a random orbit from the dataset\nnum_orbits, num_components, num_time_points = orbit_data.shape\nrandom_orbit_index = np.random.randint(0, num_orbits)\nselected_orbit = orbit_data[random_orbit_index, :, :]\n\n# Add a time column to the state vector for dynamics_defect function\n# Assuming the time steps are evenly spaced and given by the array tvec\ntvec = np.linspace(0, 2.7430007981241529E+0, num_time_points)\ntime_state_vector = np.hstack((tvec.reshape(-1, 1), selected_orbit.T))\n\n# Test jacobi_test function\nenergy_error = jacobi_test(selected_orbit.T, mu)\nprint(\"Cumulative energy error for the selected orbit:\", energy_error)\n\n# Test dynamics_defect function\npos_error, vel_error = dynamics_defect(time_state_vector, mu)\nprint(\"Cumulative position error for the selected orbit:\", pos_error)\nprint(\"Cumulative velocity error for the selected orbit:\", vel_error)\n\n# Visualize the numerically propagated orbit\nvisualize_static_orbits(orbit_data, time_instants=[0, 100, 200, 295], orbit_indices=[random_orbit_index])\n\n# Visualize the cumulative errors calculated\nfig, ax = plt.subplots(figsize=(10, 6))\n\nlabels = ['Cumulative Position Error', 'Cumulative Velocity Error']\nerrors = [pos_error, vel_error]\n\nax.bar(labels, errors, color=['blue', 'green'])\nax.set_ylabel('Error')\nax.set_title('Cumulative Position and Velocity Errors')\nax.grid(True)\n\nplt.tight_layout()\nplt.show()\n\nCumulative energy error for the selected orbit: 0.00023779340992158282\nCumulative position error for the selected orbit: 0.08343900552158802\nCumulative velocity error for the selected orbit: 0.15874181090411918\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsource\n\n\ncalculate_errors\n\n calculate_errors (orbit_data:numpy.ndarray, mu:float,\n                   orbit_indices:List[int]=None,\n                   error_types:List[str]=['position', 'velocity',\n                   'energy'], time_step:Union[float,NoneType]=None,\n                   display_results:bool=True, cumulative:bool=False)\n\nCalculate and return the cumulative error and the average error per time step for the selected orbits together. Optionally, display the evolution of each error as a chart.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\norbit_data\nndarray\n\n3D array of orbit data\n\n\nmu\nfloat\n\nGravitational parameter\n\n\norbit_indices\ntyping.List[int]\nNone\nList of integers referring to the orbits to analyze\n\n\nerror_types\ntyping.List[str]\n[‘position’, ‘velocity’, ‘energy’]\nTypes of errors to calculate\n\n\ntime_step\ntyping.Union[float, NoneType]\nNone\nOptional time step if time dimension is not included\n\n\ndisplay_results\nbool\nTrue\nBoolean to control whether to display the results\n\n\ncumulative\nbool\nFalse\nBoolean to control cumulative or average error\n\n\nReturns\ntyping.Dict[str, typing.Tuple[float, float]]\n\n\n\n\n\n\nerrors = calculate_errors(orbit_data, EM_MU, orbit_indices = [0, 1, 2], time_step=0.00917391571278981)\n\nCumulative position error for selected orbits: 0.2348241595505243\nAverage position error per time step: 0.0007853650821087769\nCumulative velocity error for selected orbits: 0.44235011161515425\nAverage velocity error per time step: 0.0014794318114219206\nCumulative energy error for selected orbits: 0.0006821222552635398\nAverage energy error per time step: 2.2813453353295643e-06",
    "crumbs": [
      "Propagation"
    ]
  }
]