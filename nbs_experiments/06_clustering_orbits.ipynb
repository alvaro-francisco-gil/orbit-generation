{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from orbit_generation.experiment import read_json_to_dataframe, plot_corr_matrix, create_experiment_image_grid\n",
    "from orbit_generation.dataset import get_first_period_dataset\n",
    "from orbit_generation.evaluation import evaluate_metrics_and_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"/orbit-generation/data/orbits_fix_1500/EM_N_fix_1500.h5\"\n",
    "experiments_folder = \"../experiments\"\n",
    "seq_len=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45211, 7, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, orbit_df, labels, system_dict = get_first_period_dataset(file_path=data_path, segment_length=seq_len)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45211,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import pairwise_distances, adjusted_rand_score, normalized_mutual_info_score, silhouette_score\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score, fowlkes_mallows_score\n",
    "from sklearn.metrics import jaccard_score, confusion_matrix\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from fastdtw import fastdtw\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def evaluate_metrics_and_clustering(orbit_data: np.ndarray,\n",
    "                                    true_labels: np.ndarray,\n",
    "                                    distance_metrics: list = None,\n",
    "                                    clustering_algorithms: list = None,\n",
    "                                    evaluation_metrics: list = None,\n",
    "                                    n_clusters: int = None,\n",
    "                                    plot_results: bool = True):\n",
    "    \"\"\"\n",
    "    Evaluates specified distance metrics and clustering algorithms on the given orbit data.\n",
    "    \n",
    "    :param orbit_data: The orbit data as a multivariate time series (shape: [n_samples, n_features, n_time_steps]).\n",
    "    :param true_labels: Array of true labels for the orbit data.\n",
    "    :param distance_metrics: List of strings specifying distance metrics to use. If None, all available metrics are used.\n",
    "    :param clustering_algorithms: List of strings specifying clustering algorithms to use. If None, all available algorithms are used.\n",
    "    :param evaluation_metrics: List of strings specifying evaluation metrics to use. If None, all available metrics are used.\n",
    "    :param n_clusters: Number of clusters for algorithms that require it. If None, it will be inferred from labels.\n",
    "    :param plot_results: If True, plot heatmaps of the results.\n",
    "    :return: A dictionary containing results for all combinations of metrics and clustering algorithms.\n",
    "    \"\"\"\n",
    "\n",
    "    def calculate_clustering_accuracy(true_labels, pred_labels):\n",
    "        cm = confusion_matrix(true_labels, pred_labels)\n",
    "        row_ind, col_ind = linear_sum_assignment(-cm)\n",
    "        return cm[row_ind, col_ind].sum() / np.sum(cm)\n",
    "    \n",
    "    def euclidean_distance(x):\n",
    "        n = x.shape[0]\n",
    "        dist_matrix = np.zeros((n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                dist = np.sqrt(np.sum((x[i] - x[j])**2))\n",
    "                dist_matrix[i, j] = dist_matrix[j, i] = dist\n",
    "        return dist_matrix\n",
    "\n",
    "    def manhattan_distance(x):\n",
    "        n = x.shape[0]\n",
    "        dist_matrix = np.zeros((n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                dist = np.sum(np.abs(x[i] - x[j]))\n",
    "                dist_matrix[i, j] = dist_matrix[j, i] = dist\n",
    "        return dist_matrix\n",
    "\n",
    "    def cosine_distance(x):\n",
    "        n = x.shape[0]\n",
    "        dist_matrix = np.zeros((n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                dot_product = np.sum(x[i] * x[j])\n",
    "                norm_i = np.sqrt(np.sum(x[i]**2))\n",
    "                norm_j = np.sqrt(np.sum(x[j]**2))\n",
    "                dist = 1 - (dot_product / (norm_i * norm_j))\n",
    "                dist_matrix[i, j] = dist_matrix[j, i] = dist\n",
    "        return dist_matrix\n",
    "\n",
    "    def dtw_distance(x):\n",
    "        n = x.shape[0]\n",
    "        dist_matrix = np.zeros((n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                distance, _ = fastdtw(x[i].T, x[j].T)\n",
    "                dist_matrix[i, j] = dist_matrix[j, i] = distance\n",
    "        return dist_matrix\n",
    "\n",
    "    # Define available distance metrics\n",
    "    available_distance_metrics = {\n",
    "        'euclidean': euclidean_distance,\n",
    "        'manhattan': manhattan_distance,\n",
    "        'cosine': cosine_distance,\n",
    "        'dtw': dtw_distance\n",
    "    }\n",
    "    \n",
    "    # Define available clustering algorithms\n",
    "    available_clustering_algorithms = {\n",
    "        'kmeans': KMeans,\n",
    "        'gmm': GaussianMixture,\n",
    "        'dbscan': DBSCAN\n",
    "    }\n",
    "    \n",
    "    # Define available evaluation metrics\n",
    "    available_evaluation_metrics = {\n",
    "        'ARI': adjusted_rand_score,\n",
    "        'NMI': normalized_mutual_info_score,\n",
    "        'Homogeneity': homogeneity_score,\n",
    "        'Completeness': completeness_score,\n",
    "        'V-Measure': v_measure_score,\n",
    "        'FMI': fowlkes_mallows_score,\n",
    "        'Purity': lambda true, pred: np.sum(np.amax(confusion_matrix(true, pred), axis=0)) / np.sum(confusion_matrix(true, pred)),\n",
    "        'Silhouette': silhouette_score,\n",
    "        'Jaccard': lambda true, pred: jaccard_score(true, pred, average='macro'),\n",
    "        'Accuracy': calculate_clustering_accuracy\n",
    "    }\n",
    "    \n",
    "    # If no metrics specified, use all available\n",
    "    if distance_metrics is None:\n",
    "        distance_metrics = list(available_distance_metrics.keys())\n",
    "    \n",
    "    # If no algorithms specified, use all available\n",
    "    if clustering_algorithms is None:\n",
    "        clustering_algorithms = list(available_clustering_algorithms.keys())\n",
    "    \n",
    "    # If no evaluation metrics specified, use all available\n",
    "    if evaluation_metrics is None:\n",
    "        evaluation_metrics = list(available_evaluation_metrics.keys())\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # If n_clusters is not provided, infer it from the labels\n",
    "    if n_clusters is None:\n",
    "        n_clusters = len(np.unique(true_labels))\n",
    "    \n",
    "    # Reshape orbit_data for clustering algorithms\n",
    "    reshaped_orbit_data = orbit_data\n",
    "    \n",
    "    for metric_name in distance_metrics:\n",
    "        if metric_name not in available_distance_metrics:\n",
    "            print(f\"Warning: {metric_name} is not an available distance metric. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Computing {metric_name} distances...\")\n",
    "        metric_func = available_distance_metrics[metric_name]\n",
    "        distance_matrix = metric_func(orbit_data)\n",
    "        \n",
    "        for algo_name in clustering_algorithms:\n",
    "            if algo_name not in available_clustering_algorithms:\n",
    "                print(f\"Warning: {algo_name} is not an available clustering algorithm. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"Clustering with {algo_name}...\")\n",
    "            algo_class = available_clustering_algorithms[algo_name]\n",
    "            \n",
    "            if algo_name == 'dbscan':\n",
    "                # For DBSCAN, we need to estimate eps\n",
    "                distances = squareform(distance_matrix)\n",
    "                eps = np.percentile(distances, 10)  # Use the 10th percentile of distances as eps\n",
    "                clusterer = algo_class(eps=eps, min_samples=5, metric='precomputed')\n",
    "                labels = clusterer.fit_predict(distance_matrix)\n",
    "            elif algo_name == 'kmeans':\n",
    "                clusterer = algo_class(n_clusters=n_clusters, random_state=42)\n",
    "                labels = clusterer.fit_predict(reshaped_orbit_data)\n",
    "            elif algo_name == 'gmm':\n",
    "                clusterer = algo_class(n_components=n_clusters, random_state=42)\n",
    "                labels = clusterer.fit_predict(reshaped_orbit_data)\n",
    "            else:\n",
    "                clusterer = algo_class()  # Use default parameters for other algorithms\n",
    "                labels = clusterer.fit_predict(reshaped_orbit_data)\n",
    "            \n",
    "            # Evaluate clustering\n",
    "            eval_results = {}\n",
    "            for eval_metric in evaluation_metrics:\n",
    "                if eval_metric not in available_evaluation_metrics:\n",
    "                    print(f\"Warning: {eval_metric} is not an available evaluation metric. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                if eval_metric == 'Silhouette':\n",
    "                    unique_labels = np.unique(labels)\n",
    "                    if len(unique_labels) > 1 and len(unique_labels) < len(labels):\n",
    "                        eval_results[eval_metric] = available_evaluation_metrics[eval_metric](reshaped_orbit_data, labels)\n",
    "                    else:\n",
    "                        eval_results[eval_metric] = np.nan\n",
    "                else:\n",
    "                    eval_results[eval_metric] = available_evaluation_metrics[eval_metric](true_labels, labels)\n",
    "            \n",
    "            # Store results\n",
    "            results[f\"{metric_name}_{algo_name}\"] = eval_results\n",
    "    \n",
    "    if plot_results:\n",
    "        plot_metric_heatmaps(results, distance_metrics, clustering_algorithms, evaluation_metrics)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_metric_heatmaps(results, distance_metrics, clustering_algorithms, evaluation_metrics):\n",
    "    \"\"\"\n",
    "    Plot heatmaps for each evaluation metric.\n",
    "    \"\"\"\n",
    "    n_metrics = len(evaluation_metrics)\n",
    "    n_cols = 3\n",
    "    n_rows = (n_metrics + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, metric in enumerate(evaluation_metrics):\n",
    "        data = np.zeros((len(distance_metrics), len(clustering_algorithms)))\n",
    "        for d, distance in enumerate(distance_metrics):\n",
    "            for c, clustering in enumerate(clustering_algorithms):\n",
    "                data[d, c] = results[f\"{distance}_{clustering}\"][metric]\n",
    "        \n",
    "        sns.heatmap(data, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", \n",
    "                    xticklabels=clustering_algorithms, yticklabels=distance_metrics, ax=axes[i])\n",
    "        axes[i].set_title(f\"{metric} Scores\")\n",
    "        axes[i].set_xlabel(\"Clustering Algorithms\")\n",
    "        axes[i].set_ylabel(\"Distance Metrics\")\n",
    "    \n",
    "    # Remove any unused subplots\n",
    "    for i in range(n_metrics, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing euclidean distances...\n",
      "Clustering with kmeans...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. KMeans expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m sampled_data \u001b[38;5;241m=\u001b[39m data[indices]\n\u001b[1;32m      5\u001b[0m sampled_labels \u001b[38;5;241m=\u001b[39m labels[indices]\n\u001b[0;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_metrics_and_clustering\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampled_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "Cell \u001b[0;32mIn[7], line 152\u001b[0m, in \u001b[0;36mevaluate_metrics_and_clustering\u001b[0;34m(orbit_data, true_labels, distance_metrics, clustering_algorithms, evaluation_metrics, n_clusters, plot_results)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m algo_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkmeans\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    151\u001b[0m     clusterer \u001b[38;5;241m=\u001b[39m algo_class(n_clusters\u001b[38;5;241m=\u001b[39mn_clusters, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m--> 152\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[43mclusterer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreshaped_orbit_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m algo_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgmm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    154\u001b[0m     clusterer \u001b[38;5;241m=\u001b[39m algo_class(n_components\u001b[38;5;241m=\u001b[39mn_clusters, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1070\u001b[0m, in \u001b[0;36m_BaseKMeans.fit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \n\u001b[1;32m   1050\u001b[0m \u001b[38;5;124;03m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03m        Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1464\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[1;32m   1439\u001b[0m \n\u001b[1;32m   1440\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1464\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m   1475\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1058\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1056\u001b[0m     )\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m   1064\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1065\u001b[0m         array,\n\u001b[1;32m   1066\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1067\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1068\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1069\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. KMeans expected <= 2."
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "indices = np.random.choice(len(data), num_samples, replace=False)\n",
    "\n",
    "sampled_data = data[indices]\n",
    "sampled_labels = labels[indices]\n",
    "\n",
    "results = evaluate_metrics_and_clustering(sampled_data, sampled_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing euclidean distances...\n",
      "Clustering with kmeans...\n",
      "Clustering with gmm...\n",
      "Clustering with dbscan...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Distance matrix 'X' must be symmetric.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_metrics_and_clustering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 87\u001b[0m, in \u001b[0;36mevaluate_metrics_and_clustering\u001b[0;34m(orbit_data, list_of_labels, distance_metrics, clustering_algorithms, label_names, n_clusters)\u001b[0m\n\u001b[1;32m     83\u001b[0m algo_class \u001b[38;5;241m=\u001b[39m available_algorithms[algo_name]\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m algo_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdbscan\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# For DBSCAN, we need to estimate eps\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[43msquareform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance_matrix\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m distance_matrix\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m distance_matrix\n\u001b[1;32m     88\u001b[0m     eps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(distances, \u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# Use the 10th percentile of distances as eps\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     clusterer \u001b[38;5;241m=\u001b[39m algo_class(eps\u001b[38;5;241m=\u001b[39meps, min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/spatial/distance.py:2326\u001b[0m, in \u001b[0;36msquareform\u001b[0;34m(X, force, checks)\u001b[0m\n\u001b[1;32m   2324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe matrix argument must be square.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checks:\n\u001b[0;32m-> 2326\u001b[0m     \u001b[43mis_valid_dm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[38;5;66;03m# One-side of the dimensions is set here.\u001b[39;00m\n\u001b[1;32m   2329\u001b[0m d \u001b[38;5;241m=\u001b[39m s[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/spatial/distance.py:2432\u001b[0m, in \u001b[0;36mis_valid_dm\u001b[0;34m(D, tol, throw, name, warning)\u001b[0m\n\u001b[1;32m   2430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (D \u001b[38;5;241m==\u001b[39m D\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m   2431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name:\n\u001b[0;32m-> 2432\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistance matrix \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m must be \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2433\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymmetric.\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m%\u001b[39m name)\n\u001b[1;32m   2434\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2435\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistance matrix must be symmetric.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Distance matrix 'X' must be symmetric."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "num_samples = 1000\n",
    "indices = np.random.choice(len(data), num_samples, replace=False)\n",
    "\n",
    "sampled_data = data[indices]\n",
    "sampled_labels = labels[indices]\n",
    "\n",
    "results = evaluate_metrics_and_clustering(sampled_data, sampled_labels)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
