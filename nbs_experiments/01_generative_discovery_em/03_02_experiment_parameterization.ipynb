{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orbit_generation.experiment import generate_parameter_sets, paralelize_notebook_experiment, create_experiments_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Data\n",
    "    'data_used': 'EM_N_fix_1500',\n",
    "    'families_to_discard': 0,\n",
    "    'seq_len': 100,\n",
    "    'feature_dim': 7,\n",
    "    \n",
    "    # Training\n",
    "    'epochs': 50,\n",
    "    'val_split': 0.05,\n",
    "    'batch_size': 32,\n",
    "    'lr': 0.001,\n",
    "    \n",
    "    # Model\n",
    "    'model_name': ['vae_conv5_legit', 'inception_time_wp_vae'],\n",
    "    'latent_dim': [2, 4, 6, 8, 16, 32, 64, 128, 256, 512, 1024],\n",
    "    'beta': [0.2, 0.5],\n",
    "    \n",
    "    # Convergence\n",
    "    'max_iter_convergence': 20,\n",
    "    'input_seq_len_convergence': 1,\n",
    "    \n",
    "    # Evaluation\n",
    "    'samples_to_generate': 100,\n",
    "    'distance_metric': 'manhattan'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Data\n",
    "    'data_used': 'EM_N_fix_1500',\n",
    "    'families_to_discard': [0, 5, 10, 20, 30],\n",
    "    'seq_len': 100,\n",
    "    'feature_dim': 7,\n",
    "    \n",
    "    # Training\n",
    "    'epochs': 50,\n",
    "    'val_split': 0.05,\n",
    "    'batch_size': 32,\n",
    "    'lr': 0.001,\n",
    "    \n",
    "    # Model\n",
    "    'model_name': ['vae_conv5_legit', 'inception_time_wp_vae'],\n",
    "    'latent_dim': [2, 6],\n",
    "    'beta': [0.001, 0.2, 0.5, 1, 1.5, 2, 10],\n",
    "    \n",
    "    # Convergence\n",
    "    'max_iter_convergence': 20,\n",
    "    'input_seq_len_convergence': 1,\n",
    "    \n",
    "    # Evaluation\n",
    "    'samples_to_generate': 100,\n",
    "    'distance_metric': 'euclidean'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_specific_params = {\n",
    "    'vae_conv5_legit': {\n",
    "        'dropout_rate': 0.2\n",
    "    },\n",
    "    'inception_time_wp_vae': {\n",
    "        'n_filters': 32,\n",
    "        'kernel_sizes': [3, 7, 13],\n",
    "        'bottleneck_channels': 32\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_sets = generate_parameter_sets(params, model_specific_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parameter_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 2,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 2,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 4,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 4,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 6,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 6,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 8,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 8,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 16,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 16,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 32,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 32,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 64,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 64,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 128,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 128,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 256,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 256,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 512,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 512,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 1024,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'vae_conv5_legit',\n",
       "  'latent_dim': 1024,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 2,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 2,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 4,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 4,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 6,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 6,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 8,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 8,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 16,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 16,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 32,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 32,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 64,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 64,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 128,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 128,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 256,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 256,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 512,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 512,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.5}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 1024,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.2}},\n",
       " {'data_used': 'EM_N_fix_1500',\n",
       "  'families_to_discard': 0,\n",
       "  'seq_len': 100,\n",
       "  'feature_dim': 7,\n",
       "  'epochs': 50,\n",
       "  'val_split': 0.05,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.001,\n",
       "  'model_name': 'inception_time_wp_vae',\n",
       "  'latent_dim': 1024,\n",
       "  'max_iter_convergence': 20,\n",
       "  'input_seq_len_convergence': 1,\n",
       "  'samples_to_generate': 100,\n",
       "  'distance_metric': 'manhattan',\n",
       "  'model_kwargs': {'n_filters': 32,\n",
       "   'kernel_sizes': [3, 7, 13],\n",
       "   'bottleneck_channels': 32,\n",
       "   'beta': 0.5}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_parameters = {\n",
    "    'want_to_train': True,  # Set this parameter to False if you want to load the model from the folder\n",
    "    'want_to_generate': True,  # Set this parameter to False if you want to load the generation from the folder\n",
    "    'want_to_get_cluster_metrics': True,  # Set this parameter to False if you don't want to calculate clustering metrics\n",
    "    'want_to_perform_convergence': True,  # Set this parameter to False if you don't want to perform convergence\n",
    "    'want_to_discover': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:papermill:/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\n",
      "WARNING:papermill:/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\n",
      "ERROR:root:Error in execution 31: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "ERROR:root:Parameters used: {'data_used': 'EM_N_fix_1500', 'families_to_discard': 0, 'seq_len': 100, 'feature_dim': 7, 'epochs': 50, 'val_split': 0.05, 'batch_size': 32, 'lr': 0.001, 'model_name': 'inception_time_wp_vae', 'latent_dim': 16, 'max_iter_convergence': 20, 'input_seq_len_convergence': 1, 'samples_to_generate': 100, 'distance_metric': 'manhattan', 'model_kwargs': {'n_filters': 32, 'kernel_sizes': [3, 7, 13], 'bottleneck_channels': 32, 'beta': 0.2}, 'want_to_train': True, 'want_to_generate': True, 'want_to_get_cluster_metrics': True, 'want_to_perform_convergence': True, 'want_to_discover': True}\n",
      "ERROR:root:Traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/orbit_generation/experiment.py\", line 387, in execute_parameter_notebook\n",
      "    nb = pm.execute_notebook(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "\n",
      "WARNING:root:An execution failed.\n",
      "ERROR:root:Error in execution 14: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "ERROR:root:Parameters used: {'data_used': 'EM_N_fix_1500', 'families_to_discard': 0, 'seq_len': 100, 'feature_dim': 7, 'epochs': 50, 'val_split': 0.05, 'batch_size': 32, 'lr': 0.001, 'model_name': 'vae_conv5_legit', 'latent_dim': 64, 'max_iter_convergence': 20, 'input_seq_len_convergence': 1, 'samples_to_generate': 100, 'distance_metric': 'manhattan', 'model_kwargs': {'dropout_rate': 0.2, 'beta': 0.5}, 'want_to_train': True, 'want_to_generate': True, 'want_to_get_cluster_metrics': True, 'want_to_perform_convergence': True, 'want_to_discover': True}\n",
      "ERROR:root:Traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/orbit_generation/experiment.py\", line 387, in execute_parameter_notebook\n",
      "    nb = pm.execute_notebook(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "\n",
      "WARNING:root:An execution failed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed7baf4c05940be840ff608dc27c449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/165 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe502ea6df6d40318f5386c8b8f0efb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/165 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:papermill:/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\n",
      "WARNING:papermill:/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\n",
      "ERROR:root:Error in execution 32: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "ERROR:root:Parameters used: {'data_used': 'EM_N_fix_1500', 'families_to_discard': 0, 'seq_len': 100, 'feature_dim': 7, 'epochs': 50, 'val_split': 0.05, 'batch_size': 32, 'lr': 0.001, 'model_name': 'inception_time_wp_vae', 'latent_dim': 16, 'max_iter_convergence': 20, 'input_seq_len_convergence': 1, 'samples_to_generate': 100, 'distance_metric': 'manhattan', 'model_kwargs': {'n_filters': 32, 'kernel_sizes': [3, 7, 13], 'bottleneck_channels': 32, 'beta': 0.5}, 'want_to_train': True, 'want_to_generate': True, 'want_to_get_cluster_metrics': True, 'want_to_perform_convergence': True, 'want_to_discover': True}\n",
      "ERROR:root:Traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/orbit_generation/experiment.py\", line 387, in execute_parameter_notebook\n",
      "    nb = pm.execute_notebook(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "\n",
      "WARNING:root:An execution failed.\n",
      "ERROR:root:Error in execution 33: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "ERROR:root:Parameters used: {'data_used': 'EM_N_fix_1500', 'families_to_discard': 0, 'seq_len': 100, 'feature_dim': 7, 'epochs': 50, 'val_split': 0.05, 'batch_size': 32, 'lr': 0.001, 'model_name': 'inception_time_wp_vae', 'latent_dim': 32, 'max_iter_convergence': 20, 'input_seq_len_convergence': 1, 'samples_to_generate': 100, 'distance_metric': 'manhattan', 'model_kwargs': {'n_filters': 32, 'kernel_sizes': [3, 7, 13], 'bottleneck_channels': 32, 'beta': 0.2}, 'want_to_train': True, 'want_to_generate': True, 'want_to_get_cluster_metrics': True, 'want_to_perform_convergence': True, 'want_to_discover': True}\n",
      "ERROR:root:Traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/orbit_generation/experiment.py\", line 387, in execute_parameter_notebook\n",
      "    nb = pm.execute_notebook(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "\n",
      "WARNING:root:An execution failed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1713edde044616bee4c895e9a9e8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/165 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f519c6103f9945ccaec251199dcb66eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/165 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:papermill:/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\n",
      "WARNING:papermill:/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\n",
      "ERROR:root:Error in execution 34: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "ERROR:root:Parameters used: {'data_used': 'EM_N_fix_1500', 'families_to_discard': 0, 'seq_len': 100, 'feature_dim': 7, 'epochs': 50, 'val_split': 0.05, 'batch_size': 32, 'lr': 0.001, 'model_name': 'inception_time_wp_vae', 'latent_dim': 32, 'max_iter_convergence': 20, 'input_seq_len_convergence': 1, 'samples_to_generate': 100, 'distance_metric': 'manhattan', 'model_kwargs': {'n_filters': 32, 'kernel_sizes': [3, 7, 13], 'bottleneck_channels': 32, 'beta': 0.5}, 'want_to_train': True, 'want_to_generate': True, 'want_to_get_cluster_metrics': True, 'want_to_perform_convergence': True, 'want_to_discover': True}\n",
      "ERROR:root:Traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/orbit_generation/experiment.py\", line 387, in execute_parameter_notebook\n",
      "    nb = pm.execute_notebook(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "\n",
      "WARNING:root:An execution failed.\n",
      "ERROR:root:Error in execution 35: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "ERROR:root:Parameters used: {'data_used': 'EM_N_fix_1500', 'families_to_discard': 0, 'seq_len': 100, 'feature_dim': 7, 'epochs': 50, 'val_split': 0.05, 'batch_size': 32, 'lr': 0.001, 'model_name': 'inception_time_wp_vae', 'latent_dim': 64, 'max_iter_convergence': 20, 'input_seq_len_convergence': 1, 'samples_to_generate': 100, 'distance_metric': 'manhattan', 'model_kwargs': {'n_filters': 32, 'kernel_sizes': [3, 7, 13], 'bottleneck_channels': 32, 'beta': 0.2}, 'want_to_train': True, 'want_to_generate': True, 'want_to_get_cluster_metrics': True, 'want_to_perform_convergence': True, 'want_to_discover': True}\n",
      "ERROR:root:Traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/orbit_generation/experiment.py\", line 387, in execute_parameter_notebook\n",
      "    nb = pm.execute_notebook(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "\n",
      "WARNING:root:An execution failed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41931a3458d423aad1301d2104b25a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/165 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780df01fc5e74e12bfcc44d09b90b105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/165 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:papermill:/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\n",
      "WARNING:papermill:/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\n",
      "ERROR:root:Error in execution 36: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "ERROR:root:Parameters used: {'data_used': 'EM_N_fix_1500', 'families_to_discard': 0, 'seq_len': 100, 'feature_dim': 7, 'epochs': 50, 'val_split': 0.05, 'batch_size': 32, 'lr': 0.001, 'model_name': 'inception_time_wp_vae', 'latent_dim': 64, 'max_iter_convergence': 20, 'input_seq_len_convergence': 1, 'samples_to_generate': 100, 'distance_metric': 'manhattan', 'model_kwargs': {'n_filters': 32, 'kernel_sizes': [3, 7, 13], 'bottleneck_channels': 32, 'beta': 0.5}, 'want_to_train': True, 'want_to_generate': True, 'want_to_get_cluster_metrics': True, 'want_to_perform_convergence': True, 'want_to_discover': True}\n",
      "ERROR:root:Traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/orbit_generation/experiment.py\", line 387, in execute_parameter_notebook\n",
      "    nb = pm.execute_notebook(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "\n",
      "WARNING:root:An execution failed.\n",
      "ERROR:root:Error in execution 37: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "ERROR:root:Parameters used: {'data_used': 'EM_N_fix_1500', 'families_to_discard': 0, 'seq_len': 100, 'feature_dim': 7, 'epochs': 50, 'val_split': 0.05, 'batch_size': 32, 'lr': 0.001, 'model_name': 'inception_time_wp_vae', 'latent_dim': 128, 'max_iter_convergence': 20, 'input_seq_len_convergence': 1, 'samples_to_generate': 100, 'distance_metric': 'manhattan', 'model_kwargs': {'n_filters': 32, 'kernel_sizes': [3, 7, 13], 'bottleneck_channels': 32, 'beta': 0.2}, 'want_to_train': True, 'want_to_generate': True, 'want_to_get_cluster_metrics': True, 'want_to_perform_convergence': True, 'want_to_discover': True}\n",
      "ERROR:root:Traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/orbit_generation/experiment.py\", line 387, in execute_parameter_notebook\n",
      "    nb = pm.execute_notebook(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "\n",
      "WARNING:root:An execution failed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111115d6191d42579080ff6a160d4bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/165 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89b0828e0e14e8c8621268961cc2019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/165 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:papermill:/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\n",
      "WARNING:papermill:/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\n",
      "ERROR:root:Error in execution 38: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "ERROR:root:Parameters used: {'data_used': 'EM_N_fix_1500', 'families_to_discard': 0, 'seq_len': 100, 'feature_dim': 7, 'epochs': 50, 'val_split': 0.05, 'batch_size': 32, 'lr': 0.001, 'model_name': 'inception_time_wp_vae', 'latent_dim': 128, 'max_iter_convergence': 20, 'input_seq_len_convergence': 1, 'samples_to_generate': 100, 'distance_metric': 'manhattan', 'model_kwargs': {'n_filters': 32, 'kernel_sizes': [3, 7, 13], 'bottleneck_channels': 32, 'beta': 0.5}, 'want_to_train': True, 'want_to_generate': True, 'want_to_get_cluster_metrics': True, 'want_to_perform_convergence': True, 'want_to_discover': True}\n",
      "ERROR:root:Traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/orbit_generation/experiment.py\", line 387, in execute_parameter_notebook\n",
      "    nb = pm.execute_notebook(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "\n",
      "WARNING:root:An execution failed.\n",
      "ERROR:root:Error in execution 39: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "ERROR:root:Parameters used: {'data_used': 'EM_N_fix_1500', 'families_to_discard': 0, 'seq_len': 100, 'feature_dim': 7, 'epochs': 50, 'val_split': 0.05, 'batch_size': 32, 'lr': 0.001, 'model_name': 'inception_time_wp_vae', 'latent_dim': 256, 'max_iter_convergence': 20, 'input_seq_len_convergence': 1, 'samples_to_generate': 100, 'distance_metric': 'manhattan', 'model_kwargs': {'n_filters': 32, 'kernel_sizes': [3, 7, 13], 'bottleneck_channels': 32, 'beta': 0.2}, 'want_to_train': True, 'want_to_generate': True, 'want_to_get_cluster_metrics': True, 'want_to_perform_convergence': True, 'want_to_discover': True}\n",
      "ERROR:root:Traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/orbit_generation/experiment.py\", line 387, in execute_parameter_notebook\n",
      "    nb = pm.execute_notebook(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "\n",
      "WARNING:root:An execution failed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8407d911f4544d33aca90c6d63a3d301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/165 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7173adefee4687b6b41071949a654a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/165 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:papermill:/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\n",
      "WARNING:papermill:/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\n",
      "ERROR:root:Error in execution 41: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "ERROR:root:Parameters used: {'data_used': 'EM_N_fix_1500', 'families_to_discard': 0, 'seq_len': 100, 'feature_dim': 7, 'epochs': 50, 'val_split': 0.05, 'batch_size': 32, 'lr': 0.001, 'model_name': 'inception_time_wp_vae', 'latent_dim': 512, 'max_iter_convergence': 20, 'input_seq_len_convergence': 1, 'samples_to_generate': 100, 'distance_metric': 'manhattan', 'model_kwargs': {'n_filters': 32, 'kernel_sizes': [3, 7, 13], 'bottleneck_channels': 32, 'beta': 0.2}, 'want_to_train': True, 'want_to_generate': True, 'want_to_get_cluster_metrics': True, 'want_to_perform_convergence': True, 'want_to_discover': True}\n",
      "ERROR:root:Traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/orbit_generation/experiment.py\", line 387, in execute_parameter_notebook\n",
      "    nb = pm.execute_notebook(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "\n",
      "WARNING:root:An execution failed.\n",
      "ERROR:root:Error in execution 40: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "ERROR:root:Parameters used: {'data_used': 'EM_N_fix_1500', 'families_to_discard': 0, 'seq_len': 100, 'feature_dim': 7, 'epochs': 50, 'val_split': 0.05, 'batch_size': 32, 'lr': 0.001, 'model_name': 'inception_time_wp_vae', 'latent_dim': 256, 'max_iter_convergence': 20, 'input_seq_len_convergence': 1, 'samples_to_generate': 100, 'distance_metric': 'manhattan', 'model_kwargs': {'n_filters': 32, 'kernel_sizes': [3, 7, 13], 'bottleneck_channels': 32, 'beta': 0.5}, 'want_to_train': True, 'want_to_generate': True, 'want_to_get_cluster_metrics': True, 'want_to_perform_convergence': True, 'want_to_discover': True}\n",
      "ERROR:root:Traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/orbit_generation/experiment.py\", line 387, in execute_parameter_notebook\n",
      "    nb = pm.execute_notebook(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "\n",
      "WARNING:root:An execution failed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115a61bf2a8248eaa804062f28867031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/165 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6e2189a3cb4f0191554a6581a75276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/165 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:papermill:/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\n",
      "WARNING:papermill:/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\n",
      "ERROR:root:Error in execution 42: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "ERROR:root:Parameters used: {'data_used': 'EM_N_fix_1500', 'families_to_discard': 0, 'seq_len': 100, 'feature_dim': 7, 'epochs': 50, 'val_split': 0.05, 'batch_size': 32, 'lr': 0.001, 'model_name': 'inception_time_wp_vae', 'latent_dim': 512, 'max_iter_convergence': 20, 'input_seq_len_convergence': 1, 'samples_to_generate': 100, 'distance_metric': 'manhattan', 'model_kwargs': {'n_filters': 32, 'kernel_sizes': [3, 7, 13], 'bottleneck_channels': 32, 'beta': 0.5}, 'want_to_train': True, 'want_to_generate': True, 'want_to_get_cluster_metrics': True, 'want_to_perform_convergence': True, 'want_to_discover': True}\n",
      "ERROR:root:Traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/orbit_generation/experiment.py\", line 387, in execute_parameter_notebook\n",
      "    nb = pm.execute_notebook(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "\n",
      "WARNING:root:An execution failed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f346a9707523463aab29014c2c53542b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/165 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error in execution 43: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "ERROR:root:Parameters used: {'data_used': 'EM_N_fix_1500', 'families_to_discard': 0, 'seq_len': 100, 'feature_dim': 7, 'epochs': 50, 'val_split': 0.05, 'batch_size': 32, 'lr': 0.001, 'model_name': 'inception_time_wp_vae', 'latent_dim': 1024, 'max_iter_convergence': 20, 'input_seq_len_convergence': 1, 'samples_to_generate': 100, 'distance_metric': 'manhattan', 'model_kwargs': {'n_filters': 32, 'kernel_sizes': [3, 7, 13], 'bottleneck_channels': 32, 'beta': 0.2}, 'want_to_train': True, 'want_to_generate': True, 'want_to_get_cluster_metrics': True, 'want_to_perform_convergence': True, 'want_to_discover': True}\n",
      "ERROR:root:Traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/orbit_generation/experiment.py\", line 387, in execute_parameter_notebook\n",
      "    nb = pm.execute_notebook(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "\n",
      "WARNING:root:An execution failed.\n",
      "WARNING:papermill:/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\n",
      "ERROR:root:Error in execution 44: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "ERROR:root:Parameters used: {'data_used': 'EM_N_fix_1500', 'families_to_discard': 0, 'seq_len': 100, 'feature_dim': 7, 'epochs': 50, 'val_split': 0.05, 'batch_size': 32, 'lr': 0.001, 'model_name': 'inception_time_wp_vae', 'latent_dim': 1024, 'max_iter_convergence': 20, 'input_seq_len_convergence': 1, 'samples_to_generate': 100, 'distance_metric': 'manhattan', 'model_kwargs': {'n_filters': 32, 'kernel_sizes': [3, 7, 13], 'bottleneck_channels': 32, 'beta': 0.5}, 'want_to_train': True, 'want_to_generate': True, 'want_to_get_cluster_metrics': True, 'want_to_perform_convergence': True, 'want_to_discover': True}\n",
      "ERROR:root:Traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/orbit_generation/experiment.py\", line 387, in execute_parameter_notebook\n",
      "    nb = pm.execute_notebook(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 131, in execute_notebook\n",
      "    raise_for_execution_errors(nb, output_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/papermill/execute.py\", line 251, in raise_for_execution_errors\n",
      "    raise error\n",
      "papermill.exceptions.PapermillExecutionError: \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [1]\":\n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "Cell In[1], line 8\n",
      "      6 print(torch.cuda.is_available())\n",
      "      7 print(torch.cuda.device_count())\n",
      "----> 8 print(torch.cuda.get_device_name(0))\n",
      "     10 import pandas as pd\n",
      "     11 pd.set_option('display.max_rows', None)\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:493, in get_device_name(device)\n",
      "    481 def get_device_name(device: Optional[_device_t] = None) -> str:\n",
      "    482     r\"\"\"Get the name of a device.\n",
      "    483 \n",
      "    484     Args:\n",
      "   (...)\n",
      "    491         str: the name of the device\n",
      "    492     \"\"\"\n",
      "--> 493     return get_device_properties(device).name\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:523, in get_device_properties(device)\n",
      "    513 def get_device_properties(device: _device_t) -> _CudaDeviceProperties:\n",
      "    514     r\"\"\"Get the properties of a device.\n",
      "    515 \n",
      "    516     Args:\n",
      "   (...)\n",
      "    521         _CudaDeviceProperties: the properties of the device\n",
      "    522     \"\"\"\n",
      "--> 523     _lazy_init()  # will define _get_device_properties\n",
      "    524     device = _get_device_index(device, optional=True)\n",
      "    525     if device < 0 or device >= device_count():\n",
      "\n",
      "File /usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:319, in _lazy_init()\n",
      "    317 if \"CUDA_MODULE_LOADING\" not in os.environ:\n",
      "    318     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
      "--> 319 torch._C._cuda_init()\n",
      "    320 # Some of the queued calls may reentrantly call _lazy_init();\n",
      "    321 # we need to just return without initializing in that case.\n",
      "    322 # However, we must not let any *other* threads in!\n",
      "    323 _tls.is_initializing = True\n",
      "\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "\n",
      "WARNING:root:An execution failed.\n"
     ]
    }
   ],
   "source": [
    "notebook_to_execute = '03_01_generative_discovery.ipynb'\n",
    "output_dir = \"../experiments/03_01_generative_discovery\"\n",
    "checkpoint_file = '../experiments/experiment_checkpoint.json'\n",
    "\n",
    "paralelize_notebook_experiment(\n",
    "    parameter_sets,\n",
    "    notebook_to_execute=notebook_to_execute,\n",
    "    output_dir=output_dir,\n",
    "    checkpoint_file=checkpoint_file,\n",
    "    extra_parameters=extra_parameters,\n",
    "    max_workers=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
