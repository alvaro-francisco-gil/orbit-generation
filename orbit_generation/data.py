"""Necessary scripts to read orbits from different formats"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_data.ipynb.

# %% auto 0
__all__ = ['EPS', 'load_orbit_data', 'load_memmap_array', 'get_orbit_features', 'save_data', 'get_example_orbit_data',
           'sample_orbits', 'TSFeatureWiseScaler', 'TSGlobalScaler']

# %% ../nbs/01_data.ipynb 2
import h5py
from scipy.io import loadmat
import numpy as np
import os
import pandas as pd
from typing import Optional, Any
import torch
import torch.nn.functional as F

# %% ../nbs/01_data.ipynb 3
from unittest.mock import patch, MagicMock
from fastcore.test import test_eq

# %% ../nbs/01_data.ipynb 5
def load_orbit_data(file_path: str,  # The path to the .mat, .h5, or .npy file.
                    variable_name: Optional[str] = None,  # Name of the variable in the .mat file, optional.
                    dataset_path: Optional[str] = None  # Path to the dataset in the .h5 file, optional.
                   ) -> Any:  # The loaded orbit data.
    """
    Load orbit data from MATLAB .mat files, HDF5 .h5 files, or NumPy .npy files.
    """
    if file_path.endswith('.mat'):
        if variable_name is None:
            raise ValueError("variable_name must be provided for .mat files")
        mat = loadmat(file_path)
        if variable_name in mat:
            data = mat[variable_name]
        else:
            raise ValueError(f"{variable_name} not found in {file_path}")

    elif file_path.endswith('.h5'):
        with h5py.File(file_path, 'r') as file:
            if dataset_path is None:
                raise ValueError("dataset_path must be provided for .h5 files")
            if dataset_path in file:
                data = np.array(file[dataset_path])
            else:
                raise ValueError(f"{dataset_path} not found in {file_path}")

    elif file_path.endswith('.npy'):
        data = np.load(file_path)

    else:
        raise ValueError("Unsupported file format. Please provide a .mat, .h5, or .npy file.")
    
    return data

# %% ../nbs/01_data.ipynb 7
def load_memmap_array(file_path: str,  # The path to the .npy file as a string.
                      mode: str = 'c'  # Mode for memory-mapping ('r', 'r+', 'w+', 'c').
                     ) -> np.memmap:   # Returns a memory-mapped array.
    """
    Load a .npy file as a memory-mapped array using numpy.memmap.
    
    Args:
    file_path: A string representing the path to the .npy file.
    mode: The mode in which the file is to be opened. Valid options are:
          - 'r'  : Read-only, no data can be modified.
          - 'r+' : Read/write, modifications to the data are written to the file.
          - 'w+' : Read/write, file is created if it does not exist, overwritten if it does.
          - 'c'  : Copy-on-write, data can be modified in memory but changes are not saved to the file.

    Returns:
    A numpy.memmap object that behaves like a numpy array but with data stored on disk instead of in memory.
    """
    
    # Check if the file exists at the specified path
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"No file found at the specified path: {file_path}")
    
    # Load the .npy file as a memmap object with the specified mode
    return np.load(file_path, mmap_mode=mode)

# %% ../nbs/01_data.ipynb 8
def get_orbit_features(file_path: str,  # The path to the file (can be .mat, .h5, or .npy).
                       variable_name: Optional[str] = None,  # Name of the variable in the .mat file, optional.
                       dataset_path: Optional[str] = None  # Path to the dataset in the .h5 file, optional.
                      ) -> pd.DataFrame:  # DataFrame with detailed orbit features.
    """
    Load orbit feature data from a specified file and convert it to a DataFrame.
    """
    # Load data using the previously defined function that supports .mat, .h5, and .npy files
    orbit_data = load_orbit_data(file_path, variable_name=variable_name, dataset_path=dataset_path)
    
    # Define column labels for the DataFrame
    column_labels = [
        'Orbit Family', 'Initial Position X', 'Initial Position Y', 'Initial Position Z',
        'Initial Velocity X', 'Initial Velocity Y', 'Initial Velocity Z',
        'Jacobi Constant', 'Period', 'Stability Index'
    ]
    
    # Create a DataFrame from the loaded data
    features = pd.DataFrame(orbit_data, columns=column_labels)

    return features

# %% ../nbs/01_data.ipynb 11
def save_data(data: np.ndarray,  # The numpy array data to save.
              file_name: str  # The name of the file to save the data in, including the extension.
             ) -> None:
    """
    Save a numpy array to a file based on the file extension specified in `file_name`.
    Supports saving to HDF5 (.hdf5) or NumPy (.npy) file formats.
    """
    # Extract file extension from file name
    _, file_extension = os.path.splitext(file_name)
    
    if file_extension == '.hdf5':
        # Open a new HDF5 file
        with h5py.File(file_name, 'w') as f:
            # Create a dataset in the file
            f.create_dataset('data', data=data, compression='gzip', compression_opts=9)
    elif file_extension == '.npy':
        # Save the array to a NumPy .npy file
        np.save(file_name, data)
    else:
        # Raise an error for unsupported file types
        raise ValueError("Unsupported file extension. Supported extensions are '.hdf5' or '.npy'.")

# %% ../nbs/01_data.ipynb 14
def get_example_orbit_data():
    """
    Load orbit data from a hardcoded MAT file located in the `data` directory.
    
    The function is specifically designed to load the 'Xarray' variable 
    from the '1_L2_S_200_EM_CR3BP.mat' file. This setup is intended for 
    demonstration or testing purposes, where the data file and the variable 
    of interest are known ahead of time.

    :return: A numpy.ndarray containing the transposed data from the MAT file.
    """
    # Hardcoded file name and variable name
    filename = "example_orbits_1_L2_S_200_EM_CR3BP.mat"
    variable_name = 'Xarray'
    
    # Assuming the notebook or script is executed in a directory at the same level as the `data` folder
    matlab_file_path = '..' + "/data/example_data/" + filename
    
    # Assuming `load_orbit_data` is a predefined function that loads and returns data from the .mat file
    data = load_orbit_data(str(matlab_file_path), variable_name=variable_name)
    # Transpose the data for further use
    data = np.transpose(data, (2, 1, 0))
    
    return data

# %% ../nbs/01_data.ipynb 17
def sample_orbits(orbit_data: np.ndarray,  # Orbit data array
                  sample_spec: dict or int, # Number of samples per class (dict) or total number of samples (int)
                  labels: np.ndarray = None # Optional: Array of labels corresponding to each orbit
                 ) -> (np.ndarray, np.ndarray):
    """
    Randomly sample orbits from the provided dataset.
    
    Parameters:
        orbit_data (np.ndarray): Array of orbit data with shape (num_orbits, 6, num_time_points).
        sample_spec (dict or int): If int, it is the total number of orbits to sample.
                                   If dict, it specifies the number of samples for each class.
        labels (np.ndarray, optional): Array of labels for each orbit.
    
    Returns:
        tuple: A tuple containing the sampled orbit data and corresponding labels (if provided).
    """
    if labels is not None and isinstance(sample_spec, dict):
        # Sampling specified number of orbits for each class
        indices = []
        for label, count in sample_spec.items():
            class_indices = np.where(labels == label)[0]
            if len(class_indices) < count:
                raise ValueError(f"Not enough samples for class {label}. Requested {count}, available {len(class_indices)}.")
            selected_indices = np.random.choice(class_indices, size=count, replace=False)
            indices.extend(selected_indices)
        indices = np.array(indices)
    else:
        # Random sampling without considering classes
        indices = np.random.choice(orbit_data.shape[0], size=sample_spec, replace=False)
    
    # Select the sampled data and labels
    sampled_data = orbit_data[indices]
    sampled_labels = labels[indices] if labels is not None else None
    
    return sampled_data, sampled_labels

# %% ../nbs/01_data.ipynb 20
EPS = 1e-18  # A small epsilon to prevent division by zero

# %% ../nbs/01_data.ipynb 21
class TSFeatureWiseScaler():
    """
    Scales time series data feature-wise using PyTorch tensors.

    Parameters:
    -----------
    feature_range : tuple(float, float), optional
        Tuple representing the minimum and maximum feature values (default is (0, 1)).

    Attributes:
    -----------
    _min_v : float
        Minimum feature value.
    _max_v : float
        Maximum feature value.
    """
    def __init__(self, feature_range: tuple = (0, 1)) -> None:
        assert len(feature_range) == 2
        self._min_v, self._max_v = feature_range

    # X: N x T x D
    def fit(self, X: torch.Tensor) -> "TSFeatureWiseScaler":
        """
        Fits the scaler to the data.
        
        :param X: Input data. Shape: (N, T, D)
        :type X: torch.Tensor
        
        :returns: The fitted scaler object.
        :rtype: TSFeatureWiseScaler
        """
        D = X.shape[2]
        self.mins = torch.zeros(D, device=X.device)
        self.maxs = torch.zeros(D, device=X.device)

        for i in range(D):
            self.mins[i] = torch.min(X[:, :, i])
            self.maxs[i] = torch.max(X[:, :, i])

        return self

    def transform(self, X: torch.Tensor) -> torch.Tensor:
        """
        Transforms the data.
        
        :param X: Input data. Shape: (N, T, D)
        :type X: torch.Tensor
        
        :returns: Scaled data.
        :rtype: torch.Tensor
        """
        return ((X - self.mins) / (self.maxs - self.mins + EPS)) * (self._max_v - self._min_v) + self._min_v

    def inverse_transform(self, X: torch.Tensor) -> torch.Tensor:
        """
        Inverse-transforms the data.
        
        :param X: Scaled data. Shape: (N, T, D)
        :type X: torch.Tensor
        
        :returns: Original data.
        :rtype: torch.Tensor
        """
        X = X - self._min_v
        X = X / (self._max_v - self._min_v)
        X = X * (self.maxs - self.mins + EPS)
        X = X + self.mins
        return X

    def fit_transform(self, X: torch.Tensor) -> torch.Tensor:
        """
        Fits the scaler to the data and transforms it.
        
        :param X: Input data. Shape: (N, T, D)
        :type X: torch.Tensor
        
        :returns: Scaled data.
        :rtype: torch.Tensor
        """
        self.fit(X)
        return self.transform(X)

# %% ../nbs/01_data.ipynb 22
class TSGlobalScaler():
    """
    Scales time series data globally using PyTorch tensors.

    Attributes:
    -----------
    min : float
        Minimum value encountered in the data.
    max : float
        Maximum value encountered in the data.
    """
    def fit(self, X: torch.Tensor) -> "TSGlobalScaler":
        """
        Fits the scaler to the data.
        
        :param X: Input data.
        :type X: torch.Tensor
        
        :returns: The fitted scaler object.
        :rtype: TSGlobalScaler
        """
        self.min = torch.min(X)
        self.max = torch.max(X)
        return self

    def transform(self, X: torch.Tensor) -> torch.Tensor:
        """
        Transforms the data.
        
        :param X: Input data.
        :type X: torch.Tensor
        
        :returns: Scaled X.
        :rtype: torch.Tensor
        """
        return (X - self.min) / (self.max - self.min + EPS)

    def inverse_transform(self, X: torch.Tensor) -> torch.Tensor:
        """
        Inverse-transforms the data.
        
        :param X: Scaled data.
        :type X: torch.Tensor
        
        :returns: Original data.
        :rtype: torch.Tensor
        """
        X = X * (self.max - self.min + EPS)
        X = X + self.min
        return X

    def fit_transform(self, X: torch.Tensor) -> torch.Tensor:
        """
        Fits the scaler to the data and transforms it.
        
        :param X: Input data.
        :type X: torch.Tensor
        
        :returns: Scaled input data X.
        :rtype: torch.Tensor
        """
        self.fit(X)
        return self.transform(X)
