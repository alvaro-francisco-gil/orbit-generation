# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_processing.ipynb.

# %% auto 0
__all__ = ['resample_3d_array', 'average_downsample_3d_array', 'reorder_orbits', 'pad_and_convert_to_3d',
           'segment_and_convert_to_3d', 'add_time_vector_to_orbits']

# %% ../nbs/02_processing.ipynb 2
from scipy.interpolate import interp1d
import numpy as np
from typing import Tuple, Any, List, Dict
from scipy.stats import kendalltau

# %% ../nbs/02_processing.ipynb 9
def resample_3d_array(data: np.ndarray,  # The original 3D array to be resampled.
                      axis: int,         # The axis along which to perform the interpolation.
                      target_size: int   # The new size of the axis after resampling.
                     ) -> np.ndarray:
    """
    Resample a 3D numpy array along a specified axis using linear interpolation.
    """
    if axis not in [0, 1, 2]:  # Validate the axis to ensure it's within the correct range.
        raise ValueError("Invalid axis. Axis must be 0, 1, or 2.")

    old_indices = np.linspace(0, 1, num=data.shape[axis])  # Calculate old indices for interpolation.
    new_indices = np.linspace(0, 1, num=target_size)       # New indices for the target size.

    new_shape = list(data.shape)  # Define the shape of the new data array.
    new_shape[axis] = target_size
    new_data = np.empty(new_shape, dtype=data.dtype)
    
    # Perform interpolation for each slice of the array along the specified axis.
    if axis == 0:
        for i in range(data.shape[1]):
            for j in range(data.shape[2]):
                interpolator = interp1d(old_indices, data[:, i, j], kind='linear')
                new_data[:, i, j] = interpolator(new_indices)
    elif axis == 1:
        for i in range(data.shape[0]):
            for j in range(data.shape[2]):
                interpolator = interp1d(old_indices, data[i, :, j], kind='linear')
                new_data[i, :, j] = interpolator(new_indices)
    else:  # axis == 2
        for i in range(data.shape[0]):
            for j in range(data.shape[1]):
                interpolator = interp1d(old_indices, data[i, j, :], kind='linear')
                new_data[i, j, :] = interpolator(new_indices)

    return new_data

# %% ../nbs/02_processing.ipynb 13
def average_downsample_3d_array(data: np.ndarray,  # The original 3D array to be downsampled.
                                axis: int,         # The axis along which to perform the downsampling (0, 1, or 2).
                                target_size: int   # The desired size of the specified axis after downsampling.
                               ) -> np.ndarray:
    """
    Downsample a 3D numpy array along a specified axis using averaging.
    """
    # Validate the axis to ensure it's within the correct range.
    if axis not in [0, 1, 2]:
        raise ValueError("Invalid axis. Axis must be 0, 1, or 2.")

    # Calculate the number of elements in each block that will be averaged.
    original_size = data.shape[axis]
    block_size = original_size / target_size

    # Define the shape of the new, downsampled data array.
    new_shape = list(data.shape)
    new_shape[axis] = target_size
    new_data = np.empty(new_shape, dtype=data.dtype)

    # Perform averaging along the specified axis.
    if axis == 0:
        for i in range(target_size):
            start_idx = int(i * block_size)
            end_idx = int((i + 1) * block_size)
            new_data[i, :, :] = np.mean(data[start_idx:end_idx, :, :], axis=0)  # Average blocks along the 0th axis.
    elif axis == 1:
        for i in range(target_size):
            start_idx = int(i * block_size)
            end_idx = int((i + 1) * block_size)
            new_data[:, i, :] = np.mean(data[:, start_idx:end_idx, :], axis=1)  # Average blocks along the 1st axis.
    else:  # axis == 2
        for i in range(target_size):
            start_idx = int(i * block_size)
            end_idx = int((i + 1) * block_size)
            new_data[:, :, i] = np.mean(data[:, :, start_idx:end_idx], axis=2)  # Average blocks along the 2nd axis.

    return new_data

# %% ../nbs/02_processing.ipynb 16
def reorder_orbits(orbit_dataset: np.ndarray  # The original 3D numpy array representing the orbits.
                  ) -> Tuple[np.ndarray,      # 3D numpy array of reordered orbits.
                             Dict[str, float]]: # Dictionary of metrics indicating the quality of the original ordering.
    """
    Reorders the time steps of each orbit in the dataset such that the time values are always incrementally increasing.
    Returns the reordered dataset and metrics indicating the quality of the original ordering.
    """
    num_orbits, num_scalars, num_timesteps = orbit_dataset.shape
    reordered_dataset = np.zeros_like(orbit_dataset)
    total_disorder_metric = 0
    total_correct_order = 0
    total_inversions = 0
    total_kendall_tau = 0
    total_timesteps = num_orbits * (num_timesteps - 1)

    for i in range(num_orbits):
        # Extract the time steps and corresponding data for the current orbit
        orbit_data = orbit_dataset[i]
        time_steps = orbit_data[0]
        
        # Calculate the disorder metric for the current orbit
        sorted_indices = np.argsort(time_steps)
        disorder_metric = np.sum(np.abs(sorted_indices - np.arange(len(time_steps))))
        correct_order = np.sum(np.diff(time_steps) >= 0)
        
        # Calculate the number of inversions
        inversions = sum(1 for j in range(num_timesteps) for k in range(j + 1, num_timesteps) if time_steps[j] > time_steps[k])
        
        # Calculate Kendall's tau distance
        tau, _ = kendalltau(time_steps, np.sort(time_steps))
        
        # Accumulate the metrics
        total_disorder_metric += disorder_metric
        total_correct_order += correct_order
        total_inversions += inversions
        total_kendall_tau += 1 - tau  # 1 - tau gives the distance (0 means perfect agreement, 1 means perfect disagreement)
        
        # Reorder the orbit data based on the sorted indices
        reordered_orbit_data = orbit_data[:, sorted_indices]
        
        # Store the reordered orbit data in the new dataset
        reordered_dataset[i] = reordered_orbit_data

    average_disorder_metric = total_disorder_metric / num_orbits
    percentage_correct_order = (total_correct_order / total_timesteps) * 100
    average_inversions = total_inversions / num_orbits
    average_kendall_tau = total_kendall_tau / num_orbits

    metrics = {
        'average_disorder_metric': average_disorder_metric,
        'percentage_correct_order': percentage_correct_order,
        'average_inversions': average_inversions,
        'average_kendall_tau': average_kendall_tau
    }
    
    return reordered_dataset, metrics

# %% ../nbs/02_processing.ipynb 19
def pad_and_convert_to_3d(orbits: Dict[int, np.ndarray],     # Dictionary of orbits with numerical keys.
                          timesteps: int                     # Desired number of timesteps.
                         ) -> np.ndarray:                    # 3D numpy array of padded orbits.
    """
    Truncate and pad each orbit to a uniform length and convert to a 3D numpy array.
    """
    # Initialize a list to store the padded arrays
    padded_arrays = []

    # Iterate over each orbit in the dictionary
    for key, orbit in orbits.items():
        # Determine the number of timesteps to take from the orbit
        num_timesteps = min(timesteps, orbit.shape[1])

        # Take the first num_timesteps from the orbit
        truncated_orbit = orbit[:, :num_timesteps]

        # Pad the truncated orbit to have length timesteps in the final dimension
        padded_orbit = np.pad(truncated_orbit, ((0, 0), (0, timesteps - num_timesteps)))

        # Add the padded orbit to the list
        padded_arrays.append(padded_orbit)

    # Convert the list of padded arrays to a 3D numpy array and return it
    return np.stack(padded_arrays)

# %% ../nbs/02_processing.ipynb 20
def segment_and_convert_to_3d(orbits: Dict[int, np.ndarray],  # Dictionary of orbits with numerical keys.
                              segment_length: int             # Desired length of each segment.
                             ) -> Tuple[np.ndarray,           # 3D numpy array of segments.
                                        List[int]]:           # List of IDs representing each new segment.
    """
    Divide each orbit into segments of a given length and convert to a 3D numpy array.
    """
    
    # Initialize a list to store the segments and their corresponding IDs
    segments = []
    segment_ids = []

    # Iterate over each orbit in the dictionary
    for key, orbit in orbits.items():
        # Determine the number of complete segments that can be taken from the orbit
        num_segments = orbit.shape[1] // segment_length

        # Iterate over the number of complete segments
        for i in range(num_segments):
            # Take the segment of the desired length
            segment = orbit[:, i*segment_length:(i+1)*segment_length]

            # Add the segment to the list
            segments.append(segment)

            # Add the corresponding ID to the list
            segment_ids.append(key)

    # Convert the list of segments to a 3D numpy array
    segments_3d = np.stack(segments)

    return segments_3d, segment_ids

# %% ../nbs/02_processing.ipynb 23
def add_time_vector_to_orbits(orbits: Dict[int, np.ndarray],  # Dictionary of orbits with numerical keys.
                              propagated_periods: List[float], # List of propagated periods for each orbit.
                              periods: List[float]            # List of periods for each orbit.
                             ) -> Dict[int, np.ndarray]:      # Dictionary of updated orbits with time vectors added.
    """
    Add a time vector to each orbit in the dictionary.
    """
    # Create a new dictionary to store the updated orbits
    updated_orbits = {}

    # Iterate over each orbit in the dictionary
    for key, orbit in orbits.items():
        # Extract the propagated_periods and period for this orbit using the key as index
        propagated_period = propagated_periods[key]
        period = periods[key]

        # Compute the new time vector
        tvec = np.linspace(0, propagated_period * period, orbit.shape[1])

        # Add the time vector as the first vector in the orbit array
        updated_orbit = np.vstack([tvec, orbit])

        # Add the updated orbit to the new dictionary
        updated_orbits[key] = updated_orbit

    return updated_orbits
