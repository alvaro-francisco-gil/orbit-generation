{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Exploration\n",
    "\n",
    "> Scripts to explore the Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp latent_exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from scipy.spatial import distance\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq, test_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def linear_interpolation(z1, z2, steps):\n",
    "    \"\"\"Perform linear interpolation between two points.\"\"\"\n",
    "    return np.linspace(z1, z2, steps)\n",
    "\n",
    "def slerp(z1, z2, steps):\n",
    "    \"\"\"Perform spherical linear interpolation between two points.\"\"\"\n",
    "    z1_norm = z1 / np.linalg.norm(z1)\n",
    "    z2_norm = z2 / np.linalg.norm(z2)\n",
    "    dot_product = np.clip(np.dot(z1_norm, z2_norm), -1.0, 1.0)\n",
    "    omega = np.arccos(dot_product)\n",
    "    if omega == 0:\n",
    "        return np.tile(z1, (steps, 1))\n",
    "    sin_omega = np.sin(omega)\n",
    "    return np.array([\n",
    "        (np.sin((1 - t) * omega) / sin_omega) * z1 +\n",
    "        (np.sin(t * omega) / sin_omega) * z2\n",
    "        for t in np.linspace(0, 1, steps)\n",
    "    ])\n",
    "\n",
    "def interpolate_sample(centroids, granularity=10, variance=0.0):\n",
    "    \"\"\"\n",
    "    Perform interpolating sampling between all pairs of centroids.\n",
    "\n",
    "    Parameters:\n",
    "    - centroids (np.ndarray): Array of shape (n_centroids, latent_dim).\n",
    "    - granularity (int): Number of interpolation steps between each pair.\n",
    "    - variance (float): Standard deviation for Gaussian sampling.\n",
    "\n",
    "    Returns:\n",
    "    - samples (np.ndarray): Array of sampled points.\n",
    "    \"\"\"\n",
    "    latent_dim = centroids.shape[1]\n",
    "    samples = []\n",
    "\n",
    "    for z1, z2 in combinations(centroids, 2):\n",
    "        if latent_dim <= 2:\n",
    "            interpolated = linear_interpolation(z1, z2, granularity)\n",
    "        else:\n",
    "            interpolated = slerp(z1, z2, granularity)\n",
    "        \n",
    "        if variance > 0:\n",
    "            noise = np.random.normal(0, variance, interpolated.shape)\n",
    "            interpolated += noise\n",
    "        \n",
    "        samples.append(interpolated)\n",
    "    \n",
    "    if samples:\n",
    "        return np.vstack(samples)\n",
    "    else:\n",
    "        return np.empty((0, latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example centroids for a 2-dimensional latent space\n",
    "centroids = np.array([\n",
    "    [1.0, 2.0],\n",
    "    [3.0, 4.0],\n",
    "    [5.0, 6.0]\n",
    "])\n",
    "\n",
    "granularity = 3\n",
    "variance = 0.0  # Set to 0 for deterministic interpolation\n",
    "\n",
    "sampled_points = interpolate_sample(centroids, granularity, variance)\n",
    "\n",
    "# Define the expected sampled points manually for granularity=3\n",
    "expected_data = np.array([\n",
    "    [1.0, 2.0],\n",
    "    [2.0, 3.0],\n",
    "    [3.0, 4.0],\n",
    "    [1.0, 2.0],\n",
    "    [3.0, 4.0],\n",
    "    [5.0, 6.0],\n",
    "    [3.0, 4.0],\n",
    "    [4.0, 5.0],\n",
    "    [5.0, 6.0]\n",
    "])\n",
    "\n",
    "# Check the sampled points against the expected data\n",
    "test_eq(sampled_points, expected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def compute_centroids(latents, labels, method='mean', return_labels=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute the centroid of each class in the latent space using various methods.\n",
    "    \n",
    "    Parameters:\n",
    "    - latents (np.ndarray): Array of shape (n_samples, latent_dim).\n",
    "    - labels (np.ndarray): Array of shape (n_samples,) with class labels.\n",
    "    - method (str): Method to compute centroids. Options: 'mean', 'median', 'geom_median', 'medoid', 'trimmed_mean', 'gmm'.\n",
    "    - return_labels (bool): If True, also return the unique labels corresponding to the centroids.\n",
    "    - kwargs: Additional arguments for specific methods.\n",
    "    \n",
    "    Returns:\n",
    "    - centroids (np.ndarray): Array of shape (n_classes, latent_dim) containing centroids.\n",
    "    - unique_labels (np.ndarray, optional): Array of shape (n_classes,) with unique class labels.\n",
    "    \"\"\"\n",
    "    unique_labels = np.unique(labels)\n",
    "    centroids = []\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        class_points = latents[labels == label]\n",
    "        \n",
    "        if method == 'mean':\n",
    "            centroid = class_points.mean(axis=0)\n",
    "        \n",
    "        elif method == 'median':\n",
    "            centroid = np.median(class_points, axis=0)\n",
    "        \n",
    "        elif method == 'geom_median':\n",
    "            centroid = geometric_median(class_points, tol=kwargs.get('tol', 1e-5))\n",
    "        \n",
    "        elif method == 'medoid':\n",
    "            centroid = compute_medoid(class_points)\n",
    "        \n",
    "        elif method == 'trimmed_mean':\n",
    "            trim_ratio = kwargs.get('trim_ratio', 0.1)\n",
    "            centroid = trimmed_mean_centroid(class_points, trim_ratio=trim_ratio)\n",
    "        \n",
    "        elif method == 'gmm':\n",
    "            n_components = kwargs.get('n_components', 1)\n",
    "            if n_components != 1:\n",
    "                raise ValueError(\"GMM-based centroids require n_components=1 for simple centroid computation.\")\n",
    "            gmm = GaussianMixture(n_components=1)\n",
    "            gmm.fit(class_points)\n",
    "            centroid = gmm.means_[0]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported centroid computation method: {method}\")\n",
    "        \n",
    "        centroids.append(centroid)\n",
    "    \n",
    "    centroids = np.array(centroids)\n",
    "    \n",
    "    if return_labels:\n",
    "        return centroids, unique_labels\n",
    "    else:\n",
    "        return centroids\n",
    "\n",
    "# Auxiliary Functions\n",
    "def geometric_median(points, tol=1e-5):\n",
    "    y = np.mean(points, axis=0)\n",
    "    while True:\n",
    "        D = distance.cdist([y], points, 'euclidean')[0]\n",
    "        nonzeros = (D != 0)\n",
    "        \n",
    "        if not np.any(nonzeros):\n",
    "            return y\n",
    "        \n",
    "        D = D[nonzeros]\n",
    "        points_nonzero = points[nonzeros]\n",
    "        y1 = np.sum(points_nonzero / D[:, np.newaxis], axis=0) / np.sum(1 / D)\n",
    "        \n",
    "        if np.linalg.norm(y - y1) < tol:\n",
    "            return y1\n",
    "        y = y1\n",
    "\n",
    "def compute_medoid(points):\n",
    "    dist_matrix = distance.cdist(points, points, 'euclidean')\n",
    "    medoid_index = np.argmin(dist_matrix.sum(axis=1))\n",
    "    return points[medoid_index]\n",
    "\n",
    "def trimmed_mean_centroid(points, trim_ratio=0.1):\n",
    "    trimmed_points = []\n",
    "    for dim in range(points.shape[1]):\n",
    "        sorted_dim = np.sort(points[:, dim])\n",
    "        trim = int(trim_ratio * len(sorted_dim))\n",
    "        trimmed_dim = sorted_dim[trim: -trim]\n",
    "        trimmed_points.append(trimmed_dim)\n",
    "    return np.array([np.mean(dim) for dim in trimmed_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# Define example latent representations\n",
    "latents = np.array([\n",
    "    [1.0, 2.0],\n",
    "    [1.5, -1.0],\n",
    "    [2.0, -1.0],\n",
    "    [1.2, 2.2],\n",
    "    [1.4, 1.8],\n",
    "    [1.7, 7.0]\n",
    "])\n",
    "\n",
    "# Define corresponding labels\n",
    "labels = np.array([1,1,1,2,2,3])\n",
    "\n",
    "# Compute centroids without returning labels\n",
    "centroids = compute_centroids(latents, labels)\n",
    "\n",
    "# Define the expected centroids\n",
    "expected_centroids = np.array([\n",
    "    [1.5, 0.],        # Centroid for label 1\n",
    "    [1.3, 2.],        # Centroid for label 2\n",
    "    [1.7, 7.]         # Centroid for label 2\n",
    "])\n",
    "\n",
    "# Check the computed centroids against the expected data\n",
    "test_close(centroids, expected_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
