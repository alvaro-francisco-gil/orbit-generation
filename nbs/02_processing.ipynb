{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing\n",
    "\n",
    "> Necessary scripts to read orbits from different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "from typing import Tuple, Any, List, Dict\n",
    "from scipy.stats import kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export   \n",
    "def downsample_3d_array(data: np.ndarray,     # The original 3D array to be downsampled.\n",
    "                        axis: int,            # The axis along which to perform the downsampling.\n",
    "                        hop: int = None,      # The interval at which to keep elements.\n",
    "                        target_size: int = None  # The target size for the specified axis.\n",
    "                       ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Downsample a 3D numpy array along a specified axis by keeping only every hop-th element or \n",
    "    to a target size.\n",
    "    \"\"\"\n",
    "    if axis not in [0, 1, 2]:  # Validate the axis to ensure it's within the correct range.\n",
    "        raise ValueError(\"Invalid axis. Axis must be 0, 1, or 2.\")\n",
    "\n",
    "    if hop is not None and hop < 1:\n",
    "        raise ValueError(\"Hop must be a positive integer greater than or equal to 1.\")\n",
    "\n",
    "    if target_size is not None and (target_size < 1 or target_size > data.shape[axis]):\n",
    "        raise ValueError(\"Target size must be a positive integer and less than or equal to the size of the axis.\")\n",
    "    \n",
    "    if hop is not None:\n",
    "        # Create slices for each axis\n",
    "        slices = [slice(None)] * 3\n",
    "        slices[axis] = slice(None, None, hop)\n",
    "        # Use the slices to downsample the array\n",
    "        downsampled_data = data[tuple(slices)]\n",
    "    \n",
    "    elif target_size is not None:\n",
    "        # Calculate the hop based on the target size\n",
    "        original_size = data.shape[axis]\n",
    "        hop = max(original_size // target_size, 1)\n",
    "        slices = [slice(None)] * 3\n",
    "        slices[axis] = slice(None, None, hop)\n",
    "        downsampled_data = data[tuple(slices)]\n",
    "        # Adjust if the resulting size does not match the target size due to rounding\n",
    "        if downsampled_data.shape[axis] != target_size:\n",
    "            indices = np.round(np.linspace(0, downsampled_data.shape[axis] - 1, target_size)).astype(int)\n",
    "            downsampled_data = np.take(downsampled_data, indices, axis=axis)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Either hop or target_size must be specified.\")\n",
    "    \n",
    "    return downsampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| test downsample_3d_array\n",
    "\n",
    "# Original 3D array\n",
    "data = np.array([\n",
    "    [[1, 2], [3, 4]],\n",
    "    [[5, 6], [7, 8]],\n",
    "    [[9, 10], [11, 12]],\n",
    "    [[13, 14], [15, 16]]\n",
    "])\n",
    "\n",
    "# Downsampling from 4 to 2 along the first axis\n",
    "target_size = 2\n",
    "\n",
    "# Perform downsampling\n",
    "downsampled_data = downsample_3d_array(data, axis=0, target_size=target_size)\n",
    "\n",
    "# Expected results by selecting every 2nd slice\n",
    "expected_data = np.array([\n",
    "    [[1, 2], [3, 4]],   # 1st slice\n",
    "    [[9, 10], [11, 12]] # 3rd slice\n",
    "])\n",
    "\n",
    "# Check the downsampled data against expected data\n",
    "test_eq(downsampled_data, expected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def resample_3d_array(data: np.ndarray,  # The original 3D array to be resampled.\n",
    "                      axis: int,         # The axis along which to perform the interpolation.\n",
    "                      target_size: int   # The new size of the axis after resampling.\n",
    "                     ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Resample a 3D numpy array along a specified axis using linear interpolation.\n",
    "    \"\"\"\n",
    "    if axis not in [0, 1, 2]:  # Validate the axis to ensure it's within the correct range.\n",
    "        raise ValueError(\"Invalid axis. Axis must be 0, 1, or 2.\")\n",
    "\n",
    "    old_indices = np.linspace(0, 1, num=data.shape[axis])  # Calculate old indices for interpolation.\n",
    "    new_indices = np.linspace(0, 1, num=target_size)       # New indices for the target size.\n",
    "\n",
    "    new_shape = list(data.shape)  # Define the shape of the new data array.\n",
    "    new_shape[axis] = target_size\n",
    "    new_data = np.empty(new_shape, dtype=data.dtype)\n",
    "    \n",
    "    # Perform interpolation for each slice of the array along the specified axis.\n",
    "    if axis == 0:\n",
    "        for i in range(data.shape[1]):\n",
    "            for j in range(data.shape[2]):\n",
    "                interpolator = interp1d(old_indices, data[:, i, j], kind='linear')\n",
    "                new_data[:, i, j] = interpolator(new_indices)\n",
    "    elif axis == 1:\n",
    "        for i in range(data.shape[0]):\n",
    "            for j in range(data.shape[2]):\n",
    "                interpolator = interp1d(old_indices, data[i, :, j], kind='linear')\n",
    "                new_data[i, :, j] = interpolator(new_indices)\n",
    "    else:  # axis == 2\n",
    "        for i in range(data.shape[0]):\n",
    "            for j in range(data.shape[1]):\n",
    "                interpolator = interp1d(old_indices, data[i, j, :], kind='linear')\n",
    "                new_data[i, j, :] = interpolator(new_indices)\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| test resample_3d_array\n",
    "\n",
    "# Original 3D array\n",
    "data = np.array([\n",
    "    [[1, 2], [3, 4]],\n",
    "    [[5, 6], [7, 8]],\n",
    "    [[9, 10], [11, 12]],\n",
    "    [[13, 14], [15, 16]]\n",
    "])\n",
    "\n",
    "# Downsampling from 4 to 2 along the first axis\n",
    "target_size = 3\n",
    "\n",
    "# Perform resampling\n",
    "resampled_data = resample_3d_array(data, axis=0, target_size=target_size)\n",
    "\n",
    "# Expected results by true linear interpolation\n",
    "expected_data = np.array([\n",
    "    [[1, 2], [3, 4]],  # 1st slice\n",
    "    [[7, 8], [9, 10]],  # Interpolation between 2nd and 3rd slices (mean in this case)\n",
    "    [[13, 14], [15, 16]]  # 4st slice\n",
    "])\n",
    "# Check the resampled data against expected data\n",
    "test_eq(resampled_data, expected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| test resample_3d_array\n",
    "def test_resample_3d_array():\n",
    "    # Simulate get_example_orbit_data() by creating a 3D array with a predictable gradient\n",
    "    x = np.linspace(0, 1, 200)\n",
    "    y = np.linspace(0, 1, 6)\n",
    "    z = np.linspace(0, 1, 300)\n",
    "    data = np.meshgrid(x, y, z, indexing='ij')\n",
    "    data = np.array(data).sum(axis=0)\n",
    "\n",
    "    # Target new size for the axis\n",
    "    target_size = 100  # example target size for the test\n",
    "\n",
    "    # Test each axis\n",
    "    for axis in range(3):\n",
    "        # Resample the array\n",
    "        resampled_data = resample_3d_array(data, axis, target_size)\n",
    "\n",
    "        # Check the shape of the output\n",
    "        expected_shape = list(data.shape)\n",
    "        expected_shape[axis] = target_size\n",
    "        test_eq(resampled_data.shape, tuple(expected_shape))\n",
    "\n",
    "        # Verify the correctness of the interpolation by using more direct interpolation checks\n",
    "        original_indices = np.linspace(0, data.shape[axis] - 1, data.shape[axis])\n",
    "        new_indices = np.linspace(0, data.shape[axis] - 1, target_size)\n",
    "        for i in new_indices:\n",
    "            original_slice = np.take(data, indices=int(np.round(i)), axis=axis)\n",
    "            interpolated_slice = np.take(resampled_data, indices=int(np.round((i / (data.shape[axis] - 1)) * (target_size - 1))), axis=axis)\n",
    "            # Verify that the mean of the interpolated slice is close to the original slice mean within a tolerance\n",
    "            test_eq(np.isclose(np.mean(interpolated_slice), np.mean(original_slice), atol=0.1), True)\n",
    "\n",
    "# Invoke the test\n",
    "test_resample_3d_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def average_downsample_3d_array(data: np.ndarray,  # The original 3D array to be downsampled.\n",
    "                                axis: int,         # The axis along which to perform the downsampling (0, 1, or 2).\n",
    "                                target_size: int   # The desired size of the specified axis after downsampling.\n",
    "                               ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Downsample a 3D numpy array along a specified axis using averaging.\n",
    "    \"\"\"\n",
    "    # Validate the axis to ensure it's within the correct range.\n",
    "    if axis not in [0, 1, 2]:\n",
    "        raise ValueError(\"Invalid axis. Axis must be 0, 1, or 2.\")\n",
    "\n",
    "    # Calculate the number of elements in each block that will be averaged.\n",
    "    original_size = data.shape[axis]\n",
    "    block_size = original_size / target_size\n",
    "\n",
    "    # Define the shape of the new, downsampled data array.\n",
    "    new_shape = list(data.shape)\n",
    "    new_shape[axis] = target_size\n",
    "    new_data = np.empty(new_shape, dtype=data.dtype)\n",
    "\n",
    "    # Perform averaging along the specified axis.\n",
    "    if axis == 0:\n",
    "        for i in range(target_size):\n",
    "            start_idx = int(i * block_size)\n",
    "            end_idx = int((i + 1) * block_size)\n",
    "            new_data[i, :, :] = np.mean(data[start_idx:end_idx, :, :], axis=0)  # Average blocks along the 0th axis.\n",
    "    elif axis == 1:\n",
    "        for i in range(target_size):\n",
    "            start_idx = int(i * block_size)\n",
    "            end_idx = int((i + 1) * block_size)\n",
    "            new_data[:, i, :] = np.mean(data[:, start_idx:end_idx, :], axis=1)  # Average blocks along the 1st axis.\n",
    "    else:  # axis == 2\n",
    "        for i in range(target_size):\n",
    "            start_idx = int(i * block_size)\n",
    "            end_idx = int((i + 1) * block_size)\n",
    "            new_data[:, :, i] = np.mean(data[:, :, start_idx:end_idx], axis=2)  # Average blocks along the 2nd axis.\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| test average_downsample_3d_array\n",
    "def test_average_downsample_3d_array():\n",
    "    # Create a simple 3D array with shape (4, 2, 2)\n",
    "    # Each element in the z-dimension is the same to make averaging predictable\n",
    "    data = np.array([\n",
    "        [[3, 0.1], [2, 5]],\n",
    "        [[1, 0.1], [2, 2]],\n",
    "        [[0.3, 3], [4, 4]],\n",
    "        [[0.2, 3], [4, 6]]\n",
    "    ])\n",
    "\n",
    "    # Target new size for the axis 0 is 2\n",
    "    target_size = 2\n",
    "\n",
    "    # Perform averaging along axis 0\n",
    "    downsampled_data = average_downsample_3d_array(data, axis=0, target_size=target_size)\n",
    "\n",
    "    # Manually calculate expected results\n",
    "    expected_data = np.array([\n",
    "        [[2, 0.1], [2, 3.5]],  # Average of the first two and the last two blocks along axis 0\n",
    "        [[0.25, 3], [4, 5]]\n",
    "    ])\n",
    "    \n",
    "    # Check that the downsampled data matches the expected data\n",
    "    test_eq(downsampled_data, expected_data)\n",
    "\n",
    "# Invoke the test\n",
    "test_average_downsample_3d_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reorder Orbit with Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def reorder_orbits(orbit_dataset: np.ndarray\n",
    "                  ) -> Tuple[np.ndarray,      # 3D numpy array of reordered orbits.\n",
    "                             np.ndarray,        # 2D numpy array of metric values.\n",
    "                             List[str]]:        # List of metric labels.\n",
    "    \"\"\"\n",
    "    Reorders the time steps of each orbit in the dataset such that the time values are always incrementally increasing.\n",
    "    Returns the reordered dataset, a 2D array of metric values for each orbit, and a list of metric labels.\n",
    "    \"\"\"\n",
    "    num_orbits, num_scalars, num_timesteps = orbit_dataset.shape\n",
    "    reordered_dataset = np.zeros_like(orbit_dataset)\n",
    "    metrics_array = np.zeros((num_orbits, 4))  # Assuming four metrics\n",
    "    metric_labels = ['disorder_metric', 'correct_order', 'inversions', 'kendall_tau_distance']\n",
    "    \n",
    "    for i in range(num_orbits):\n",
    "        # Extract the time steps and corresponding data for the current orbit\n",
    "        orbit_data = orbit_dataset[i]\n",
    "        time_steps = orbit_data[0]\n",
    "        \n",
    "        # Calculate the disorder metric for the current orbit\n",
    "        sorted_indices = np.argsort(time_steps)\n",
    "        disorder_metric = np.sum(np.abs(sorted_indices - np.arange(len(time_steps))))\n",
    "        correct_order = np.sum(np.diff(time_steps) >= 0)\n",
    "        \n",
    "        # Calculate the number of inversions\n",
    "        inversions = sum(1 for j in range(num_timesteps) for k in range(j + 1, num_timesteps) if time_steps[j] > time_steps[k])\n",
    "        \n",
    "        # Calculate Kendall's tau distance\n",
    "        tau, _ = kendalltau(time_steps, np.sort(time_steps))\n",
    "        kendall_tau_distance = 1 - tau if not np.isnan(tau) else 1.0  # Handle NaN\n",
    "        \n",
    "        # Store the metrics in the array\n",
    "        metrics_array[i] = [disorder_metric, correct_order, inversions, kendall_tau_distance]\n",
    "        \n",
    "        # Reorder the orbit data based on the sorted indices\n",
    "        reordered_orbit_data = orbit_data[:, sorted_indices]\n",
    "        \n",
    "        # Store the reordered orbit data in the new dataset\n",
    "        reordered_dataset[i] = reordered_orbit_data\n",
    "    \n",
    "    return reordered_dataset, metrics_array, metric_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| test reorder_orbits\n",
    "\n",
    "data = np.array([[[4, 3, 2, 1],  # Time steps for orbit 1\n",
    "                  [0, 0, 0, 0],  # posx\n",
    "                  [0, 0, 0, 0],  # posy\n",
    "                  [0, 0, 0, 0],  # posz\n",
    "                  [0, 0, 0, 0],  # velx\n",
    "                  [0, 0, 0, 0],  # vely\n",
    "                  [0, 0, 0, 0]], # velz\n",
    "\n",
    "                  [[4, 3, 2, 1],  # Time steps for orbit 2\n",
    "                  [0, 0, 0, 0],  # posx\n",
    "                  [0, 0, 0, 0],  # posy\n",
    "                  [0, 0, 0, 0],  # posz\n",
    "                  [0, 0, 0, 0],  # velx\n",
    "                  [0, 0, 0, 0],  # vely\n",
    "                  [0, 0, 0, 0]]]) # velz\n",
    "\n",
    "expected_data = np.array([[[1, 2, 3, 4],\n",
    "                            [0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0]],\n",
    "\n",
    "                          [[1, 2, 3, 4],\n",
    "                            [0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0]]])\n",
    "\n",
    "# Reorder the data\n",
    "reordered_data, metrics_array, metric_labels = reorder_orbits(data)\n",
    "\n",
    "# Aggregating the metrics to obtain average values\n",
    "average_metrics = metrics_array.mean(axis=0)\n",
    "average_metrics_dict = dict(zip(metric_labels, average_metrics))\n",
    "\n",
    "# Check that the reordered data matches the expected data\n",
    "assert np.array_equal(reordered_data, expected_data), f\"Expected {expected_data}, but got {reordered_data}\"\n",
    "\n",
    "# Check the average disorder metric\n",
    "expected_avg_disorder_metric = 8.0  # The disorder metric for each orbit is 8, so the average is also 8\n",
    "assert np.isclose(average_metrics_dict['disorder_metric'], expected_avg_disorder_metric), f\"Expected {expected_avg_disorder_metric}, but got {average_metrics_dict['disorder_metric']}\"\n",
    "\n",
    "# Check the average correct order\n",
    "expected_avg_correct_order = 0.0  # None of the time steps were originally in order\n",
    "assert np.isclose(average_metrics_dict['correct_order'], expected_avg_correct_order), f\"Expected {expected_avg_correct_order}, but got {average_metrics_dict['correct_order']}\"\n",
    "\n",
    "# Check the average number of inversions\n",
    "expected_avg_inversions = 6.0  # There are 6 inversions in each orbit\n",
    "assert np.isclose(average_metrics_dict['inversions'], expected_avg_inversions), f\"Expected {expected_avg_inversions}, but got {average_metrics_dict['inversions']}\"\n",
    "\n",
    "# Check the average Kendall's tau distance\n",
    "expected_avg_kendall_tau = 2.0  # Complete disagreement for both orbits\n",
    "assert np.isclose(average_metrics_dict['kendall_tau_distance'], expected_avg_kendall_tau), f\"Expected {expected_avg_kendall_tau}, but got {average_metrics_dict['kendall_tau_distance']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pad_and_convert_to_3d(orbits: Dict[int, np.ndarray],     # Dictionary of orbits with numerical keys.\n",
    "                          timesteps: int                     # Desired number of timesteps.\n",
    "                         ) -> np.ndarray:                    # 3D numpy array of padded orbits.\n",
    "    \"\"\"\n",
    "    Truncate and pad each orbit to a uniform length and convert to a 3D numpy array.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store the padded arrays\n",
    "    padded_arrays = []\n",
    "\n",
    "    # Iterate over each orbit in the dictionary\n",
    "    for key, orbit in orbits.items():\n",
    "        # Determine the number of timesteps to take from the orbit\n",
    "        num_timesteps = min(timesteps, orbit.shape[1])\n",
    "\n",
    "        # Take the first num_timesteps from the orbit\n",
    "        truncated_orbit = orbit[:, :num_timesteps]\n",
    "\n",
    "        # Pad the truncated orbit to have length timesteps in the final dimension\n",
    "        padded_orbit = np.pad(truncated_orbit, ((0, 0), (0, timesteps - num_timesteps)))\n",
    "\n",
    "        # Add the padded orbit to the list\n",
    "        padded_arrays.append(padded_orbit)\n",
    "\n",
    "    # Convert the list of padded arrays to a 3D numpy array and return it\n",
    "    return np.stack(padded_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def segment_and_convert_to_3d(orbits: Dict[int, np.ndarray],  # Dictionary of orbits with numerical keys.\n",
    "                              segment_length: int             # Desired length of each segment.\n",
    "                             ) -> Tuple[np.ndarray,           # 3D numpy array of segments.\n",
    "                                        List[int]]:           # List of IDs representing each new segment.\n",
    "    \"\"\"\n",
    "    Divide each orbit into segments of a given length and convert to a 3D numpy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a list to store the segments and their corresponding IDs\n",
    "    segments = []\n",
    "    segment_ids = []\n",
    "\n",
    "    # Iterate over each orbit in the dictionary\n",
    "    for key, orbit in orbits.items():\n",
    "        # Determine the number of complete segments that can be taken from the orbit\n",
    "        num_segments = orbit.shape[1] // segment_length\n",
    "\n",
    "        # Iterate over the number of complete segments\n",
    "        for i in range(num_segments):\n",
    "            # Take the segment of the desired length\n",
    "            segment = orbit[:, i*segment_length:(i+1)*segment_length]\n",
    "\n",
    "            # Add the segment to the list\n",
    "            segments.append(segment)\n",
    "\n",
    "            # Add the corresponding ID to the list\n",
    "            segment_ids.append(key)\n",
    "\n",
    "    # Convert the list of segments to a 3D numpy array\n",
    "    segments_3d = np.stack(segments)\n",
    "\n",
    "    return segments_3d, segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test segment_and_convert_to_3d\n",
    "\n",
    "orbits = {\n",
    "    1: np.array([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "                    [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24],\n",
    "                    [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36],\n",
    "                    [37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48],\n",
    "                    [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60],\n",
    "                    [61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72]]),\n",
    "    2: np.array([[73, 74, 75, 76, 77, 78, 79],\n",
    "                    [81, 82, 83, 84, 85, 86, 87],\n",
    "                    [89, 90, 91, 92, 93, 94, 95],\n",
    "                    [97, 98, 99, 100, 101, 102, 103],\n",
    "                    [105, 106, 107, 108, 109, 110, 111],\n",
    "                    [113, 114, 115, 116, 117, 118, 119]])\n",
    "}\n",
    "segment_length = 4\n",
    "\n",
    "# Expected segments and IDs\n",
    "expected_segments = np.array([\n",
    "    [[1, 2, 3, 4], [13, 14, 15, 16], [25, 26, 27, 28], [37, 38, 39, 40], [49, 50, 51, 52], [61, 62, 63, 64]],\n",
    "    [[5, 6, 7, 8], [17, 18, 19, 20], [29, 30, 31, 32], [41, 42, 43, 44], [53, 54, 55, 56], [65, 66, 67, 68]],\n",
    "    [[9, 10, 11, 12], [21, 22, 23, 24], [33, 34, 35, 36], [45, 46, 47, 48], [57, 58, 59, 60], [69, 70, 71, 72]],\n",
    "    [[73, 74, 75, 76], [81, 82, 83, 84], [89, 90, 91, 92], [97, 98, 99, 100], [105, 106, 107, 108], [113, 114, 115, 116]]\n",
    "])\n",
    "expected_ids = [1, 1, 1, 2]\n",
    "\n",
    "# Call the function\n",
    "segments_3d, segment_ids = segment_and_convert_to_3d(orbits, segment_length)\n",
    "\n",
    "# Use test_eq to check the results\n",
    "test_eq(segments_3d.tolist(), expected_segments.tolist())\n",
    "test_eq(segment_ids, expected_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Time Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def add_time_vector_to_orbits(orbits: Dict[int, np.ndarray],  # Dictionary of orbits with numerical keys.\n",
    "                              propagated_periods: List[float], # List of propagated periods for each orbit.\n",
    "                              periods: List[float]            # List of periods for each orbit.\n",
    "                             ) -> Dict[int, np.ndarray]:      # Dictionary of updated orbits with time vectors added.\n",
    "    \"\"\"\n",
    "    Add a time vector to each orbit in the dictionary.\n",
    "    \"\"\"\n",
    "    # Create a new dictionary to store the updated orbits\n",
    "    updated_orbits = {}\n",
    "\n",
    "    # Iterate over each orbit in the dictionary\n",
    "    for key, orbit in orbits.items():\n",
    "        # Extract the propagated_periods and period for this orbit using the key as index\n",
    "        propagated_period = propagated_periods[key]\n",
    "        period = periods[key]\n",
    "\n",
    "        # Compute the new time vector\n",
    "        tvec = np.linspace(0, propagated_period * period, orbit.shape[1])\n",
    "\n",
    "        # Add the time vector as the first vector in the orbit array\n",
    "        updated_orbit = np.vstack([tvec, orbit])\n",
    "\n",
    "        # Add the updated orbit to the new dictionary\n",
    "        updated_orbits[key] = updated_orbit\n",
    "\n",
    "    return updated_orbits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolating Equal Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def interpolate_equal_times(orbit_dataset: np.ndarray) -> np.ndarray:\n",
    "    num_orbits, num_scalars, num_timesteps = orbit_dataset.shape\n",
    "    processed_dataset = np.zeros_like(orbit_dataset, dtype=float)\n",
    "    \n",
    "    for i in range(num_orbits):\n",
    "        orbit_data = orbit_dataset[i]\n",
    "        time_steps = orbit_data[0]  # Extract time steps\n",
    "        \n",
    "        first_unequal = np.argmax(time_steps != time_steps[0])\n",
    "        if first_unequal == 0:  # All values are equal\n",
    "            first_unequal = len(time_steps)\n",
    "        \n",
    "        if first_unequal > 1:\n",
    "            new_orbit_data = np.copy(orbit_data).astype(float)\n",
    "            \n",
    "            # Perform interpolation for the full range plus one extra step\n",
    "            num_points = first_unequal + 1  # Add one more point\n",
    "            if first_unequal < len(time_steps):\n",
    "                interp_times = np.linspace(time_steps[0], time_steps[first_unequal], num_points)\n",
    "            else:\n",
    "                interp_times = np.linspace(0, 1, num_points)\n",
    "            \n",
    "            new_orbit_data[0, :num_points] = interp_times\n",
    "            \n",
    "            # Interpolate other scalar values\n",
    "            for j in range(1, num_scalars):\n",
    "                if first_unequal < len(time_steps):\n",
    "                    f = interp1d([time_steps[0], time_steps[first_unequal]], \n",
    "                                 [orbit_data[j, 0], orbit_data[j, first_unequal]],\n",
    "                                 fill_value=\"extrapolate\")\n",
    "                    new_orbit_data[j, :num_points] = f(interp_times)\n",
    "                else:\n",
    "                    new_orbit_data[j, :num_points] = np.linspace(orbit_data[j, 0], orbit_data[j, -1], num_points)\n",
    "            \n",
    "            processed_dataset[i] = new_orbit_data\n",
    "        else:\n",
    "            processed_dataset[i] = orbit_data.astype(float)\n",
    "    \n",
    "    return processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.125 0.25  0.375 0.5   0.625 0.75  0.875 1.    2.   ]]\n"
     ]
    }
   ],
   "source": [
    "# Testing with dummy data that has equal time values at the beginning\n",
    "test_data = np.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 1, 2],\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "])\n",
    "\n",
    "# Reshape to 3D array (1 orbit with 3 scalars and 10 timesteps)\n",
    "test_data = test_data.reshape(1, 3, 10)\n",
    "\n",
    "output = interpolate_equal_times(test_data)\n",
    "print(output[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
