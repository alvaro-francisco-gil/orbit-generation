{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "> Scripts to build the different datasets used for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, List, Dict, Any\n",
    "\n",
    "from orbit_generation.processing import pad_and_convert_to_3d, segment_and_convert_to_3d, add_time_vector_to_orbits\n",
    "from orbit_generation.constants import ORBIT_CLASS_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_orbit_data_from_hdf5(file_path: str                   # Path to the HDF5 file.\n",
    "                            ) -> Tuple[Dict[int, np.ndarray], # Dictionary of orbits with numerical keys.\n",
    "                                    pd.DataFrame,             # DataFrame containing orbit features.\n",
    "                                    Dict[str, float]]:        # Dictionary containing system features.\n",
    "    \"\"\"\n",
    "    Load orbit data from an HDF5 file.\n",
    "    \"\"\"\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        # Extract not_propagated_orbits and store in a list of integers\n",
    "        not_propagated_orbits = [index - 1 for index in file['not_propagated_orbits'][0].tolist()]\n",
    "        \n",
    "        # Extract system features and labels\n",
    "        system_features = file['system_features'][:]\n",
    "        system_labels = file['system_labels'][:].astype(str)\n",
    "        \n",
    "        # Create a dictionary for system\n",
    "        system_dict = {label: feature[0] for label, feature in zip(system_labels.flatten().tolist(), system_features)}\n",
    "        \n",
    "        # Extract orbit features and labels\n",
    "        orbit_features = file['orbit_features'][:]\n",
    "        orbit_labels = file['orbit_labels'][:].astype(str)\n",
    "        \n",
    "        # Create a dataframe for orbits\n",
    "        orbit_df = pd.DataFrame(orbit_features.T, columns=orbit_labels.flatten().tolist())\n",
    "        \n",
    "        # Remove rows in orbit_df based on not_propagated_orbits\n",
    "        orbit_df = orbit_df.drop(not_propagated_orbits).reset_index(drop=True)\n",
    "        \n",
    "        # Extract numpy arrays with numerical keys\n",
    "        orbits = {int(key): file[key][:] for key in file.keys() if key.isdigit()}\n",
    "        \n",
    "        # Reset the index of the dictionary to start on 0\n",
    "        orbits = {i: orbits[key] for i, key in enumerate(sorted(orbits.keys()))}\n",
    "                \n",
    "    return orbits, orbit_df, system_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orbit Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_orbit_features_from_hdf5(file_path: str          # Path to the HDF5 file.\n",
    "                                ) -> pd.DataFrame:       # DataFrame containing orbit features.\n",
    "    \"\"\"\n",
    "    Load orbit DataFrame from an HDF5 file.\n",
    "    \"\"\"\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        # Extract not_propagated_orbits and store in a list of integers\n",
    "        not_propagated_orbits = [index - 1 for index in file['not_propagated_orbits'][0].tolist()]\n",
    "        \n",
    "        # Extract orbit features and labels\n",
    "        orbit_features = file['orbit_features'][:]\n",
    "        orbit_labels = file['orbit_labels'][:].astype(str)\n",
    "        \n",
    "        # Create a dataframe for orbits\n",
    "        orbit_df = pd.DataFrame(orbit_features.T, columns=orbit_labels.flatten().tolist())\n",
    "        \n",
    "        # Remove rows in orbit_df based on not_propagated_orbits\n",
    "        orbit_df = orbit_df.drop(not_propagated_orbits).reset_index(drop=True)\n",
    "                \n",
    "    return orbit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_orbit_features_from_folder(folder_path: str    # Path to the folder\n",
    "                                  ) -> pd.DataFrame:   # DataFrame containing concatenated orbit features.\n",
    "    \"\"\"\n",
    "    Concatenate orbit DataFrames from all HDF5 files in a folder, preserving original index and adding system column.\n",
    "    \"\"\"\n",
    "    all_dfs = []  # List to store individual DataFrames\n",
    "\n",
    "    # Iterate over all files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the file is an HDF5 file\n",
    "        if file_name.endswith('.h5') or file_name.endswith('.hdf5'):\n",
    "            # Get the orbit DataFrame from the HDF5 file\n",
    "            orbit_df = get_orbit_features_from_hdf5(file_path)\n",
    "            \n",
    "            # Preserve the original index as a new column\n",
    "            orbit_df['original_index'] = orbit_df.index\n",
    "            \n",
    "            # Add a new column called 'system' with the name of the file (without extension)\n",
    "            orbit_df['system'] = os.path.splitext(file_name)[0].split('_')[0]\n",
    "            \n",
    "            # Append the DataFrame to the list\n",
    "            all_dfs.append(orbit_df)\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    concatenated_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    \n",
    "    return concatenated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_data_from_hdf5(file_path: str              # Path to the HDF5 file.\n",
    "                             ) -> Dict[str, float]:       # Dictionary containing system features.\n",
    "    \"\"\"\n",
    "    Load system data from an HDF5 file.\n",
    "    \"\"\"\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        # Extract system features and labels\n",
    "        system_features = file['system_features'][:]\n",
    "        system_labels = file['system_labels'][:].astype(str)\n",
    "        \n",
    "        # Create a dictionary for system\n",
    "        system_dict = {label: feature[0] for label, feature in zip(system_labels.flatten().tolist(), system_features)}\n",
    "        \n",
    "    return system_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_features_from_folder(folder_path: str    # Path to the folder\n",
    "                                   ) -> pd.DataFrame:   # DataFrame containing concatenated system features.\n",
    "    \"\"\"\n",
    "    Concatenate system DataFrames from all HDF5 files in a folder, preserving original index and adding system column.\n",
    "    \"\"\"\n",
    "    all_systems = []  # List to store individual system dictionaries\n",
    "\n",
    "    # Iterate over all files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the file is an HDF5 file\n",
    "        if file_name.endswith('.h5') or file_name.endswith('.hdf5'):\n",
    "            # Get the system dictionary from the HDF5 file\n",
    "            system_dict = get_system_data_from_hdf5(file_path)\n",
    "            \n",
    "            # Add a new entry to the dictionary for the system name\n",
    "            system_dict['system'] = os.path.splitext(file_name)[0].split('_')[0]\n",
    "            \n",
    "            # Append the dictionary to the list\n",
    "            all_systems.append(system_dict)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    concatenated_df = pd.DataFrame(all_systems)\n",
    "    \n",
    "    return concatenated_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def substitute_values_from_df(values: List[Any],         # List of values to be substituted.\n",
    "                              df: pd.DataFrame,          # DataFrame containing the mapping.\n",
    "                              goal_column: str,          # Column in the DataFrame to get the substitution values from.\n",
    "                              id_column: str = 'Id'      # Column in the DataFrame to match the values with. Default is 'Id'.\n",
    "                             ) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Substitute values in the given list based on the mapping from a DataFrame's id column to goal column.\n",
    "\n",
    "    Parameters:\n",
    "    values (List[Any]): List of values to be substituted.\n",
    "    df (pd.DataFrame): DataFrame containing the mapping from id_column to goal_column.\n",
    "    goal_column (str): Column in the DataFrame to get the substitution values from.\n",
    "    id_column (str, optional): Column in the DataFrame to match the values with. Default is 'Id'.\n",
    "\n",
    "    Returns:\n",
    "    List[Any]: A list with substituted values from the DataFrame's goal_column.\n",
    "    \"\"\"\n",
    "    # Create a dictionary for substitution from the DataFrame\n",
    "    substitution_dict = df.set_index(id_column)[goal_column].to_dict()\n",
    "\n",
    "    # Substitute the values in the list using the dictionary\n",
    "    substituted_values = [substitution_dict.get(value, value) for value in values]\n",
    "\n",
    "    return substituted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_orbit_classes(values: List[Any]) -> Tuple[List[Any], List[Any], List[Any], List[Any]]:\n",
    "    \"\"\"\n",
    "    Get orbit classes based on the given values and DataFrame. Returns four lists corresponding\n",
    "    to 'Label', 'Type', 'Subtype', and 'Direction' columns.\n",
    "\n",
    "    Parameters:\n",
    "    values (List[Any]): List of values to be substituted.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[List[Any], List[Any], List[Any], List[Any]]: Four lists with substituted values from 'Label', 'Type', 'Subtype', and 'Direction' columns.\n",
    "    \"\"\"\n",
    "    labels = substitute_values_from_df(values, ORBIT_CLASS_DF, 'Label')\n",
    "    types = substitute_values_from_df(values, ORBIT_CLASS_DF, 'Type')\n",
    "    subtypes = substitute_values_from_df(values, ORBIT_CLASS_DF, 'Subtype')\n",
    "    directions = substitute_values_from_df(values, ORBIT_CLASS_DF, 'Direction')\n",
    "\n",
    "    return labels, types, subtypes, directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['S_BN', 'S_L1_A', 'S_L4_LP'],\n",
       " ['System-wide', 'L1', 'L4'],\n",
       " ['Butterfly', 'Axial', 'Long Period'],\n",
       " ['North', 'No specification', 'East'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [1,7,23]\n",
    "get_orbit_classes(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets fixed Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_first_period_dataset(file_path: str                  # Path to the HDF5 file.\n",
    "                            ) -> Tuple[np.ndarray,          # 3D numpy array of padded orbits.\n",
    "                                       pd.DataFrame,        # DataFrame containing orbit features.\n",
    "                                       Dict[str, float]]:   # Dictionary containing system features.\n",
    "    \"\"\"\n",
    "    Load and process orbit data from an HDF5 file for the first period.\n",
    "    \"\"\"\n",
    "    # Load the orbit data, features dataframe, and system dictionary from the HDF5 file\n",
    "    orbits, orbit_df, system_dict = get_orbit_data_from_hdf5(file_path)\n",
    "\n",
    "    # Extract propagated periods and periods from the DataFrame\n",
    "    propagated_periods = orbit_df['propagated_periods'].tolist()\n",
    "    periods = orbit_df['period'].tolist()\n",
    "\n",
    "    # Remove the file type and extract parts of the file name to determine processing steps\n",
    "    file_name = os.path.basename(file_path).split('.')[0]\n",
    "    file_parts = file_name.split('_')\n",
    "\n",
    "    # Check if the second part of the file name is 'N'\n",
    "    if file_parts[1] == 'N':\n",
    "        # Add time vectors to the orbits\n",
    "        orbits = add_time_vector_to_orbits(orbits, propagated_periods, periods)\n",
    "        # Pad and convert the orbits to a 3D array using the fourth part of the file name as timesteps\n",
    "        orbits = pad_and_convert_to_3d(orbits, int(file_parts[3]))\n",
    "\n",
    "    return orbits, orbit_df, system_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset fixed Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_segmented_dataset(file_path: str,                     # Path to the HDF5 file.\n",
    "                          segment_length: int                 # Desired length of each segment.\n",
    "                         ) -> Tuple[np.ndarray,               # 3D numpy array of segmented orbits.\n",
    "                                    pd.DataFrame,             # DataFrame containing orbit features.\n",
    "                                    List[int],                # List of IDs representing each new segment.\n",
    "                                    Dict[str, float]]:        # Dictionary containing system features.\n",
    "    \"\"\"\n",
    "    Load and process orbit data from an HDF5 file, segmenting each orbit into specified length.\n",
    "    \"\"\"\n",
    "    # Load the orbit data, features dataframe, and system dictionary from the HDF5 file\n",
    "    orbits, orbit_df, system_dict = get_orbit_data_from_hdf5(file_path)\n",
    "\n",
    "    # Check if the second part of the file name is 'dt'\n",
    "    if os.path.basename(file_path).split('_')[1] == 'dt':\n",
    "        # Segment the orbits and get the corresponding segment IDs\n",
    "        orbits, orbits_ids = segment_and_convert_to_3d(orbits, segment_length)\n",
    "\n",
    "    return orbits, orbit_df, orbits_ids, system_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
