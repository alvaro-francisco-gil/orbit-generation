{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "\n",
    "> Scripts to perform the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Dict, Any, Optional, List, Union, Tuple\n",
    "import torch\n",
    "import itertools\n",
    "import nbformat\n",
    "import papermill as pm\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import logging\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def setup_new_experiment(params: Dict[str, Any],              # Dictionary of parameters for the new experiment.\n",
    "                         experiments_folder: str,             # Path to the folder containing all experiments.\n",
    "                         json_file: Optional[str] = None      # Optional path to the JSON file tracking experiment parameters.\n",
    "                        ) -> str:                             # The path to the newly created experiment folder.\n",
    "    \"\"\"\n",
    "    Sets up a new experiment by creating a new folder and updating the JSON file with experiment parameters.\n",
    "    \"\"\"\n",
    "    # Ensure the experiments folder exists\n",
    "    if not os.path.exists(experiments_folder):\n",
    "        os.makedirs(experiments_folder)\n",
    "\n",
    "    # Default JSON file to 'experiments.json' in the experiments_folder if not provided\n",
    "    if json_file is None:\n",
    "        json_file = os.path.join(experiments_folder, 'experiments.json')\n",
    "\n",
    "    # Load existing experiments from the JSON file if it exists\n",
    "    if os.path.isfile(json_file):\n",
    "        with open(json_file, mode='r') as file:\n",
    "            experiments = json.load(file)\n",
    "    else:\n",
    "        experiments = []\n",
    "\n",
    "    # Check if the parameters already exist in the JSON file\n",
    "    for experiment in experiments:\n",
    "        if all(experiment['parameters'].get(key) == value for key, value in params.items()):\n",
    "            candidate_folder = os.path.join(experiments_folder, f\"experiment_{experiment['id']}\")\n",
    "            if os.path.exists(candidate_folder):\n",
    "                print(f'Parameters already exist for experiment: {candidate_folder}')\n",
    "                return candidate_folder\n",
    "\n",
    "    # Determine the next experiment number\n",
    "    next_experiment_number = max((experiment['id'] for experiment in experiments), default=0) + 1\n",
    "\n",
    "    # Create a new folder for the next experiment\n",
    "    new_experiment_folder = os.path.join(experiments_folder, f'experiment_{next_experiment_number}')\n",
    "    os.makedirs(new_experiment_folder, exist_ok=True)\n",
    "\n",
    "    # Add the new experiment to the list and save to JSON file\n",
    "    new_experiment = {\n",
    "        'id': next_experiment_number,\n",
    "        'parameters': params\n",
    "    }\n",
    "    experiments.append(new_experiment)\n",
    "    with open(json_file, mode='w') as file:\n",
    "        json.dump(experiments, file, indent=4)\n",
    "\n",
    "    print(f'New experiment setup complete: {new_experiment_folder}')\n",
    "    print(f'Parameters saved to {json_file}.')\n",
    "\n",
    "    return new_experiment_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_experiments_json(parameter_sets, output_file='experiments.json'):\n",
    "    \"\"\"\n",
    "    Create an experiments.json file from given parameter sets.\n",
    "    \n",
    "    Args:\n",
    "    parameter_sets (list): List of dictionaries containing parameters for each experiment.\n",
    "    output_file (str): Name of the output JSON file. Defaults to 'experiments.json'.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    experiments = []\n",
    "    \n",
    "    for i, params in enumerate(parameter_sets, start=1):\n",
    "        experiment = {\n",
    "            \"id\": i,\n",
    "            \"parameters\": params\n",
    "        }\n",
    "        experiments.append(experiment)\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(experiments, f, indent=4)\n",
    "    \n",
    "    print(f\"Experiments JSON file created: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_numpy_types(obj):\n",
    "    \"\"\"\n",
    "    Recursively convert numpy types and tensors to native Python types for JSON serialization.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: convert_numpy_types(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_numpy_types(item) for item in obj]\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.int32, np.int64)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, torch.Tensor):\n",
    "        return obj.item() if obj.numel() == 1 else obj.tolist()\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def add_experiment_metrics(experiments_folder: str,                    # Path to the folder containing all experiments.\n",
    "                           params: Optional[Dict[str, Any]] = None,    # Optional dictionary of parameters identifying the experiment.\n",
    "                           experiment_id: Optional[int] = None,        # Optional ID to identify the experiment.\n",
    "                           metrics: Optional[Dict[str, Any]] = None,   # Optional dictionary of metrics to be added to the experiment.\n",
    "                           json_file: Optional[str] = None             # Optional path to the JSON file tracking experiment parameters and metrics.\n",
    "                          ) -> None:\n",
    "    \"\"\"\n",
    "    Adds metrics to an existing experiment in the JSON file based on the given parameters or ID.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(experiments_folder):\n",
    "        raise FileNotFoundError(f\"The experiments folder '{experiments_folder}' does not exist.\")\n",
    "\n",
    "    if json_file is None:\n",
    "        json_file = os.path.join(experiments_folder, 'experiments.json')\n",
    "\n",
    "    if not os.path.isfile(json_file):\n",
    "        raise FileNotFoundError(f\"The JSON file '{json_file}' does not exist.\")\n",
    "\n",
    "    if params is None and experiment_id is None:\n",
    "        raise ValueError(\"Either 'params' or 'experiment_id' must be provided to identify the experiment.\")\n",
    "\n",
    "    if metrics is None:\n",
    "        metrics = {}\n",
    "\n",
    "    with open(json_file, mode='r') as file:\n",
    "        try:\n",
    "            experiments = json.load(file)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Error reading JSON file: {e}\")\n",
    "\n",
    "    found_experiment = False\n",
    "\n",
    "    for experiment in experiments:\n",
    "        if (experiment_id is not None and experiment['id'] == experiment_id) or \\\n",
    "           (params is not None and all(experiment['parameters'].get(key) == value for key, value in params.items())):\n",
    "            experiment.update(convert_numpy_types(metrics))\n",
    "            found_experiment = True\n",
    "            break\n",
    "\n",
    "    if not found_experiment:\n",
    "        if experiment_id is not None:\n",
    "            raise ValueError(f\"Experiment with the specified ID {experiment_id} does not exist.\")\n",
    "        else:\n",
    "            raise ValueError(\"Experiment with the specified parameters does not exist.\")\n",
    "\n",
    "    # Convert the entire experiments list to ensure all nested objects are serializable\n",
    "    serializable_experiments = convert_numpy_types(experiments)\n",
    "\n",
    "    with open(json_file, mode='w') as file:\n",
    "        json.dump(serializable_experiments, file, indent=4)\n",
    "\n",
    "    if experiment_id is not None:\n",
    "        print(f'Metrics added to experiment with ID {experiment_id} in {json_file}.')\n",
    "    else:\n",
    "        experiment_id = experiment['id']\n",
    "        print(f'Metrics added to experiment with ID {experiment_id} in {json_file}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_experiment_parameters(experiments_folder: str,                    # Path to the folder containing all experiments.\n",
    "                              experiment_id: int,                         # ID to identify the experiment.\n",
    "                              json_file: Optional[str] = None             # Optional path to the JSON file tracking experiment parameters and metrics.\n",
    "                             ) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Retrieves the parameters of an experiment from the JSON file based on the given ID.\n",
    "    \"\"\"\n",
    "    # Ensure the experiments folder exists\n",
    "    if not os.path.exists(experiments_folder):\n",
    "        raise FileNotFoundError(f\"The experiments folder '{experiments_folder}' does not exist.\")\n",
    "\n",
    "    # Default JSON file to 'experiments.json' in the experiments_folder if not provided\n",
    "    if json_file is None:\n",
    "        json_file = os.path.join(experiments_folder, 'experiments.json')\n",
    "\n",
    "    if not os.path.isfile(json_file):\n",
    "        raise FileNotFoundError(f\"The JSON file '{json_file}' does not exist.\")\n",
    "\n",
    "    # Load existing experiments from the JSON file\n",
    "    with open(json_file, mode='r') as file:\n",
    "        experiments = json.load(file)\n",
    "\n",
    "    # Find the matching experiment and return its parameters\n",
    "    for experiment in experiments:\n",
    "        if experiment['id'] == experiment_id:\n",
    "            return experiment.get('parameters', {})\n",
    "\n",
    "    # If the experiment is not found, raise an error\n",
    "    raise ValueError(f\"Experiment with the specified ID {experiment_id} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_experiment_data(experiments_folder: str,  # Path to the folder containing all experiments\n",
    "                       experiment_id: int,  # ID to identify the experiment\n",
    "                       json_file: Optional[str] = None,  # Optional path to the JSON file tracking experiment data\n",
    "                       ) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Retrieves all data for an experiment from the JSON file based on the given ID.\n",
    "    \"\"\"\n",
    "    # Ensure the experiments folder exists\n",
    "    if not os.path.exists(experiments_folder):\n",
    "        raise FileNotFoundError(f\"The experiments folder '{experiments_folder}' does not exist.\")\n",
    "\n",
    "    # Default JSON file to 'experiments.json' in the experiments_folder if not provided\n",
    "    if json_file is None:\n",
    "        json_file = os.path.join(experiments_folder, 'experiments.json')\n",
    "\n",
    "    if not os.path.isfile(json_file):\n",
    "        raise FileNotFoundError(f\"The JSON file '{json_file}' does not exist.\")\n",
    "\n",
    "    # Load existing experiments from the JSON file\n",
    "    with open(json_file, mode='r') as file:\n",
    "        experiments = json.load(file)\n",
    "\n",
    "    # Find the matching experiment and return all its data\n",
    "    for experiment in experiments:\n",
    "        if experiment['id'] == int(experiment_id):\n",
    "            return experiment\n",
    "\n",
    "    # If the experiment is not found, raise an error\n",
    "    raise ValueError(f\"Experiment with the specified ID {experiment_id} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_json_to_dataframe(json_path: str,  # Path to the JSON file containing experiment results\n",
    "                          ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a JSON file containing experiment results and returns a DataFrame.\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Extract relevant information\n",
    "    records = []\n",
    "    for item in data:\n",
    "        # Assuming each item is a dictionary with an 'id' field and other details\n",
    "        record = {'id_experiment': item['id']}\n",
    "        record.update(item)\n",
    "        records.append(record)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_image_paths(folder_prefix: str,  # Base folder path prefix for each experiment\n",
    "                        unique_ids: list[int],  # List of experiment IDs\n",
    "                        file_suffix: str,  # Suffix to append to the generated filenames\n",
    "                        ) -> list[str]:\n",
    "    \"\"\"\n",
    "    Generates a list of image file paths based on experiment IDs and folder structure.\n",
    "    \"\"\"\n",
    "    file_paths = []\n",
    "    for unique_id in unique_ids:\n",
    "        file_name = f\"exp{unique_id}{file_suffix}\"\n",
    "        file_path = f\"{folder_prefix}{unique_id}/images/{file_name}\"\n",
    "        file_paths.append(file_path)\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Orbits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def concatenate_orbits_from_experiment_folder(experiments_folder: str,  # Root folder containing experiment subfolders\n",
    "                                            seq_len: int,  # Expected sequence length of orbit data\n",
    "                                            file_suffix: str = '_generated_orbits',  # Suffix for orbit data files\n",
    "                                            ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Concatenates orbit data from multiple experiment folders into a single array.\n",
    "    \"\"\"\n",
    "    arrays = []\n",
    "    \n",
    "    for folder in os.listdir(experiments_folder):\n",
    "        if folder.startswith('experiment_') and os.path.isdir(os.path.join(experiments_folder, folder)):\n",
    "            # Extract the experiment number using regex\n",
    "            match = re.search(r'experiment_(\\d+)', folder)\n",
    "            if match:\n",
    "                experiment_id = match.group(1)\n",
    "                generated_data_path = os.path.join(experiments_folder, folder, f'exp{experiment_id}{file_suffix}.npy')\n",
    "                \n",
    "                if os.path.isfile(generated_data_path):\n",
    "                    generated_orbit = np.load(generated_data_path)\n",
    "                    \n",
    "                    if generated_orbit.shape[-1] == seq_len:\n",
    "                        arrays.append(generated_orbit)\n",
    "    \n",
    "    if arrays:\n",
    "        return np.concatenate(arrays, axis=0)\n",
    "    else:\n",
    "        return np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def concatenate_csvs_from_experiment_folder(experiments_folder: str,  # Root folder containing experiment subfolders\n",
    "                                          file_suffix: str,  # Suffix for CSV files to concatenate\n",
    "                                          ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Concatenates CSV files from multiple experiment folders into a single DataFrame.\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "    \n",
    "    for folder in os.listdir(experiments_folder):\n",
    "        if folder.startswith('experiment_') and os.path.isdir(os.path.join(experiments_folder, folder)):\n",
    "            # Extract the experiment number using regex\n",
    "            match = re.search(r'experiment_(\\d+)', folder)\n",
    "            if match:\n",
    "                experiment_id = match.group(1)\n",
    "                csv_file_path = os.path.join(experiments_folder, folder, f'exp{experiment_id}_{file_suffix}.csv')\n",
    "                \n",
    "                if os.path.isfile(csv_file_path):\n",
    "                    # Load the CSV file into a DataFrame\n",
    "                    df = pd.read_csv(csv_file_path)\n",
    "                    \n",
    "                    # Add a column to identify the experiment\n",
    "                    df['experiment_id'] = experiment_id\n",
    "                    \n",
    "                    dataframes.append(df)\n",
    "    \n",
    "    # Concatenate all DataFrames along rows\n",
    "    if dataframes:\n",
    "        return pd.concat(dataframes, axis=0, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Orbit and Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def concatenate_and_check_orbits_from_experiment_folder(\n",
    "    experiments_folder: str,  # Root folder containing experiment subfolders\n",
    "    csv_file_name: str = '_refined_orbits_df.csv',  # Suffix for CSV files containing refined orbits\n",
    "    np_file_name: str = '_refined_orbits',  # Suffix for numpy files containing generated orbits\n",
    "    ) -> Tuple[np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Concatenates orbit data from multiple experiment folders and checks for consistency between generated and refined orbits.\n",
    "    \"\"\"\n",
    "    arrays = []\n",
    "    all_refined_orbit_dfs = []\n",
    "    \n",
    "    for folder in os.listdir(experiments_folder):\n",
    "        folder_path = os.path.join(experiments_folder, folder)  # Construct the folder path\n",
    "        \n",
    "        if folder.startswith('experiment_') and os.path.isdir(folder_path):\n",
    "            # Extract the experiment number using regex\n",
    "            match = re.search(r'experiment_(\\d+)', folder)\n",
    "            if match:\n",
    "                experiment_id = match.group(1)\n",
    "                generated_data_path = os.path.join(folder_path, f'exp{experiment_id}{np_file_name}.npy')\n",
    "                refined_orbit_path = os.path.join(folder_path, f'exp{experiment_id}{csv_file_name}')  # Path to refined orbits\n",
    "                \n",
    "                if os.path.isfile(generated_data_path):\n",
    "                    generated_orbit = np.load(generated_data_path)\n",
    "                    \n",
    "                    # Load the refined orbits DataFrame\n",
    "                    if os.path.isfile(refined_orbit_path):\n",
    "                        refined_orbit_df = pd.read_csv(refined_orbit_path)\n",
    "                        \n",
    "                        # Add a column to identify the experiment\n",
    "                        refined_orbit_df['experiment_id'] = experiment_id\n",
    "                        \n",
    "                        # Check if the number of orbits matches the length of refined_orbit_df\n",
    "                        if generated_orbit.shape[0] != len(refined_orbit_df):\n",
    "                            print(f\"Mismatch for experiment {experiment_id}: generated_orbit count = {generated_orbit.shape[0]}, refined_orbit_df length = {len(refined_orbit_df)}\")\n",
    "                            continue  # Skip to the next folder if there is a mismatch\n",
    "                        \n",
    "                        all_refined_orbit_dfs.append(refined_orbit_df)\n",
    "                    \n",
    "                    arrays.append(generated_orbit)\n",
    "    \n",
    "    if arrays:\n",
    "        concatenated_orbit = np.concatenate(arrays, axis=0)\n",
    "        return concatenated_orbit, pd.concat(all_refined_orbit_dfs, ignore_index=True)\n",
    "    else:\n",
    "        return np.array([]), pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_parameter_sets(params: Dict[str, Union[Any, List[Any]]],  # Dictionary of parameter names and their values/value lists\n",
    "                          model_specific_params: Dict[str, Dict],  # Dictionary mapping model names to their specific parameters\n",
    "                          ) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Generates all possible parameter combinations from the given parameter sets and merges them with model-specific parameters.\n",
    "    \"\"\"\n",
    "    keys, values = zip(*params.items())\n",
    "    combinations = [dict(zip(keys, v)) for v in itertools.product(*[\n",
    "        value if isinstance(value, list) else [value] for value in values\n",
    "    ])]\n",
    "    \n",
    "    final_combinations = []\n",
    "    for combo in combinations:\n",
    "        model_name = combo['model_name']\n",
    "        if model_name in model_specific_params:\n",
    "            model_kwargs = model_specific_params[model_name].copy()\n",
    "            combo['model_kwargs'] = model_kwargs\n",
    "            combo['model_kwargs']['beta'] = combo.pop('beta')\n",
    "            final_combinations.append(combo)\n",
    "    \n",
    "    return final_combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def execute_parameter_notebook(notebook_to_execute: str,  # Path to the notebook file to execute\n",
    "                             output_dir: str,  # Directory to save output notebook\n",
    "                             i: int,  # Execution index\n",
    "                             params: Dict,  # Parameters to pass to the notebook\n",
    "                             extra_parameters: Optional[Dict] = None,  # Additional parameters to merge with params\n",
    "                             checkpoint_file: Optional[str] = None,  # Path to checkpoint file\n",
    "                             ) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Executes a Jupyter notebook with given parameters and saves the output.\n",
    "    Returns the execution index if successful, None if failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Mark as started\n",
    "        with open(checkpoint_file, 'r+') as f:\n",
    "            checkpoint = json.load(f)\n",
    "            if i not in checkpoint['started']:\n",
    "                checkpoint['started'].append(i)\n",
    "                f.seek(0)\n",
    "                json.dump(checkpoint, f)\n",
    "                f.truncate()\n",
    "        \n",
    "        logging.info(f\"Starting execution {i}\")\n",
    "\n",
    "        # Generate output filenames\n",
    "        base_name = os.path.splitext(os.path.basename(notebook_to_execute))[0]\n",
    "        output_notebook = os.path.join(output_dir, f\"{base_name}_execution_{i}.ipynb\")\n",
    "\n",
    "        # Read the notebook\n",
    "        with open(notebook_to_execute, 'r', encoding='utf-8') as f:\n",
    "            nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "        # Merge params and extra_parameters into a single dictionary\n",
    "        if extra_parameters is not None:\n",
    "            params.update(extra_parameters)\n",
    "\n",
    "        nb = pm.execute_notebook(\n",
    "            nb,\n",
    "            output_notebook,\n",
    "            parameters=params,\n",
    "            kernel_name='pytorch',\n",
    "            timeout=100000,\n",
    "            log_output=True\n",
    "        )\n",
    "        \n",
    "        logging.info(f\"Completed execution {i}\")\n",
    "        return i\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in execution {i}: {str(e)}\")\n",
    "        logging.error(f\"Parameters used: {params}\")\n",
    "        import traceback\n",
    "        logging.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def paralelize_notebook_experiment(parameter_sets: List[Dict],  # List of parameter dictionaries to execute\n",
    "                                 notebook_to_execute: str,  # Path to the notebook file to execute\n",
    "                                 output_dir: str,  # Directory to save execution outputs\n",
    "                                 checkpoint_file: str,  # Path to checkpoint file tracking execution progress\n",
    "                                 max_workers: int = 3,  # Maximum number of parallel workers\n",
    "                                 extra_parameters: Optional[Dict] = None,  # Additional parameters to pass to each execution\n",
    "                                 ) -> None:\n",
    "    \"\"\"\n",
    "    Executes a Jupyter notebook multiple times in parallel with different parameter sets, tracking progress with checkpoints.\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(checkpoint_file):\n",
    "        with open(checkpoint_file, 'r') as f:\n",
    "            checkpoint = json.load(f)\n",
    "    else:\n",
    "        checkpoint = {'completed': [], 'started': []}\n",
    "        with open(checkpoint_file, 'w') as f:\n",
    "            json.dump(checkpoint, f)\n",
    "\n",
    "    # Ensure checkpoint is a dictionary with 'completed' and 'started' keys\n",
    "    if not isinstance(checkpoint, dict) or 'completed' not in checkpoint or 'started' not in checkpoint:\n",
    "        checkpoint = {'completed': [], 'started': []}\n",
    "        with open(checkpoint_file, 'w') as f:\n",
    "            json.dump(checkpoint, f)\n",
    "    \n",
    "    # Filter out already completed executions\n",
    "    remaining_executions = [i for i in range(1, len(parameter_sets) + 1) if i not in checkpoint['completed']]\n",
    "    \n",
    "    logging.info(f\"Starting execution. {len(remaining_executions)} executions remaining.\")\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for i in remaining_executions:\n",
    "            future = executor.submit(\n",
    "                execute_parameter_notebook,\n",
    "                notebook_to_execute=notebook_to_execute,\n",
    "                output_dir=output_dir,\n",
    "                i=i,\n",
    "                params=parameter_sets[i-1],\n",
    "                extra_parameters=extra_parameters,\n",
    "                checkpoint_file=checkpoint_file\n",
    "            )\n",
    "            futures.append(future)\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                logging.info(f\"Execution {result} completed successfully.\")\n",
    "                # Update checkpoint\n",
    "                with open(checkpoint_file, 'r+') as f:\n",
    "                    checkpoint = json.load(f)\n",
    "                    checkpoint['completed'].append(result)\n",
    "                    f.seek(0)\n",
    "                    json.dump(checkpoint, f)\n",
    "                    f.truncate()\n",
    "            else:\n",
    "                logging.warning(\"An execution failed.\")\n",
    "    \n",
    "    logging.info(\"All executions completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "data_path = r\"/orbit-generation/data/orbits_fix_1500/EM_N_fix_1500.h5\"\n",
    "experiments_folder = \"../experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_file_paths(experiment_id: Union[int, str],  # Unique ID of the experiment\n",
    "                       images_folder: str,  # Folder path where image files are stored\n",
    "                       experiment_folder: str,  # Folder path where experiment-related files are stored\n",
    "                       ) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Generate a dictionary of file paths for an experiment.\n",
    "    \"\"\"\n",
    "    paths = {\n",
    "        # Images - Orbits\n",
    "        'static_all_orbit_path': os.path.join(images_folder, f'exp{experiment_id}_generated_orbits.png'),\n",
    "        'dynamic_orbits_path': os.path.join(images_folder, f'exp{experiment_id}_generated_orbits.html'),\n",
    "        'refined_orbits_path': os.path.join(images_folder, f'exp{experiment_id}_refined_orbits.png'),\n",
    "        'dynamical_refined_orbits_path': os.path.join(images_folder, f'exp{experiment_id}_refined_orbits.html'),\n",
    "        'generated_orbits_that_converged_path': os.path.join(images_folder, f'exp{experiment_id}_generated_orbits_that_converged.png'),\n",
    "        'generated_orbits_that_did_not_converged_path': os.path.join(images_folder, f'exp{experiment_id}_generated_orbits_that_not_converged.png'),\n",
    "\n",
    "        # Images - Latent Spaces\n",
    "        'latent_space_path': os.path.join(images_folder, f'exp{experiment_id}_latent_space'),\n",
    "        'full_latent_space_path': os.path.join(images_folder, f'exp{experiment_id}_full_latent_space'),\n",
    "        'discarded_latent_space_path': os.path.join(images_folder, f'exp{experiment_id}_discarded_latent_space'),\n",
    "        'combined_latent_space_path': os.path.join(images_folder, f'exp{experiment_id}_combined_latent_space'),\n",
    "        'combined_latent_space_arrows_path': os.path.join(images_folder, f'exp{experiment_id}_combined_latent_space_arrows'),\n",
    "        'family_centroids_plot_path': os.path.join(images_folder, f'exp{experiment_id}_family_centroids'),\n",
    "        'full_family_centroids_plot_path': os.path.join(images_folder, f'exp{experiment_id}_full_family_centroids'),\n",
    "\n",
    "        # Images - Feature Spaces\n",
    "        'features_plot_path': os.path.join(images_folder, f'exp{experiment_id}_features'),\n",
    "        'family_feature_centroids_plot_path': os.path.join(images_folder, f'exp{experiment_id}_family_feature_centroids'),\n",
    "\n",
    "        # Other Images\n",
    "        'model_losses_path': os.path.join(images_folder, f'exp{experiment_id}_model_losses.png'),\n",
    "        'histogram_comparison_path': os.path.join(images_folder, f'exp{experiment_id}_histogram_comparison.png'),\n",
    "        'full_histogram_comparison_path': os.path.join(images_folder, f'exp{experiment_id}_full_histogram_comparison.png'),\n",
    "\n",
    "        # Model\n",
    "        'model_save_path': os.path.join(experiment_folder, f'exp{experiment_id}_model.pth'),\n",
    "\n",
    "        # Orbits Data\n",
    "        'generated_data_path': os.path.join(experiment_folder, f'exp{experiment_id}_generated_orbits.npy'),\n",
    "        'refined_data_path': os.path.join(experiment_folder, f'exp{experiment_id}_refined_orbits.npy'),\n",
    "\n",
    "        # Latent Representations\n",
    "        'latent_representations_path': os.path.join(experiment_folder, f'exp{experiment_id}_latent_representations.npy'),\n",
    "        'family_centroids_path': os.path.join(experiment_folder, f'exp{experiment_id}_family_centroids.npy'),\n",
    "\n",
    "        # Features Data\n",
    "        'generation_df_path': os.path.join(experiment_folder, f'exp{experiment_id}_generation_df.csv'),\n",
    "        'refined_orbits_df_path': os.path.join(experiment_folder, f'exp{experiment_id}_refined_orbits_df.csv')\n",
    "    }\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from orbit_generation.dataset import get_first_period_dataset, get_orbit_classes\n",
    "from orbit_generation.data import TSFeatureWiseScaler, discard_random_labels\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prepare_experiment_data(params: Dict[str, Any],  # Dictionary containing experiment parameters\n",
    "                          experiments_folder: str,  # Folder where experiments are stored\n",
    "                          data_path: str,  # Path to the dataset file\n",
    "                          want_to_discover: bool,  # Flag indicating whether to discover new families or use existing ones\n",
    "                          ) -> Tuple[torch.Tensor, pd.DataFrame, List[str], List[str], np.ndarray, Dict[str, str], int]:\n",
    "    \"\"\"\n",
    "    Prepare the experiment data based on the provided parameters and configurations.\n",
    "    \"\"\"\n",
    "    # Step 1: Setup experiment folders\n",
    "    experiment_folder = setup_new_experiment(params, experiments_folder)\n",
    "    images_folder = os.path.join(experiment_folder, 'images')\n",
    "    if not os.path.exists(images_folder):\n",
    "        os.makedirs(images_folder)\n",
    "    \n",
    "    experiment_id = int(os.path.basename(experiment_folder).split('_')[1])\n",
    "\n",
    "    # Step 2: Generate file paths\n",
    "    file_paths = generate_file_paths(experiment_id, images_folder, experiment_folder)\n",
    "\n",
    "    # Step 3: Load full dataset\n",
    "    full_data, full_orbit_df, full_labels, system_dict = get_first_period_dataset(\n",
    "        file_path=data_path,\n",
    "        segment_length=params['seq_len']\n",
    "    )\n",
    "\n",
    "    # Adjust data shape if feature_dim is 6\n",
    "    if params['feature_dim'] == 6:\n",
    "        full_data = full_data[:, 1:, :]  # Remove the first feature dimension\n",
    "\n",
    "    # Map orbit IDs to classes\n",
    "    full_orbits_id_classes = [full_orbit_df.at[index, 'id_class'] for index in full_labels]\n",
    "\n",
    "    # Step 4: Handle discovery or reuse of discarded families\n",
    "    if want_to_discover:\n",
    "        discarded_family_ids, data, orbits_id_classes = discard_random_labels(\n",
    "            full_data,\n",
    "            np.array(full_orbits_id_classes),\n",
    "            int(params['families_to_discard'])\n",
    "        )\n",
    "        discarded_families = get_orbit_classes(discarded_family_ids)[0]\n",
    "        orbit_df = full_orbit_df[~full_orbit_df['id_class'].isin(discarded_family_ids)]\n",
    "\n",
    "        # Log metrics for the experiment\n",
    "        add_experiment_metrics(\n",
    "            experiments_folder,\n",
    "            experiment_id=experiment_id,\n",
    "            metrics={\n",
    "                'discarded_family_ids': discarded_family_ids,\n",
    "                'discarded_families': discarded_families\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        # Retrieve previously discarded families for this experiment\n",
    "        experiment_data = get_experiment_data(\n",
    "            experiments_folder=experiments_folder,\n",
    "            experiment_id=experiment_id\n",
    "        )\n",
    "        discarded_family_ids = experiment_data.get('discarded_family_ids', {})\n",
    "\n",
    "        discarded_family_ids, data, orbits_id_classes = discard_random_labels(\n",
    "            full_data,\n",
    "            np.array(full_orbits_id_classes),\n",
    "            discarded_family_ids\n",
    "        )\n",
    "        discarded_families = get_orbit_classes(discarded_family_ids)[0]\n",
    "        orbit_df = full_orbit_df[~full_orbit_df['id_class'].isin(discarded_family_ids)]\n",
    "\n",
    "    # Step 5: Get family labels for remaining orbits\n",
    "    family_labels = get_orbit_classes(orbits_id_classes)[0]\n",
    "\n",
    "    # Step 6: Extract features and scale data\n",
    "    feature_names = ['jacobi', 'period', 'stability']\n",
    "    features = orbit_df[feature_names].to_numpy()\n",
    "\n",
    "    scaler = TSFeatureWiseScaler()\n",
    "    scaled_data = scaler.fit_transform(torch.tensor(data, dtype=torch.float32))\n",
    "\n",
    "    # Return processed data and metadata\n",
    "    return scaled_data, orbit_df, family_labels, discarded_families, features, file_paths, experiment_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pytorch_lightning import Trainer\n",
    "from orbit_generation.model_factory import get_model\n",
    "from orbit_generation.data import create_dataloaders\n",
    "from orbit_generation.architectures import VAELossHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prepare_and_train_model(params: Dict[str, Any],  # Dictionary containing all experiment parameters\n",
    "                           scaled_data: torch.Tensor,  # Scaled data tensor for training/validation\n",
    "                           experiments_folder: str,  # Folder where experiments are stored\n",
    "                           experiment_id: int,  # Unique ID of current experiment\n",
    "                           file_paths: Dict[str, str],  # Dictionary of paths for model/metrics files\n",
    "                           want_to_train: bool,  # Whether to train model or load pre-trained\n",
    "                           ) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Prepare the model and either train it or load a pre-trained version based on the provided parameters.\n",
    "    \"\"\"\n",
    "    # Step 1: Initialize the model\n",
    "    model = get_model(params)\n",
    "\n",
    "    # Step 2: Handle training\n",
    "    if want_to_train:\n",
    "        # Create data loaders\n",
    "        train_loader, val_loader = create_dataloaders(\n",
    "            scaled_data,\n",
    "            val_split=params.get('val_split', 0.1),\n",
    "            batch_size=params.get('batch_size', 32)\n",
    "        )\n",
    "\n",
    "        # Initialize loss history callback\n",
    "        loss_history = VAELossHistory()\n",
    "\n",
    "        # Initialize Trainer\n",
    "        trainer = Trainer(\n",
    "            max_epochs=params.get('epochs', 10),\n",
    "            log_every_n_steps=10,\n",
    "            devices=\"auto\",\n",
    "            accelerator=\"auto\",\n",
    "            enable_progress_bar=True,\n",
    "            enable_model_summary=True,\n",
    "            callbacks=[loss_history]\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "        # Log metrics\n",
    "        for metric_name, metric_value in trainer.callback_metrics.items():\n",
    "            print(f\"{metric_name}: {metric_value}\")\n",
    "\n",
    "        # Save metrics to experiment folder\n",
    "        add_experiment_metrics(\n",
    "            experiments_folder,\n",
    "            experiment_id=experiment_id,\n",
    "            metrics=trainer.callback_metrics\n",
    "        )\n",
    "\n",
    "        # Save model state to file\n",
    "        torch.save(model.state_dict(), file_paths['model_save_path'])\n",
    "\n",
    "        # Plot and save loss history\n",
    "        loss_history.plot_all_losses(save_path=file_paths['model_losses_path'])\n",
    "\n",
    "    else:\n",
    "        # Load pre-trained model state from file\n",
    "        model.load_state_dict(torch.load(file_paths['model_save_path'], weights_only=True))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
