{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Space\n",
    "\n",
    "> Scripts to visualize and explore the Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp latent_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from scipy.spatial import distance\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from typing import Optional, List, Any, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq, test_close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_latent_space_2d(latent_representations: np.ndarray,  # Precomputed latent representations (numpy array).\n",
    "                         labels: np.ndarray,                  # Labels for the data points, used for coloring in the plot.\n",
    "                         figsize: tuple = (12, 9),            # Size of the figure for the plot.\n",
    "                         save_path: Optional[str] = None,     # Optional path to save the plot image.\n",
    "                         many_classes: bool = False,          # Flag to use enhanced plotting for many classes.\n",
    "                         **kwargs: Any                        # Additional keyword arguments for the plotting.\n",
    "                        ) -> None:\n",
    "    \"\"\"\n",
    "    Plots and optionally saves the latent space representations assuming they are already in 2D.\n",
    "    \"\"\"\n",
    "    # Encode string labels to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    class_names = label_encoder.classes_\n",
    "\n",
    "    # Use a colormap for better color differentiation\n",
    "    cmap = cm.get_cmap('tab20', len(class_names))  # You can change 'tab20' to any other colormap\n",
    "    markers = ['o', 's', '^', 'v', 'D', '<', '>', 'p', '*', 'h', 'H', '8']  # Marker styles\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    if many_classes:\n",
    "        for class_idx, class_name in enumerate(class_names):\n",
    "            class_mask = (encoded_labels == class_idx)\n",
    "            color = cmap(class_idx)\n",
    "            marker = markers[class_idx % len(markers)]\n",
    "            ax.scatter(latent_representations[class_mask, 0], latent_representations[class_mask, 1],\n",
    "                       label=class_name, marker=marker, color=color, s=30, **kwargs)\n",
    "        ax.legend(title=\"Classes\")\n",
    "    else:\n",
    "        unique_labels = np.unique(encoded_labels)\n",
    "        for class_idx, class_name in zip(unique_labels, class_names):\n",
    "            class_mask = (encoded_labels == class_idx)\n",
    "            color = cmap(class_idx)\n",
    "            ax.scatter(latent_representations[class_mask, 0], latent_representations[class_mask, 1],\n",
    "                       label=class_name, color=color, s=30, **kwargs)\n",
    "        ax.legend(title=\"Classes\")\n",
    "\n",
    "    ax.set_title('2D Latent Space Visualization')\n",
    "    ax.set_xlabel('Dimension 1')\n",
    "    ax.set_ylabel('Dimension 2')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        print(f\"Saved plot to {save_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_combined_latent_space_2d(\n",
    "        real_data: np.ndarray,                    # Real data samples.\n",
    "        synthetic_data: np.ndarray,               # Synthetic data samples generated by a model.\n",
    "        encoder,                                  # Encoder function or model that predicts latent space representations.\n",
    "        synthetic_labels: Optional[Union[int, List[int]]] = 1,  # Labels for synthetic data. Can be a single label or a list of labels.\n",
    "        figsize: tuple = (12, 9),                 # Size of the figure.\n",
    "        save_path: Optional[str] = None,          # Optional path to save the plot image.\n",
    "        many_classes: bool = False,               # Flag to use enhanced plotting for many classes.\n",
    "        show_legend: bool = True,                 # Flag to show or hide the legend.\n",
    "        annotation_mode: str = 'legend'           # Mode for annotation: 'legend' for colored dots, 'numbers' for numeric annotations.\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "    Plots the combined latent space of real and synthetic data.\n",
    "    Assumes the latent space is already 2D.\n",
    "    \"\"\"\n",
    "    # Concatenate real and synthetic data\n",
    "    combined_data = np.concatenate([real_data, synthetic_data], axis=0)\n",
    "\n",
    "    # Create labels for real and synthetic data\n",
    "    real_labels = np.zeros(real_data.shape[0], dtype=int)\n",
    "    if isinstance(synthetic_labels, int):\n",
    "        synthetic_labels = np.full(synthetic_data.shape[0], synthetic_labels, dtype=int)\n",
    "    synthetic_labels = np.array(synthetic_labels)\n",
    "    combined_labels = np.concatenate([real_labels, synthetic_labels], axis=0)\n",
    "\n",
    "    # Generate latent representations for the combined dataset\n",
    "    latent_representations = encoder.predict(combined_data)\n",
    "\n",
    "    # Handle case where encoder returns a tuple or list\n",
    "    if isinstance(latent_representations, (list, tuple)):\n",
    "        latent_representations = latent_representations[0]  # Assuming the first element is the required representation\n",
    "\n",
    "    # Convert latent_representations to a NumPy array if it is a list\n",
    "    latent_representations = np.array(latent_representations)\n",
    "\n",
    "    # Ensure the latent space is 2D\n",
    "    assert latent_representations.shape[1] == 2, \"The latent space representations must be 2D.\"\n",
    "\n",
    "    # Create a color map with enough colors\n",
    "    cmap = plt.get_cmap('tab20', len(np.unique(combined_labels)))\n",
    "    norm = mcolors.BoundaryNorm(boundaries=np.arange(len(np.unique(combined_labels))+1)-0.5, ncolors=len(np.unique(combined_labels)))\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=figsize)\n",
    "    scatter = plt.scatter(latent_representations[:, 0], latent_representations[:, 1], c=combined_labels, cmap=cmap, norm=norm, alpha=0.7)\n",
    "    \n",
    "    if annotation_mode == 'legend' and show_legend:\n",
    "        # Create custom legend\n",
    "        unique_labels = np.unique(combined_labels)\n",
    "        custom_handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=cmap(norm(label)), markersize=10) for label in unique_labels]\n",
    "        custom_labels = [\"Real\"] + [f\"Synthetic {label}\" for label in np.unique(synthetic_labels)]\n",
    "        plt.legend(custom_handles, custom_labels, title=\"Classes\", loc='upper right')  # Place legend in the upper right corner\n",
    "    \n",
    "    elif annotation_mode == 'numbers':\n",
    "        # Annotate only synthetic points with their class labels\n",
    "        for i in range(real_data.shape[0], combined_data.shape[0]):\n",
    "            plt.annotate(combined_labels[i], (latent_representations[i, 0], latent_representations[i, 1]), fontsize=9, alpha=0.7)\n",
    "\n",
    "    # Save the plot if a save path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_latent_space_with_feature_distributions(latent_representations: np.ndarray,\n",
    "                                                 labels: np.ndarray,\n",
    "                                                 features: Optional[np.ndarray] = None,\n",
    "                                                 feature_names: Optional[list] = None,\n",
    "                                                 figsize: tuple = (12, 12),  # Adjusted to be a square\n",
    "                                                 save_path: Optional[str] = None,\n",
    "                                                 many_classes: bool = False,\n",
    "                                                 show_legend: bool = True,\n",
    "                                                 legend_fontsize: int = 8,\n",
    "                                                 **kwargs: Any) -> None:\n",
    "    \"\"\"\n",
    "    Plots the latent space with class colors and normalized vertical and horizontal feature distributions in separate subplots.\n",
    "    \"\"\"\n",
    "    # Encode string labels to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    class_names = label_encoder.classes_\n",
    "\n",
    "    # Use a colormap for better color differentiation\n",
    "    cmap = plt.get_cmap('tab20')  # You can change 'tab20' to any other colormap\n",
    "    markers = ['o', 's', '^', 'v', 'D', '<', '>', 'p', '*', 'h', 'H', '8']  # Marker styles\n",
    "\n",
    "    # Create subplots\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    # Adjust height_ratios and width_ratios to ensure square latent space plot\n",
    "    gs = fig.add_gridspec(2, 2, height_ratios=[5, 1], width_ratios=[5, 1])\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[0, 0])  # Latent space plot\n",
    "    ax2 = fig.add_subplot(gs[1, 0])  # Horizontal distribution plot\n",
    "    ax3 = fig.add_subplot(gs[0, 1], sharey=ax1)  # Vertical distribution plot\n",
    "\n",
    "    # Plot the latent representations with class colors\n",
    "    if many_classes:\n",
    "        for class_idx, class_name in enumerate(class_names):\n",
    "            class_mask = (encoded_labels == class_idx)\n",
    "            color = cmap(class_idx / len(class_names))\n",
    "            marker = markers[class_idx % len(markers)]\n",
    "            ax1.scatter(latent_representations[class_mask, 0], latent_representations[class_mask, 1],\n",
    "                        label=class_name, marker=marker, color=color, s=30, **kwargs)\n",
    "    else:\n",
    "        unique_labels = np.unique(encoded_labels)\n",
    "        for class_idx, class_name in zip(unique_labels, class_names):\n",
    "            class_mask = (encoded_labels == class_idx)\n",
    "            color = cmap(class_idx / len(class_names))\n",
    "            ax1.scatter(latent_representations[class_mask, 0], latent_representations[class_mask, 1],\n",
    "                        label=class_name, color=color, s=30, **kwargs)\n",
    "\n",
    "    ax1.set_title('2D Latent Space Visualization')\n",
    "    ax1.set_xlabel('Dimension 1')\n",
    "    ax1.set_ylabel('Dimension 2')\n",
    "    ax1.set_aspect('equal', 'box')  # Ensure the latent space plot is square\n",
    "    if show_legend:\n",
    "        ax1.legend(title=\"Classes\", fontsize=legend_fontsize)\n",
    "\n",
    "    if features is not None and feature_names is not None:\n",
    "        # Horizontal distribution\n",
    "        x_min, x_max = np.min(latent_representations[:, 0]), np.max(latent_representations[:, 0])\n",
    "        x_bins = np.linspace(x_min, x_max, 100)\n",
    "\n",
    "        for feature_index, feature_name in enumerate(feature_names):\n",
    "            feature_values = features[:, feature_index]\n",
    "            avg_feature_values = []\n",
    "\n",
    "            for i in range(len(x_bins) - 1):\n",
    "                mask = (latent_representations[:, 0] >= x_bins[i]) & (latent_representations[:, 0] < x_bins[i+1])\n",
    "                avg_feature_values.append(np.mean(feature_values[mask]) if np.sum(mask) > 0 else 0)\n",
    "\n",
    "            avg_feature_values = np.array(avg_feature_values)\n",
    "            # Normalize the feature values\n",
    "            avg_feature_values = (avg_feature_values - np.min(avg_feature_values)) / (np.max(avg_feature_values) - np.min(avg_feature_values) + 1e-8)\n",
    "            # Plot the normalized distributions\n",
    "            ax2.plot((x_bins[:-1] + x_bins[1:]) / 2, avg_feature_values, label=f'{feature_name} distribution')\n",
    "\n",
    "        ax2.set_title('Normalized Horizontal Feature Distributions')\n",
    "        ax2.set_xlabel('Dimension 1')\n",
    "        ax2.set_ylabel('Normalized Feature Value')\n",
    "        if show_legend:\n",
    "            ax2.legend(fontsize=legend_fontsize)\n",
    "\n",
    "        # Vertical distribution\n",
    "        y_min, y_max = np.min(latent_representations[:, 1]), np.max(latent_representations[:, 1])\n",
    "        y_bins = np.linspace(y_min, y_max, 100)\n",
    "\n",
    "        for feature_index, feature_name in enumerate(feature_names):\n",
    "            feature_values = features[:, feature_index]\n",
    "            avg_feature_values = []\n",
    "\n",
    "            for i in range(len(y_bins) - 1):\n",
    "                mask = (latent_representations[:, 1] >= y_bins[i]) & (latent_representations[:, 1] < y_bins[i+1])\n",
    "                avg_feature_values.append(np.mean(feature_values[mask]) if np.sum(mask) > 0 else 0)\n",
    "\n",
    "            avg_feature_values = np.array(avg_feature_values)\n",
    "            # Normalize the feature values\n",
    "            avg_feature_values = (avg_feature_values - np.min(avg_feature_values)) / (np.max(avg_feature_values) - np.min(avg_feature_values) + 1e-8)\n",
    "            # Plot the normalized distributions\n",
    "            ax3.plot(avg_feature_values, (y_bins[:-1] + y_bins[1:]) / 2, label=f'{feature_name} distribution')\n",
    "\n",
    "        ax3.set_title('Normalized Vertical Feature Distributions')\n",
    "        ax3.set_xlabel('Normalized Feature Value')\n",
    "        ax3.set_ylabel('Dimension 2')\n",
    "        if show_legend:\n",
    "            ax3.legend(fontsize=legend_fontsize)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        print(f\"Saved plot to {save_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def reduce_dimensions_plot_latent_space(latent_representations: np.ndarray,  # Precomputed latent representations (numpy array).\n",
    "                      labels: np.ndarray,                  # Labels for the data points, used for coloring in the plot.\n",
    "                      techniques: List[str] = ['PCA'],     # Techniques to use for reduction ('PCA', 't-SNE', 'UMAP', 'LDA').\n",
    "                      n_components: int = 2,               # Number of dimensions to reduce to (1, 2, or 3).\n",
    "                      figsize: tuple = (12, 9),            # Size of the figure for each subplot.\n",
    "                      save_path: Optional[str] = None,     # Optional path to save the plot image.\n",
    "                      many_classes: bool = False,          # Flag to use enhanced plotting for many classes.\n",
    "                      grid_view: bool = True,              # Flag to plot all techniques in a single grid view.\n",
    "                      class_names: Optional[List[str]] = None,  # Optional class names for the legend\n",
    "                      show_legend: bool = True,            # Flag to show or hide the legend\n",
    "                      **kwargs: Any                        # Additional keyword arguments for dimensionality reduction methods.\n",
    "                     ) -> None:\n",
    "    \"\"\"\n",
    "    Plots and optionally saves the latent space representations using specified dimensionality reduction techniques.\n",
    "    Each technique's plot is handled in a separate figure, supporting 1D, 2D, or 3D visualizations.\n",
    "    \"\"\"\n",
    "    # Encode string labels to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    \n",
    "    # Use provided class names if available\n",
    "    if class_names:\n",
    "        class_names = class_names\n",
    "    else:\n",
    "        class_names = label_encoder.classes_\n",
    "\n",
    "    models = {\n",
    "        'PCA': PCA(n_components=n_components),\n",
    "        't-SNE': TSNE(n_components=n_components, **kwargs),\n",
    "        'UMAP': umap.UMAP(n_components=n_components, **kwargs),\n",
    "        'LDA': LinearDiscriminantAnalysis(n_components=n_components)\n",
    "    }\n",
    "\n",
    "    markers = ['o', 's', '^', 'v', 'D', '<', '>', 'p', '*', 'h', 'H', '8']  # Marker styles\n",
    "\n",
    "    n_techniques = len(techniques)\n",
    "    if grid_view:\n",
    "        fig, axs = plt.subplots(1, n_techniques, figsize=(figsize[0] * n_techniques, figsize[1]))\n",
    "        if n_techniques == 1:\n",
    "            axs = [axs]\n",
    "    else:\n",
    "        axs = [None] * n_techniques\n",
    "\n",
    "    for idx, technique in enumerate(techniques):\n",
    "        model = models.get(technique)\n",
    "        if not model:\n",
    "            continue  # Skip if model not found in dictionary\n",
    "\n",
    "        if technique == 'LDA':\n",
    "            results = model.fit_transform(latent_representations, encoded_labels)\n",
    "        else:\n",
    "            results = model.fit_transform(latent_representations)\n",
    "\n",
    "        if n_components == 3:\n",
    "            if grid_view:\n",
    "                ax = fig.add_subplot(1, n_techniques, idx+1, projection='3d')\n",
    "            else:\n",
    "                fig = plt.figure(figsize=figsize)\n",
    "                ax = fig.add_subplot(111, projection='3d')\n",
    "        else:\n",
    "            ax = axs[idx] if grid_view else plt.subplots(figsize=figsize)[1]\n",
    "\n",
    "        if many_classes:\n",
    "            for class_idx, class_name in enumerate(class_names):\n",
    "                class_mask = (encoded_labels == class_idx)\n",
    "                marker = markers[class_idx % len(markers)]\n",
    "                if n_components == 1:\n",
    "                    ax.scatter(results[class_mask], np.zeros_like(results[class_mask]), label=class_name, marker=marker, s=30)\n",
    "                elif n_components == 2:\n",
    "                    ax.scatter(results[class_mask, 0], results[class_mask, 1], label=class_name, marker=marker, s=30)\n",
    "                elif n_components == 3:\n",
    "                    ax.scatter(results[class_mask, 0], results[class_mask, 1], results[class_mask, 2], label=class_name, marker=marker, s=30)\n",
    "            if show_legend:\n",
    "                ax.legend(title=\"Classes\")\n",
    "        else:\n",
    "            unique_labels = np.unique(encoded_labels)\n",
    "            for class_idx, class_name in zip(unique_labels, class_names):\n",
    "                class_mask = (encoded_labels == class_idx)\n",
    "                if n_components == 1:\n",
    "                    ax.scatter(results[class_mask], np.zeros_like(results[class_mask]), label=class_name, s=30)\n",
    "                elif n_components == 2:\n",
    "                    ax.scatter(results[class_mask, 0], results[class_mask, 1], label=class_name, s=30)\n",
    "                elif n_components == 3:\n",
    "                    ax.scatter(results[class_mask, 0], results[class_mask, 1], results[class_mask, 2], label=class_name, s=30)\n",
    "            if show_legend:\n",
    "                ax.legend(title=\"Classes\")\n",
    "\n",
    "        ax.set_title(f'Visualization with {technique}')\n",
    "        if n_components == 1:\n",
    "            ax.set_xlabel(f'{technique} Component 1')\n",
    "        elif n_components == 2:\n",
    "            ax.set_xlabel(f'{technique} Dimension 1')\n",
    "            ax.set_ylabel(f'{technique} Dimension 2')\n",
    "        elif n_components == 3:\n",
    "            ax.set_xlabel(f'{technique} Dimension 1')\n",
    "            ax.set_ylabel(f'{technique} Dimension 2')\n",
    "            ax.set_zlabel(f'{technique} Dimension 3')\n",
    "\n",
    "        if not grid_view:\n",
    "            if save_path:\n",
    "                individual_save_path = f\"{save_path}_{technique}.png\"\n",
    "                plt.savefig(individual_save_path, bbox_inches='tight')\n",
    "                print(f\"Saved plot to {individual_save_path}\")\n",
    "            plt.show()\n",
    "\n",
    "    if grid_view:\n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            grid_save_path = f\"{save_path}_grid.png\"\n",
    "            plt.savefig(grid_save_path, bbox_inches='tight')\n",
    "            print(f\"Saved grid plot to {grid_save_path}\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test reduce_dimensions_plot_latent_space\n",
    "\n",
    "# Reshape data to 2D (num_orbits, 6 * num_time_points)\n",
    "orbit_data_reshaped = orbit_data.reshape(200, -1)\n",
    "\n",
    "# Use PCA to reduce to a lower-dimensional space (e.g., 10 dimensions)\n",
    "pca = PCA(n_components=10)\n",
    "latent_representations = pca.fit_transform(orbit_data_reshaped)\n",
    "\n",
    "labels = np.random.randint(0, 5, size=200)  # 5 different classes\n",
    "\n",
    "reduce_dimensions_plot_latent_space(latent_representations, labels, techniques=['UMAP','LDA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test reduce_dimensions_plot_latent_space\n",
    "reduce_dimensions_plot_latent_space(latent_representations, labels, techniques=['PCA'], n_components=1, many_classes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test reduce_dimensions_plot_latent_space\n",
    "reduce_dimensions_plot_latent_space(latent_representations, labels, techniques=['t-SNE'], n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def reduce_dimensions_plot_combined_latent_space(\n",
    "        real_data: np.ndarray,                # Real data samples.\n",
    "        synthetic_data: np.ndarray,           # Synthetic data samples generated by a model.\n",
    "        encoder,                              # Encoder function or model that predicts latent space representations.\n",
    "        techniques: List[str] = ['PCA'],      # Techniques to use for reduction ('PCA', 't-SNE', 'UMAP', 'LDA').\n",
    "        n_components: int = 2,                # Number of dimensions to reduce to.\n",
    "        figsize: tuple = (12, 9),             # Size of the figure for each subplot.\n",
    "        save_path: Optional[str] = None,      # Optional path to save the plot image.\n",
    "        many_classes: bool = False,           # Flag to use enhanced plotting for many classes.\n",
    "        grid_view: bool = False,              # Flag to plot all techniques in a single grid view.\n",
    "        **kwargs: Any                         # Additional keyword arguments for dimensionality reduction methods.\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "    Plots the combined latent space of real and synthetic data using specified dimensionality reduction techniques.\n",
    "    \"\"\"\n",
    "    # Concatenate real and synthetic data\n",
    "    combined_data = np.concatenate([real_data, synthetic_data], axis=0)\n",
    "\n",
    "    # Create labels for real and synthetic data\n",
    "    real_labels = np.zeros(real_data.shape[0], dtype=int)\n",
    "    synthetic_labels = np.ones(synthetic_data.shape[0], dtype=int)\n",
    "    combined_labels = np.concatenate([real_labels, synthetic_labels], axis=0)\n",
    "\n",
    "    # Generate latent representations for the combined dataset\n",
    "    latent_representations = encoder.predict(combined_data)\n",
    "\n",
    "    # Handle case where encoder returns a tuple or list\n",
    "    if isinstance(latent_representations, (list, tuple)):\n",
    "        latent_representations = latent_representations[0]  # Assuming the first element is the required representation\n",
    "\n",
    "    # Convert latent_representations to a NumPy array if it is a list\n",
    "    latent_representations = np.array(latent_representations)\n",
    "\n",
    "    # Reshape the latent representations to 2D: (samples, features)\n",
    "    latent_representations = latent_representations.reshape(latent_representations.shape[0], -1)\n",
    "\n",
    "    # Plot the latent space using the previously defined function\n",
    "    reduce_dimensions_plot_latent_space(\n",
    "        latent_representations=latent_representations,\n",
    "        labels=combined_labels,\n",
    "        techniques=techniques,\n",
    "        n_components=n_components,\n",
    "        figsize=figsize,\n",
    "        save_path=save_path,\n",
    "        many_classes=many_classes,\n",
    "        grid_view=grid_view,\n",
    "        class_names=[\"Real\", \"Synthetic\"],\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def plot_combined_latent_space_with_labels(\n",
    "        real_data: np.ndarray,                # Real data samples.\n",
    "        synthetic_data: np.ndarray,           # Synthetic data samples generated by a model.\n",
    "        real_labels: np.ndarray,              # Labels for the real data samples.\n",
    "        encoder,                              # Encoder function or model that predicts latent space representations.\n",
    "        techniques: List[str] = ['PCA'],      # Techniques to use for reduction ('PCA', 't-SNE', 'UMAP', 'LDA').\n",
    "        n_components: int = 2,                # Number of dimensions to reduce to.\n",
    "        figsize: tuple = (12, 9),             # Size of the figure for each subplot.\n",
    "        real_colors: Optional[List[str]] = None,   # Optional list of colors for the real data labels. If None, use random colors.\n",
    "        synthetic_color: str = 'red',         # Color for the synthetic data points.\n",
    "        save_path: Optional[str] = None,      # Optional path to save the plot image.\n",
    "        **kwargs: Any                         # Additional keyword arguments for dimensionality reduction methods.\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "    Plots the combined latent space of real and synthetic data using specified dimensionality reduction techniques.\n",
    "    The real data points are colored according to their labels, and the synthetic data points are overlaid in a new color.\n",
    "    \"\"\"\n",
    "    # Concatenate real and synthetic data\n",
    "    combined_data = np.concatenate([real_data, synthetic_data], axis=0)\n",
    "\n",
    "    # Create labels for real and synthetic data\n",
    "    synthetic_labels = np.full(synthetic_data.shape[0], -1, dtype=int)  # Use -1 to distinguish synthetic data\n",
    "    combined_labels = np.concatenate([real_labels, synthetic_labels], axis=0)\n",
    "\n",
    "    # Generate latent representations for the combined dataset\n",
    "    latent_outputs = encoder.predict(combined_data)\n",
    "    latent_representations = latent_outputs[0]  # Assuming the mean of the latent space is the first output\n",
    "\n",
    "    models = {\n",
    "        'PCA': PCA(n_components=n_components),\n",
    "        't-SNE': TSNE(n_components=n_components, **kwargs),\n",
    "        'UMAP': umap.UMAP(n_components=n_components, **kwargs),\n",
    "        'LDA': LinearDiscriminantAnalysis(n_components=n_components)\n",
    "    }\n",
    "\n",
    "    for technique in techniques:\n",
    "        model = models.get(technique)\n",
    "        if not model:\n",
    "            continue  # Skip if model not found in dictionary\n",
    "\n",
    "        if technique == 'LDA':\n",
    "            results = model.fit_transform(latent_representations, combined_labels)\n",
    "        else:\n",
    "            results = model.fit_transform(latent_representations)\n",
    "\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        if n_components == 1:\n",
    "            ax = fig.add_subplot(111)\n",
    "            real_data_points = ax.scatter(results[:real_data.shape[0]], np.zeros(real_data.shape[0]), c=real_labels, cmap='viridis' if real_colors is None else real_colors, s=30, label='Real Data')\n",
    "            synthetic_data_points = ax.scatter(results[real_data.shape[0]:], np.zeros(synthetic_data.shape[0]), c=synthetic_color, s=30, label='Synthetic Data')\n",
    "            ax.set_xlabel(f'{technique} Component 1')\n",
    "        elif n_components == 2:\n",
    "            ax = fig.add_subplot(111)\n",
    "            real_data_points = ax.scatter(results[:real_data.shape[0], 0], results[:real_data.shape[0], 1], c=real_labels, cmap='viridis' if real_colors is None else real_colors, s=30, label='Real Data')\n",
    "            synthetic_data_points = ax.scatter(results[real_data.shape[0]:, 0], results[real_data.shape[0]:, 1], c=synthetic_color, s=30, label='Synthetic Data')\n",
    "            ax.set_xlabel(f'{technique} Dimension 1')\n",
    "            ax.set_ylabel(f'{technique} Dimension 2')\n",
    "        elif n_components == 3:\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            real_data_points = ax.scatter(results[:real_data.shape[0], 0], results[:real_data.shape[0], 1], results[:real_data.shape[0], 2], c=real_labels, cmap='viridis' if real_colors is None else real_colors, s=30, label='Real Data')\n",
    "            synthetic_data_points = ax.scatter(results[real_data.shape[0]:, 0], results[real_data.shape[0]:, 1], results[real_data.shape[0]:, 2], c=synthetic_color, s=30, label='Synthetic Data')\n",
    "            ax.set_xlabel(f'{technique} Dimension 1')\n",
    "            ax.set_ylabel(f'{technique} Dimension 2')\n",
    "            ax.set_zlabel(f'{technique} Dimension 3')\n",
    "\n",
    "        ax.set_title(f'Visualization with {technique}')\n",
    "        plt.legend()\n",
    "        if save_path:\n",
    "            individual_save_path = f\"{save_path}_{technique}.png\"\n",
    "            plt.savefig(individual_save_path)\n",
    "            print(f\"Saved plot to {individual_save_path}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def linear_interpolation(z1, z2, steps):\n",
    "    \"\"\"Perform linear interpolation between two points.\"\"\"\n",
    "    return np.linspace(z1, z2, steps)\n",
    "\n",
    "def slerp(z1, z2, steps):\n",
    "    \"\"\"Perform spherical linear interpolation between two points.\"\"\"\n",
    "    z1_norm = z1 / np.linalg.norm(z1)\n",
    "    z2_norm = z2 / np.linalg.norm(z2)\n",
    "    dot_product = np.clip(np.dot(z1_norm, z2_norm), -1.0, 1.0)\n",
    "    omega = np.arccos(dot_product)\n",
    "    if omega == 0:\n",
    "        return np.tile(z1, (steps, 1))\n",
    "    sin_omega = np.sin(omega)\n",
    "    return np.array([\n",
    "        (np.sin((1 - t) * omega) / sin_omega) * z1 +\n",
    "        (np.sin(t * omega) / sin_omega) * z2\n",
    "        for t in np.linspace(0, 1, steps)\n",
    "    ])\n",
    "\n",
    "def interpolate_sample(centroids, granularity=10, variance=0.0):\n",
    "    \"\"\"\n",
    "    Perform interpolating sampling between all pairs of centroids.\n",
    "\n",
    "    Parameters:\n",
    "    - centroids (np.ndarray): Array of shape (n_centroids, latent_dim).\n",
    "    - granularity (int): Number of interpolation steps between each pair.\n",
    "    - variance (float): Standard deviation for Gaussian sampling.\n",
    "\n",
    "    Returns:\n",
    "    - samples (np.ndarray): Array of sampled points.\n",
    "    \"\"\"\n",
    "    latent_dim = centroids.shape[1]\n",
    "    samples = []\n",
    "\n",
    "    for z1, z2 in combinations(centroids, 2):\n",
    "        if latent_dim <= 2:\n",
    "            interpolated = linear_interpolation(z1, z2, granularity)\n",
    "        else:\n",
    "            interpolated = slerp(z1, z2, granularity)\n",
    "        \n",
    "        if variance > 0:\n",
    "            noise = np.random.normal(0, variance, interpolated.shape)\n",
    "            interpolated += noise\n",
    "        \n",
    "        samples.append(interpolated)\n",
    "    \n",
    "    if samples:\n",
    "        return np.vstack(samples)\n",
    "    else:\n",
    "        return np.empty((0, latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example centroids for a 2-dimensional latent space\n",
    "centroids = np.array([\n",
    "    [1.0, 2.0],\n",
    "    [3.0, 4.0],\n",
    "    [5.0, 6.0]\n",
    "])\n",
    "\n",
    "granularity = 3\n",
    "variance = 0.0  # Set to 0 for deterministic interpolation\n",
    "\n",
    "sampled_points = interpolate_sample(centroids, granularity, variance)\n",
    "\n",
    "# Define the expected sampled points manually for granularity=3\n",
    "expected_data = np.array([\n",
    "    [1.0, 2.0],\n",
    "    [2.0, 3.0],\n",
    "    [3.0, 4.0],\n",
    "    [1.0, 2.0],\n",
    "    [3.0, 4.0],\n",
    "    [5.0, 6.0],\n",
    "    [3.0, 4.0],\n",
    "    [4.0, 5.0],\n",
    "    [5.0, 6.0]\n",
    "])\n",
    "\n",
    "# Check the sampled points against the expected data\n",
    "test_eq(sampled_points, expected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def compute_centroids(latents, labels, method='mean', return_labels=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute the centroid of each class in the latent space using various methods.\n",
    "    \n",
    "    Parameters:\n",
    "    - latents (np.ndarray): Array of shape (n_samples, latent_dim).\n",
    "    - labels (np.ndarray): Array of shape (n_samples,) with class labels.\n",
    "    - method (str): Method to compute centroids. Options: 'mean', 'median', 'geom_median', 'medoid', 'trimmed_mean', 'gmm'.\n",
    "    - return_labels (bool): If True, also return the unique labels corresponding to the centroids.\n",
    "    - kwargs: Additional arguments for specific methods.\n",
    "    \n",
    "    Returns:\n",
    "    - centroids (np.ndarray): Array of shape (n_classes, latent_dim) containing centroids.\n",
    "    - unique_labels (np.ndarray, optional): Array of shape (n_classes,) with unique class labels.\n",
    "    \"\"\"\n",
    "    unique_labels = np.unique(labels)\n",
    "    centroids = []\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        class_points = latents[labels == label]\n",
    "        \n",
    "        if method == 'mean':\n",
    "            centroid = class_points.mean(axis=0)\n",
    "        \n",
    "        elif method == 'median':\n",
    "            centroid = np.median(class_points, axis=0)\n",
    "        \n",
    "        elif method == 'geom_median':\n",
    "            centroid = geometric_median(class_points, tol=kwargs.get('tol', 1e-5))\n",
    "        \n",
    "        elif method == 'medoid':\n",
    "            centroid = compute_medoid(class_points)\n",
    "        \n",
    "        elif method == 'trimmed_mean':\n",
    "            trim_ratio = kwargs.get('trim_ratio', 0.1)\n",
    "            centroid = trimmed_mean_centroid(class_points, trim_ratio=trim_ratio)\n",
    "        \n",
    "        elif method == 'gmm':\n",
    "            n_components = kwargs.get('n_components', 1)\n",
    "            if n_components != 1:\n",
    "                raise ValueError(\"GMM-based centroids require n_components=1 for simple centroid computation.\")\n",
    "            gmm = GaussianMixture(n_components=1)\n",
    "            gmm.fit(class_points)\n",
    "            centroid = gmm.means_[0]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported centroid computation method: {method}\")\n",
    "        \n",
    "        centroids.append(centroid)\n",
    "    \n",
    "    centroids = np.array(centroids)\n",
    "    \n",
    "    if return_labels:\n",
    "        return centroids, unique_labels\n",
    "    else:\n",
    "        return centroids\n",
    "\n",
    "# Auxiliary Functions\n",
    "def geometric_median(points, tol=1e-5):\n",
    "    y = np.mean(points, axis=0)\n",
    "    while True:\n",
    "        D = distance.cdist([y], points, 'euclidean')[0]\n",
    "        nonzeros = (D != 0)\n",
    "        \n",
    "        if not np.any(nonzeros):\n",
    "            return y\n",
    "        \n",
    "        D = D[nonzeros]\n",
    "        points_nonzero = points[nonzeros]\n",
    "        y1 = np.sum(points_nonzero / D[:, np.newaxis], axis=0) / np.sum(1 / D)\n",
    "        \n",
    "        if np.linalg.norm(y - y1) < tol:\n",
    "            return y1\n",
    "        y = y1\n",
    "\n",
    "def compute_medoid(points):\n",
    "    dist_matrix = distance.cdist(points, points, 'euclidean')\n",
    "    medoid_index = np.argmin(dist_matrix.sum(axis=1))\n",
    "    return points[medoid_index]\n",
    "\n",
    "def trimmed_mean_centroid(points, trim_ratio=0.1):\n",
    "    trimmed_points = []\n",
    "    for dim in range(points.shape[1]):\n",
    "        sorted_dim = np.sort(points[:, dim])\n",
    "        trim = int(trim_ratio * len(sorted_dim))\n",
    "        trimmed_dim = sorted_dim[trim: -trim]\n",
    "        trimmed_points.append(trimmed_dim)\n",
    "    return np.array([np.mean(dim) for dim in trimmed_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# Define example latent representations\n",
    "latents = np.array([\n",
    "    [1.0, 2.0],\n",
    "    [1.5, -1.0],\n",
    "    [2.0, -1.0],\n",
    "    [1.2, 2.2],\n",
    "    [1.4, 1.8],\n",
    "    [1.7, 7.0]\n",
    "])\n",
    "\n",
    "# Define corresponding labels\n",
    "labels = np.array([1,1,1,2,2,3])\n",
    "\n",
    "# Compute centroids without returning labels\n",
    "centroids = compute_centroids(latents, labels)\n",
    "\n",
    "# Define the expected centroids\n",
    "expected_centroids = np.array([\n",
    "    [1.5, 0.],        # Centroid for label 1\n",
    "    [1.3, 2.],        # Centroid for label 2\n",
    "    [1.7, 7.]         # Centroid for label 2\n",
    "])\n",
    "\n",
    "# Check the computed centroids against the expected data\n",
    "test_close(centroids, expected_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
