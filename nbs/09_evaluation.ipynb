{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "> Scripts to perform evaluation on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, homogeneity_score, completeness_score, v_measure_score, fowlkes_mallows_score, silhouette_score, jaccard_score, confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from scipy.spatial.distance import squareform\n",
    "from fastdtw import fastdtw\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.spatial import cKDTree\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliar Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_metric_heatmaps(results, distance_metrics, clustering_algorithms, evaluation_metrics):\n",
    "    \"\"\"\n",
    "    Plot heatmaps for each evaluation metric.\n",
    "    \"\"\"\n",
    "    n_metrics = len(evaluation_metrics)\n",
    "    n_cols = 3\n",
    "    n_rows = (n_metrics + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, metric in enumerate(evaluation_metrics):\n",
    "        data = np.zeros((len(distance_metrics), len(clustering_algorithms)))\n",
    "        for d, distance in enumerate(distance_metrics):\n",
    "            for c, clustering in enumerate(clustering_algorithms):\n",
    "                data[d, c] = results[f\"{distance}_{clustering}\"][metric]\n",
    "        \n",
    "        sns.heatmap(data, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", \n",
    "                    xticklabels=clustering_algorithms, yticklabels=distance_metrics, ax=axes[i])\n",
    "        axes[i].set_title(f\"{metric} Scores\")\n",
    "        axes[i].set_xlabel(\"Clustering Algorithms\")\n",
    "        axes[i].set_ylabel(\"Distance Metrics\")\n",
    "    \n",
    "    # Remove any unused subplots\n",
    "    for i in range(n_metrics, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### the following function is not being used anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_comparison(orbit_df, synthetic_orbit_df):\n",
    "    \"\"\"\n",
    "    Function to create a scatter plot comparing 'period' and 'calculated_jacobi'\n",
    "    between two DataFrames and plot the index of points in synthetic_orbit_df.\n",
    "    \n",
    "    Parameters:\n",
    "    - orbit_df: DataFrame containing 'period' and 'calculated_jacobi' columns\n",
    "    - synthetic_orbit_df: DataFrame containing 'period' and 'calculated_jacobi' columns\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot for orbit_df\n",
    "    plt.scatter(orbit_df['period'], orbit_df['calculated_jacobi'], color='blue', label='orbit_df', marker='o')\n",
    "\n",
    "    # Plot for synthetic_orbit_df\n",
    "    plt.scatter(synthetic_orbit_df['period'], synthetic_orbit_df['calculated_jacobi'], color='red', label='synthetic_orbit_df', marker='x')\n",
    "\n",
    "    # Annotate the points in synthetic_orbit_df with their indices\n",
    "    for i in synthetic_orbit_df.index:\n",
    "        plt.text(synthetic_orbit_df['period'].loc[i], \n",
    "                 synthetic_orbit_df['calculated_jacobi'].loc[i], \n",
    "                 str(int(i)), \n",
    "                 fontsize=9, color='black', ha='right')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Period')\n",
    "    plt.ylabel('Calculated Jacobi')\n",
    "    plt.title('Comparison of Features Between Two DataFrames')\n",
    "    plt.legend()  # Add legend to distinguish between the groups\n",
    "\n",
    "    # Display the plot\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def calculate_closest_feature_distances(\n",
    "    orbit_df: pd.DataFrame,\n",
    "    synthetic_orbit_df: pd.DataFrame,\n",
    "    features: list,\n",
    "    display_comparison: bool = True\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculate the distance from each point in synthetic_orbit_df to the closest point in orbit_df\n",
    "    based on specified features, and return both the distances and the indices of the closest orbits.\n",
    "    \n",
    "    Parameters:\n",
    "    - orbit_df (pd.DataFrame): DataFrame containing the training data.\n",
    "    - synthetic_orbit_df (pd.DataFrame): DataFrame containing the synthetic data.\n",
    "    - features (list): List of feature column names to use for calculating the distances.\n",
    "    - display_comparison (bool): Whether to display a comparison plot. Defaults to True.\n",
    "    \n",
    "    Returns:\n",
    "    - distances (np.ndarray): Array of the minimum distances from each synthetic point to the nearest orbit point.\n",
    "    - closest_indices (np.ndarray): Array of indices corresponding to the nearest orbit points in orbit_df.\n",
    "    \"\"\"\n",
    "    # Extract the relevant features from both DataFrames\n",
    "    orbit_points = orbit_df[features].values\n",
    "    synthetic_points = synthetic_orbit_df[features].values\n",
    "\n",
    "    # Create a KDTree for efficient nearest-neighbor search in orbit_df\n",
    "    tree = cKDTree(orbit_points)\n",
    "\n",
    "    # Query the KDTree with the synthetic points to find the distance and index of the nearest orbit point\n",
    "    distances, closest_indices = tree.query(synthetic_points, k=1)\n",
    "\n",
    "    if display_comparison:\n",
    "        plot_comparison(orbit_df, synthetic_orbit_df)\n",
    "\n",
    "    return distances, closest_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_non_matching_elements(main_array, check_array):\n",
    "    \"\"\"\n",
    "    Finds elements in check_array that are not present in main_array.\n",
    "\n",
    "    Parameters:\n",
    "    main_array (numpy.ndarray): The main array with larger set of elements.\n",
    "    check_array (numpy.ndarray): The array with elements to check against the main array.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Elements in check_array that are not in main_array.\n",
    "    \"\"\"\n",
    "    # Convert arrays to tuples to enable comparison\n",
    "    main_set = set(map(tuple, main_array))\n",
    "    check_set = set(map(tuple, check_array))\n",
    "\n",
    "    # Find elements in check_set that are not in main_set\n",
    "    non_matching_elements = check_set - main_set\n",
    "\n",
    "    # Convert the result back to a numpy array\n",
    "    non_matching_elements_array = np.array(list(non_matching_elements))\n",
    "\n",
    "    return non_matching_elements_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Clustering with Multiple Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def evaluate_clustering_multiple_labels(latent_representations: np.ndarray,  # The latent space data.\n",
    "                                        list_of_labels: list,                # List of true labels or a single true labels array.\n",
    "                                        clustering_method: str = 'kmeans',   # The clustering algorithm to use ('kmeans', 'gmm', 'dbscan').\n",
    "                                        label_names: list = None,            # Optional names for the label sets.\n",
    "                                        **kwargs                             # Additional arguments for the clustering algorithm.\n",
    "                                       ) -> dict:                            # Returns a dictionary with clustering metrics.\n",
    "    \"\"\"\n",
    "    Evaluates the clustering quality of the latent representations for one or multiple sets of labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    def calculate_clustering_accuracy(true_labels, pred_labels):\n",
    "        contingency = contingency_matrix(true_labels, pred_labels)\n",
    "        row_ind, col_ind = linear_sum_assignment(-contingency)\n",
    "        return contingency[row_ind, col_ind].sum() / np.sum(contingency)\n",
    "\n",
    "    # Ensure list_of_labels is a list of arrays\n",
    "    if isinstance(list_of_labels, np.ndarray):\n",
    "        list_of_labels = [list_of_labels]\n",
    "    \n",
    "    # Use default names if label_names are not provided\n",
    "    if label_names is None:\n",
    "        label_names = [f'Set_{i+1}' for i in range(len(list_of_labels))]\n",
    "    \n",
    "    combined_metrics = {}\n",
    "    average_metrics = {\n",
    "        'ARI': 0,\n",
    "        'NMI': 0,\n",
    "        'Homogeneity': 0,\n",
    "        'Completeness': 0,\n",
    "        'V-Measure': 0,\n",
    "        'FMI': 0,\n",
    "        'Purity': 0,\n",
    "        'Silhouette Score': 0,\n",
    "        'Jaccard': 0,\n",
    "        'Accuracy': 0\n",
    "    }\n",
    "    num_label_sets = len(list_of_labels)\n",
    "    \n",
    "    label_encoders = [LabelEncoder() for _ in range(num_label_sets)]\n",
    "    encoded_labels_list = [label_encoders[i].fit_transform(list_of_labels[i]) for i in range(num_label_sets)]\n",
    "    \n",
    "    for i, true_labels in enumerate(encoded_labels_list):\n",
    "        # Determine the number of clusters\n",
    "        n_clusters = len(np.unique(true_labels))\n",
    "        \n",
    "        # Apply the selected clustering algorithm\n",
    "        if clustering_method == 'kmeans':\n",
    "            clusterer = KMeans(n_clusters=n_clusters, random_state=42, n_init=10, **kwargs)\n",
    "            pred_labels = clusterer.fit_predict(latent_representations)\n",
    "        elif clustering_method == 'gmm':\n",
    "            clusterer = GaussianMixture(n_components=n_clusters, random_state=42, **kwargs)\n",
    "            pred_labels = clusterer.fit_predict(latent_representations)\n",
    "        elif clustering_method == 'dbscan':\n",
    "            clusterer = DBSCAN(**kwargs)\n",
    "            pred_labels = clusterer.fit_predict(latent_representations)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported clustering method. Choose from 'kmeans', 'gmm', 'dbscan'.\")\n",
    "        \n",
    "        # Check if only one label is predicted\n",
    "        if len(np.unique(pred_labels)) == 1:\n",
    "            print(f\"Warning: Only one cluster predicted for {label_names[i]}. Some metrics will be NaN.\")\n",
    "            ari = nmi = homogeneity = completeness = v_measure = fmi = purity = silhouette = jaccard = accuracy = float('nan')\n",
    "        else:\n",
    "            # Calculate clustering metrics\n",
    "            ari = adjusted_rand_score(true_labels, pred_labels)\n",
    "            nmi = normalized_mutual_info_score(true_labels, pred_labels)\n",
    "            homogeneity = homogeneity_score(true_labels, pred_labels)\n",
    "            completeness = completeness_score(true_labels, pred_labels)\n",
    "            v_measure = v_measure_score(true_labels, pred_labels)\n",
    "            fmi = fowlkes_mallows_score(true_labels, pred_labels)\n",
    "            \n",
    "            # Purity\n",
    "            cont_matrix = contingency_matrix(true_labels, pred_labels)\n",
    "            purity = np.sum(np.amax(cont_matrix, axis=0)) / np.sum(cont_matrix)\n",
    "            \n",
    "            # Silhouette Score\n",
    "            silhouette = silhouette_score(latent_representations, pred_labels)\n",
    "            \n",
    "            # Jaccard Coefficient and Accuracy\n",
    "            jaccard = jaccard_score(true_labels, pred_labels, average='macro')\n",
    "            accuracy = calculate_clustering_accuracy(true_labels, pred_labels)\n",
    "        \n",
    "        # Store the results for this set of labels\n",
    "        combined_metrics.update({\n",
    "            f'{label_names[i]}_ari': ari,\n",
    "            f'{label_names[i]}_nmi': nmi,\n",
    "            f'{label_names[i]}_homogeneity': homogeneity,\n",
    "            f'{label_names[i]}_completeness': completeness,\n",
    "            f'{label_names[i]}_v-measure': v_measure,\n",
    "            f'{label_names[i]}_fmi': fmi,\n",
    "            f'{label_names[i]}_purity': purity,\n",
    "            f'{label_names[i]}_silhouette_score': silhouette,\n",
    "            f'{label_names[i]}_jaccard': jaccard,\n",
    "            f'{label_names[i]}_accuracy': accuracy\n",
    "        })\n",
    "        \n",
    "        # Accumulate the results for averaging\n",
    "        average_metrics['ARI'] += ari\n",
    "        average_metrics['NMI'] += nmi\n",
    "        average_metrics['Homogeneity'] += homogeneity\n",
    "        average_metrics['Completeness'] += completeness\n",
    "        average_metrics['V-Measure'] += v_measure\n",
    "        average_metrics['FMI'] += fmi\n",
    "        average_metrics['Purity'] += purity\n",
    "        average_metrics['Silhouette Score'] += silhouette\n",
    "        average_metrics['Jaccard'] += jaccard\n",
    "        average_metrics['Accuracy'] += accuracy\n",
    "    \n",
    "    # Compute the average metrics if there are multiple sets of labels\n",
    "    if num_label_sets > 1:\n",
    "        for key in average_metrics:\n",
    "            combined_metrics[f'average_{key}'] = average_metrics[key] / num_label_sets\n",
    "    \n",
    "    return combined_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def euclidean_distance(point1: np.ndarray, point2: np.ndarray) -> float:\n",
    "    return np.sqrt(np.sum((point1 - point2) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def manhattan_distance(point1: np.ndarray, point2: np.ndarray) -> float:\n",
    "    return np.sum(np.abs(point1 - point2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cosine_distance(point1: np.ndarray, point2: np.ndarray) -> float:\n",
    "    dot_product = np.sum(point1 * point2)\n",
    "    norm1 = np.linalg.norm(point1)\n",
    "    norm2 = np.linalg.norm(point2)\n",
    "    if norm1 == 0.0 or norm2 == 0.0:\n",
    "        return 1.0  # Maximum distance if one of the vectors is zero\n",
    "    cosine_similarity = dot_product / (norm1 * norm2)\n",
    "    return 1.0 - cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Time Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def dtw_distance(point1: np.ndarray, point2: np.ndarray) -> float:\n",
    "    distance, _ = fastdtw(point1.T, point2.T)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "DISTANCE_FUNCTIONS = {\n",
    "    'euclidean': euclidean_distance,\n",
    "    'manhattan': manhattan_distance,\n",
    "    'cosine': cosine_distance,\n",
    "    'dtw': dtw_distance\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calculate_distance(point1: np.ndarray, point2: np.ndarray, distance_metric: str = 'euclidean') -> float:\n",
    "    \"\"\"\n",
    "    Calculates the distance between two points based on the specified distance metric.\n",
    "    \n",
    "    :param point1: First data point array.\n",
    "    :param point2: Second data point array.\n",
    "    :param distance_metric: The distance metric to use ('euclidean', 'manhattan', 'cosine', 'dtw').\n",
    "    :return: Distance as a float.\n",
    "    \"\"\"\n",
    "    if distance_metric == 'euclidean':\n",
    "        return euclidean_distance(point1, point2)\n",
    "    elif distance_metric == 'manhattan':\n",
    "        return manhattan_distance(point1, point2)\n",
    "    elif distance_metric == 'cosine':\n",
    "        return cosine_distance(point1, point2)\n",
    "    elif distance_metric == 'dtw':\n",
    "        return dtw_distance(point1, point2)\n",
    "    else:\n",
    "        raise ValueError('Unknown distance metric: ' + distance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calculate_pairwise_distances(array1: np.ndarray, array2: np.ndarray, distance_metric: str = 'euclidean') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the distance between corresponding pairs of points from two arrays using the specified distance metric.\n",
    "    \n",
    "    :param array1: A 2D numpy array where each row represents a data point.\n",
    "    :param array2: A 2D numpy array where each row represents a data point.\n",
    "    :param distance_metric: The distance metric to use ('euclidean', 'manhattan', 'cosine', 'dtw').\n",
    "    :return: A 1D numpy array containing the distances between corresponding pairs.\n",
    "    \"\"\"\n",
    "    if array1.shape != array2.shape:\n",
    "        raise ValueError(\"Both input arrays must have the same shape.\")\n",
    "    \n",
    "    distances = np.array([\n",
    "        calculate_distance(point1, point2, distance_metric)\n",
    "        for point1, point2 in zip(array1, array2)\n",
    "    ])\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calculate_distances_batch(single_points: np.ndarray, points_array: np.ndarray, distance_metric: str = 'euclidean') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the distances between single data points and an array of data points based on the specified distance metric.\n",
    "    \n",
    "    :param single_points: Single data point array or a batch of data points.\n",
    "    :param points_array: Array of data points to compare against.\n",
    "    :param distance_metric: The distance metric to use ('euclidean', 'manhattan', 'cosine', 'dtw').\n",
    "    :return: Array of distances.\n",
    "    \"\"\"\n",
    "    if single_points.ndim == 1:\n",
    "        single_points = single_points.reshape(1, -1)\n",
    "    \n",
    "    distances = []\n",
    "    for single_point in single_points:\n",
    "        for point in points_array:\n",
    "            distance = calculate_distance(single_point, point, distance_metric)\n",
    "            distances.append(distance)\n",
    "    \n",
    "    return np.array(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_nearest_points(single_point: np.ndarray, points_array: np.ndarray, n: int, distance_metric: str = 'euclidean') -> tuple:\n",
    "    \n",
    "    distances = calculate_distances_batch(single_point, points_array, distance_metric=distance_metric)\n",
    "\n",
    "    # Get the indices of the n nearest points\n",
    "    nearest_indices = np.argsort(distances)[:n]\n",
    "\n",
    "    # Gather the nearest distances using the indices\n",
    "    nearest_distances = distances[nearest_indices]\n",
    "    \n",
    "    # If only one nearest point is requested, return a single int and float\n",
    "    if n == 1:\n",
    "        return nearest_indices[0], nearest_distances[0]\n",
    "\n",
    "    return nearest_indices, nearest_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_nearest_points_batch(single_points: np.ndarray, points_array: np.ndarray, n: int, distance_metric: str = 'euclidean') -> tuple:\n",
    "    \"\"\"\n",
    "    Finds the nearest indices and distances for a batch of single data points to an array of data points based on the specified distance metric.\n",
    "    \n",
    "    :param single_points: Array of single data points (2D array).\n",
    "    :param points_array: Array of data points to compare against (2D array).\n",
    "    :param n: Number of nearest points to retrieve for each single point.\n",
    "    :param distance_metric: The distance metric to use ('euclidean', 'manhattan', 'cosine', 'dtw').\n",
    "    :return: Tuple of nearest indices and nearest distances for each single point.\n",
    "    \"\"\"    \n",
    "    all_nearest_indices = []\n",
    "    all_nearest_distances = []\n",
    "    \n",
    "    for single_point in single_points:\n",
    "        nearest_indices, nearest_distances = find_nearest_points(single_point, points_array, n, distance_metric)\n",
    "        all_nearest_indices.append(nearest_indices)\n",
    "        all_nearest_distances.append(nearest_distances)\n",
    "    \n",
    "    return np.array(all_nearest_indices), np.array(all_nearest_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orbits Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def orbits_distances(\n",
    "    orbit_data1: np.ndarray,                # Shape: [n_samples1, n_features, n_time_steps] or [n_features, n_time_steps]\n",
    "    orbit_data2: np.ndarray,                # Shape: [n_samples2, n_features, n_time_steps] or [n_features, n_time_steps]\n",
    "    distance_metric: str                     # String representing the distance metric ('euclidean', 'manhattan', 'cosine', 'dtw')\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates distances between orbits in two datasets using a specified distance metric.\n",
    "\n",
    "    This function is robust to input shapes. If an input is a 2D array (representing a single orbit),\n",
    "    it is automatically converted to a 3D array with one sample. This allows for flexible comparisons\n",
    "    between single or multiple orbits.\n",
    "\n",
    "    :param orbit_data1: First set of orbits (shape: [n_samples1, n_features, n_time_steps] or [n_features, n_time_steps]).\n",
    "    :param orbit_data2: Second set of orbits or a single orbit.\n",
    "                        Shape: [n_samples2, n_features, n_time_steps] or [n_features, n_time_steps].\n",
    "    :param distance_metric: A string representing the distance metric to use ('euclidean', 'manhattan', 'cosine', 'dtw').\n",
    "\n",
    "    :return: NumPy array of distances.\n",
    "             - If one input is single and the other is multiple:\n",
    "                 - Shape: [n_samples1] or [n_samples2]\n",
    "             - If both inputs are multiple:\n",
    "                 - Shape: [n_samples1, n_samples2]\n",
    "    \"\"\"\n",
    "    \n",
    "    def ensure_3d(array: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Ensures the input array is 3D. If it's 2D, adds an extra dimension.\n",
    "        \n",
    "        :param array: Input NumPy array.\n",
    "        :return: 3D NumPy array.\n",
    "        \"\"\"\n",
    "        if array.ndim == 2:\n",
    "            return array[np.newaxis, ...]\n",
    "        elif array.ndim == 3:\n",
    "            return array\n",
    "        else:\n",
    "            raise ValueError(f\"Input array must be either 2D or 3D, got {array.ndim}D array instead.\")\n",
    "\n",
    "    # Mapping of distance metrics to their corresponding functions\n",
    "    distance_functions = DISTANCE_FUNCTIONS\n",
    "\n",
    "    # Ensure inputs are 3D\n",
    "    orbit_data1 = ensure_3d(orbit_data1)\n",
    "    orbit_data2 = ensure_3d(orbit_data2)\n",
    "\n",
    "    n_samples1 = orbit_data1.shape[0]\n",
    "    n_samples2 = orbit_data2.shape[0]\n",
    "\n",
    "    # Verify that feature and time step dimensions match\n",
    "    if orbit_data1.shape[1:] != orbit_data2.shape[1:]:\n",
    "        raise ValueError(\"Feature and time step dimensions must match between orbit_data1 and orbit_data2.\")\n",
    "\n",
    "    # Check if the specified distance metric is supported\n",
    "    if distance_metric not in distance_functions:\n",
    "        raise ValueError(f\"Unsupported distance metric: {distance_metric}. Choose from {list(distance_functions.keys())}.\")\n",
    "\n",
    "    # Select the appropriate distance function\n",
    "    selected_distance_func = distance_functions[distance_metric]\n",
    "\n",
    "    # Initialize the distance matrix\n",
    "    if n_samples1 == 1 and n_samples2 == 1:\n",
    "        # Both are single orbits\n",
    "        distances = np.array([selected_distance_func(orbit_data1[0], orbit_data2[0])])\n",
    "    elif n_samples1 == 1:\n",
    "        # orbit_data1 is single, orbit_data2 is multiple\n",
    "        distances = np.array([selected_distance_func(orbit_data1[0], orbit_data2[j]) for j in range(n_samples2)])\n",
    "    elif n_samples2 == 1:\n",
    "        # orbit_data2 is single, orbit_data1 is multiple\n",
    "        distances = np.array([selected_distance_func(orbit_data1[i], orbit_data2[0]) for i in range(n_samples1)])\n",
    "    else:\n",
    "        # Both are multiple\n",
    "        distances = np.zeros((n_samples1, n_samples2), dtype=float)\n",
    "        for i in range(n_samples1):\n",
    "            for j in range(n_samples2):\n",
    "                distances[i, j] = selected_distance_func(orbit_data1[i], orbit_data2[j])\n",
    "\n",
    "    # Convert to 1D array if one of the inputs was a single orbit\n",
    "    if n_samples1 == 1 or n_samples2 == 1:\n",
    "        distances = distances.flatten()\n",
    "\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Closest Orbits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_nearest_orbits(\n",
    "    single_orbit: np.ndarray,\n",
    "    orbit_data: np.ndarray,\n",
    "    n: int,\n",
    "    distance_metric: str = 'euclidean'\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Finds the n closest orbits in orbit_data to the single_orbit based on the specified distance metric.\n",
    "\n",
    "    :param single_orbit: The reference orbit (shape: [n_features, n_time_steps]).\n",
    "    :param orbit_data: The dataset of orbits (shape: [n_samples, n_features, n_time_steps]).\n",
    "    :param n: The number of closest orbits to return.\n",
    "    :param distance_metric: The distance metric to use ('euclidean', 'manhattan', 'cosine', 'dtw').\n",
    "                            Defaults to 'euclidean'.\n",
    "    :return: A tuple containing:\n",
    "             - Indices of the n closest orbits in orbit_data.\n",
    "             - Distances of the n closest orbits.\n",
    "    \"\"\"\n",
    "    # Calculate distance matrix\n",
    "    distance_matrix = orbits_distances(orbit_data, single_orbit, distance_metric)\n",
    "    \n",
    "    # Flatten if single_orbit was 2D (now treated as 3D with shape [1, ...])\n",
    "    if distance_matrix.ndim == 2 and distance_matrix.shape[0] == 1:\n",
    "        distances = distance_matrix.flatten()\n",
    "    else:\n",
    "        distances = distance_matrix\n",
    "    \n",
    "    # Get the indices of the n smallest distances\n",
    "    nearest_indices = np.argsort(distances)[:n]\n",
    "    \n",
    "    # Get the corresponding distances\n",
    "    nearest_distances = distances[nearest_indices]\n",
    "    \n",
    "    if n == 1:\n",
    "        return nearest_indices[0], nearest_distances[0]\n",
    "    else:\n",
    "        return nearest_indices, nearest_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_nearest_orbits_batch(\n",
    "    single_orbits: np.ndarray,       # Shape: [num_single_orbits, n_features, n_time_steps]\n",
    "    orbit_data: np.ndarray,          # Shape: [n_samples, n_features, n_time_steps]\n",
    "    n: int,                           # Number of nearest orbits to find\n",
    "    distance_metric: str = 'euclidean'  # Distance metric\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Iteratively finds the n closest orbits in orbit_data for each orbit in single_orbits.\n",
    "\n",
    "    :param single_orbits: The reference orbits (shape: [num_single_orbits, n_features, n_time_steps]).\n",
    "    :param orbit_data: The dataset of orbits to search within (shape: [n_samples, n_features, n_time_steps]).\n",
    "    :param n: The number of closest orbits to return for each single_orbit.\n",
    "    :param distance_metric: The distance metric to use ('euclidean', 'manhattan', 'cosine', 'dtw').\n",
    "                            Defaults to 'euclidean'.\n",
    "    :return: A tuple containing:\n",
    "             - A 2D array of shape [num_single_orbits, n] with indices of the n closest orbits.\n",
    "             - A 2D array of shape [num_single_orbits, n] with distances of the n closest orbits.\n",
    "    \"\"\"\n",
    "    # Validate input dimensions\n",
    "    if single_orbits.ndim != 3:\n",
    "        raise ValueError(f\"single_orbits must be a 3D array, got {single_orbits.ndim}D array instead.\")\n",
    "    if orbit_data.ndim != 3:\n",
    "        raise ValueError(f\"orbit_data must be a 3D array, got {orbit_data.ndim}D array instead.\")\n",
    "    if single_orbits.shape[1:] != orbit_data.shape[1:]:\n",
    "        raise ValueError(\"Each single_orbit must have the same shape as the orbits in orbit_data.\")\n",
    "    if n <= 0:\n",
    "        raise ValueError(\"Parameter n must be a positive integer.\")\n",
    "    if distance_metric not in ['euclidean', 'manhattan', 'cosine', 'dtw']:\n",
    "        raise ValueError(f\"Unsupported distance metric: {distance_metric}. Choose from 'euclidean', 'manhattan', 'cosine', 'dtw'.\")\n",
    "\n",
    "    num_single_orbits = single_orbits.shape[0]\n",
    "    \n",
    "    nearest_indices_all = np.empty((num_single_orbits, n), dtype=int)\n",
    "    nearest_distances_all = np.empty((num_single_orbits, n), dtype=float)\n",
    "\n",
    "    for i in range(num_single_orbits):\n",
    "        single_orbit = single_orbits[i]\n",
    "        nearest_indices, nearest_distances = find_nearest_orbits(\n",
    "            single_orbit=single_orbit,\n",
    "            orbit_data=orbit_data,\n",
    "            n=n,\n",
    "            distance_metric=distance_metric\n",
    "        )\n",
    "        nearest_indices_all[i] = nearest_indices\n",
    "        nearest_distances_all[i] = nearest_distances\n",
    "\n",
    "    return nearest_indices_all, nearest_distances_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Pairwise distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calculate_pairwise_orbit_distances(\n",
    "    orbit_data1: np.ndarray,       # Shape: [n_samples, n_features, n_time_steps]\n",
    "    orbit_data2: np.ndarray,       # Shape: [n_samples, n_features, n_time_steps]\n",
    "    distance_metric: str = 'euclidean'  # Distance metric\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the distance between corresponding orbits in two orbit datasets.\n",
    "    \n",
    "    :param orbit_data1: The first set of orbits (shape: [n_samples, n_features, n_time_steps]).\n",
    "    :param orbit_data2: The second set of orbits (shape: [n_samples, n_features, n_time_steps]).\n",
    "    :param distance_metric: The distance metric to use ('euclidean', 'manhattan', 'cosine', 'dtw').\n",
    "                            Defaults to 'euclidean'.\n",
    "    :return: An array of distances with shape [n_samples].\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inline validation\n",
    "    if orbit_data1.shape != orbit_data2.shape:\n",
    "        raise ValueError(\"Both orbit datasets must have the same shape.\")\n",
    "    if orbit_data1.ndim != 3:\n",
    "        raise ValueError(f\"orbit_data1 must be a 3D array, got {orbit_data1.ndim}D array instead.\")\n",
    "    \n",
    "    # Mapping of distance metrics to functions\n",
    "    distance_functions = DISTANCE_FUNCTIONS\n",
    "    \n",
    "    if distance_metric not in distance_functions:\n",
    "        raise ValueError(f\"Unsupported distance metric: {distance_metric}. Choose from {list(distance_functions.keys())}.\")\n",
    "    \n",
    "    n_samples = orbit_data1.shape[0]\n",
    "    distances = np.empty(n_samples, dtype=float)\n",
    "    \n",
    "    distance_func = distance_functions[distance_metric]\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        distances[i] = distance_func(orbit_data1[i], orbit_data2[i])\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Distance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def evaluate_distance_metrics_and_clustering(orbit_data: np.ndarray,\n",
    "                                    true_labels: np.ndarray,\n",
    "                                    distance_metrics: list = None,\n",
    "                                    clustering_algorithms: list = None,\n",
    "                                    evaluation_metrics: list = None,\n",
    "                                    n_clusters: int = None,\n",
    "                                    plot_results: bool = True):\n",
    "    \"\"\"\n",
    "    Evaluates specified distance metrics and clustering algorithms on the given orbit data.\n",
    "    \n",
    "    :param orbit_data: The orbit data as either:\n",
    "                      - multivariate time series (shape: [n_samples, n_features, n_time_steps])\n",
    "                      - point data (shape: [n_samples, n_features])\n",
    "    :param true_labels: Array of true labels for the orbit data.\n",
    "    :param distance_metrics: List of strings specifying distance metrics to use. If None, all available metrics are used.\n",
    "    :param clustering_algorithms: List of strings specifying clustering algorithms to use. If None, all available algorithms are used.\n",
    "    :param evaluation_metrics: List of strings specifying evaluation metrics to use. If None, all available metrics are used.\n",
    "    :param n_clusters: Number of clusters for algorithms that require it. If None, it will be inferred from labels.\n",
    "    :param plot_results: If True, plot heatmaps of the results.\n",
    "    :return: A dictionary containing results for all combinations of metrics and clustering algorithms.\n",
    "    \"\"\"\n",
    "\n",
    "    def calculate_clustering_accuracy(true_labels, pred_labels):\n",
    "        cm = confusion_matrix(true_labels, pred_labels)\n",
    "        row_ind, col_ind = linear_sum_assignment(-cm)\n",
    "        return cm[row_ind, col_ind].sum() / np.sum(cm)\n",
    "\n",
    "    # Define available distance metrics\n",
    "    available_distance_metrics = list(DISTANCE_FUNCTIONS.keys())\n",
    "    \n",
    "    # Define available clustering algorithms\n",
    "    available_clustering_algorithms = {\n",
    "        'kmeans': KMeans,\n",
    "        'gmm': GaussianMixture,\n",
    "        'dbscan': DBSCAN\n",
    "    }\n",
    "    \n",
    "    # Define available evaluation metrics\n",
    "    available_evaluation_metrics = {\n",
    "        'ARI': adjusted_rand_score,\n",
    "        'NMI': normalized_mutual_info_score,\n",
    "        'Homogeneity': homogeneity_score,\n",
    "        'Completeness': completeness_score,\n",
    "        'V-Measure': v_measure_score,\n",
    "        'Purity': lambda true, pred: np.sum(np.amax(confusion_matrix(true, pred), axis=0)) / np.sum(confusion_matrix(true, pred)),\n",
    "        'Accuracy': calculate_clustering_accuracy\n",
    "    }\n",
    "    \n",
    "    # If no metrics specified, use all available\n",
    "    if distance_metrics is None:\n",
    "        distance_metrics = available_distance_metrics\n",
    "    \n",
    "    # If no algorithms specified, use all available\n",
    "    if clustering_algorithms is None:\n",
    "        clustering_algorithms = list(available_clustering_algorithms.keys())\n",
    "    \n",
    "    # If no evaluation metrics specified, use all available\n",
    "    if evaluation_metrics is None:\n",
    "        evaluation_metrics = list(available_evaluation_metrics.keys())\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # If n_clusters is not provided, infer it from the labels\n",
    "    if n_clusters is None:\n",
    "        n_clusters = len(np.unique(true_labels))\n",
    "    \n",
    "    for distance_metric in distance_metrics:\n",
    "        if distance_metric not in available_distance_metrics:\n",
    "            print(f\"Warning: {distance_metric} is not an available distance metric. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Computing {distance_metric} distances...\")\n",
    "        \n",
    "        # Check input dimensionality and compute distances accordingly\n",
    "        if orbit_data.ndim == 3:\n",
    "            distance_matrix = orbits_distances(orbit_data, orbit_data, distance_metric)\n",
    "        elif orbit_data.ndim == 2:\n",
    "            n_samples = orbit_data.shape[0]\n",
    "            distance_matrix = np.zeros((n_samples, n_samples))\n",
    "            distance_func = DISTANCE_FUNCTIONS[distance_metric]\n",
    "            for i in range(n_samples):\n",
    "                for j in range(i+1, n_samples):\n",
    "                    distance = distance_func(orbit_data[i], orbit_data[j])\n",
    "                    distance_matrix[i,j] = distance\n",
    "                    distance_matrix[j,i] = distance\n",
    "        else:\n",
    "            raise ValueError(f\"Input data must be 2D or 3D, got {orbit_data.ndim}D array instead.\")\n",
    "\n",
    "        # Make the matrix symmetric by averaging with its transpose\n",
    "        distance_matrix = 0.5 * (distance_matrix + distance_matrix.T)\n",
    "        \n",
    "        if np.any(distance_matrix < 0):\n",
    "            distance_matrix = distance_matrix - np.min(distance_matrix)\n",
    "        np.fill_diagonal(distance_matrix, 0)  # Ensure diagonal is exactly zero\n",
    "        \n",
    "        for algo_name in clustering_algorithms:\n",
    "            if algo_name not in available_clustering_algorithms:\n",
    "                print(f\"Warning: {algo_name} is not an available clustering algorithm. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"Clustering with {algo_name}...\")\n",
    "            algo_class = available_clustering_algorithms[algo_name]\n",
    "            \n",
    "            if algo_name == 'dbscan':\n",
    "                # For DBSCAN, we need to estimate eps\n",
    "                distances = squareform(distance_matrix)\n",
    "                eps = np.percentile(distances, 10)  # Use the 10th percentile of distances as eps\n",
    "                clusterer = algo_class(eps=eps, min_samples=5, metric='precomputed')\n",
    "                labels = clusterer.fit_predict(distance_matrix)\n",
    "            elif algo_name == 'kmeans':\n",
    "                clusterer = algo_class(n_clusters=n_clusters, random_state=42)\n",
    "                labels = clusterer.fit_predict(distance_matrix)\n",
    "            elif algo_name == 'gmm':\n",
    "                clusterer = algo_class(n_components=n_clusters, random_state=42)\n",
    "                labels = clusterer.fit_predict(distance_matrix)\n",
    "            else:\n",
    "                clusterer = algo_class()  # Use default parameters for other algorithms\n",
    "                labels = clusterer.fit_predict(distance_matrix)\n",
    "            \n",
    "            # Evaluate clustering\n",
    "            eval_results = {}\n",
    "            for eval_metric in evaluation_metrics:\n",
    "                if eval_metric not in available_evaluation_metrics:\n",
    "                    print(f\"Warning: {eval_metric} is not an available evaluation metric. Skipping.\")\n",
    "                    continue\n",
    "                else:\n",
    "                    eval_results[eval_metric] = available_evaluation_metrics[eval_metric](true_labels, labels)\n",
    "            \n",
    "            # Store results\n",
    "            results[f\"{distance_metric}_{algo_name}\"] = eval_results\n",
    "    \n",
    "    if plot_results:\n",
    "        plot_metric_heatmaps(results, distance_metrics, clustering_algorithms, evaluation_metrics)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def machine_learning_evaluation(X, y, print_results=False, return_best_model=False, scale_data=True):\n",
    "    \"\"\"\n",
    "    Evaluates multiple machine learning algorithms on the provided dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Features, expected to be a 2D array. If higher dimensions, the function attempts to reshape.\n",
    "    - y: Target labels.\n",
    "    - print_results: If True, visualizes the evaluation results.\n",
    "    - return_best_model: If True, returns the best model based on accuracy.\n",
    "    - scale_data: If True, scales the features using StandardScaler.\n",
    "\n",
    "    Returns:\n",
    "    - results: Dictionary containing accuracy and classification report for each algorithm.\n",
    "    - best_model: The model with the highest accuracy if return_best_model is True.\n",
    "    \"\"\"\n",
    "    \n",
    "    def visualize_results(results):\n",
    "        # Accuracy comparison\n",
    "        accuracies = [result['accuracy'] for result in results.values()]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(results.keys(), accuracies, color='skyblue')\n",
    "        plt.title('Accuracy Comparison')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.ylim(0, 1)\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "        plt.show()\n",
    "\n",
    "        # Detailed metrics heatmap\n",
    "        metrics = ['precision', 'recall', 'f1-score']\n",
    "        data = []\n",
    "        for algo, result in results.items():\n",
    "            for metric in metrics:\n",
    "                value = np.mean([\n",
    "                    v[metric] for k, v in result['report'].items() \n",
    "                    if k not in ['accuracy', 'macro avg', 'weighted avg']\n",
    "                ])\n",
    "                data.append([algo, metric, value])\n",
    "\n",
    "        df = pd.DataFrame(data, columns=['Algorithm', 'Metric', 'Value'])\n",
    "        pivot_df = df.pivot(index='Algorithm', columns='Metric', values='Value')\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(pivot_df, annot=True, cmap='YlGnBu', fmt='.2f')\n",
    "        plt.title('Performance Metrics Heatmap')\n",
    "        plt.show()\n",
    "\n",
    "    # Validate and reshape X if necessary\n",
    "    if isinstance(X, np.ndarray):\n",
    "        if X.ndim > 2:\n",
    "            try:\n",
    "                # Flatten all dimensions except the first (samples)\n",
    "                X = X.reshape(X.shape[0], -1)\n",
    "                print(\"Input features reshaped to 2D for processing.\")\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error reshaping input features: {e}\")\n",
    "        elif X.ndim < 2:\n",
    "            raise ValueError(f\"Input features must be at least 2D, but got {X.ndim}D.\")\n",
    "    else:\n",
    "        raise TypeError(\"Input features X must be a NumPy array.\")\n",
    "\n",
    "    # List of algorithms to evaluate\n",
    "    algorithms = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=2000),\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'Support Vector Machine': SVC(),\n",
    "        'Random Forest': RandomForestClassifier()\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    # Train and evaluate each algorithm\n",
    "    for name, model in algorithms.items():\n",
    "        try:\n",
    "            # Create a pipeline that optionally scales the data and then applies the model\n",
    "            steps = []\n",
    "            if scale_data:\n",
    "                steps.append(('scaler', StandardScaler()))\n",
    "            steps.append(('model', model))\n",
    "            pipeline = make_pipeline(*steps)\n",
    "            \n",
    "            # Use cross-validation to get predictions\n",
    "            y_pred = cross_val_predict(pipeline, X, y, cv=5)\n",
    "            \n",
    "            accuracy = accuracy_score(y, y_pred)\n",
    "            report = classification_report(y, y_pred, output_dict=True, zero_division=0)\n",
    "            results[name] = {'accuracy': accuracy, 'report': report}\n",
    "            \n",
    "            # Check for the best model\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_model = model\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {name}: {e}\")\n",
    "            results[name] = {'accuracy': None, 'report': None}\n",
    "\n",
    "    if print_results:\n",
    "        visualize_results(results)\n",
    "\n",
    "    if return_best_model:\n",
    "        return results, best_model\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
