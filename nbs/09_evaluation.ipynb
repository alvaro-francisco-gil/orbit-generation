{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "> Scripts to perform evaluation on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, homogeneity_score, completeness_score, v_measure_score, fowlkes_mallows_score, silhouette_score, jaccard_score, accuracy_score\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def evaluate_clustering_multiple_labels(latent_representations: np.ndarray,  # The latent space data.\n",
    "                                        list_of_labels: list,                # List of true labels or a single true labels array.\n",
    "                                        clustering_method: str = 'kmeans',   # The clustering algorithm to use ('kmeans', 'gmm', 'dbscan').\n",
    "                                        label_names: list = None,            # Optional names for the label sets.\n",
    "                                        **kwargs                             # Additional arguments for the clustering algorithm.\n",
    "                                       ) -> dict:                            # Returns a dictionary with clustering metrics.\n",
    "    \"\"\"\n",
    "    Evaluates the clustering quality of the latent representations for one or multiple sets of labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    def calculate_clustering_accuracy(true_labels, pred_labels):\n",
    "        contingency = contingency_matrix(true_labels, pred_labels)\n",
    "        row_ind, col_ind = linear_sum_assignment(-contingency)\n",
    "        return contingency[row_ind, col_ind].sum() / np.sum(contingency)\n",
    "\n",
    "    # Ensure list_of_labels is a list of arrays\n",
    "    if isinstance(list_of_labels, np.ndarray):\n",
    "        list_of_labels = [list_of_labels]\n",
    "    \n",
    "    # Use default names if label_names are not provided\n",
    "    if label_names is None:\n",
    "        label_names = [f'Set_{i+1}' for i in range(len(list_of_labels))]\n",
    "    \n",
    "    combined_metrics = {}\n",
    "    average_metrics = {\n",
    "        'ARI': 0,\n",
    "        'NMI': 0,\n",
    "        'Homogeneity': 0,\n",
    "        'Completeness': 0,\n",
    "        'V-Measure': 0,\n",
    "        'FMI': 0,\n",
    "        'Purity': 0,\n",
    "        'Silhouette Score': 0,\n",
    "        'Jaccard': 0,\n",
    "        'Accuracy': 0\n",
    "    }\n",
    "    num_label_sets = len(list_of_labels)\n",
    "    \n",
    "    label_encoders = [LabelEncoder() for _ in range(num_label_sets)]\n",
    "    encoded_labels_list = [label_encoders[i].fit_transform(list_of_labels[i]) for i in range(num_label_sets)]\n",
    "    \n",
    "    for i, true_labels in enumerate(encoded_labels_list):\n",
    "        # Determine the number of clusters\n",
    "        n_clusters = len(np.unique(true_labels))\n",
    "        \n",
    "        # Apply the selected clustering algorithm\n",
    "        if clustering_method == 'kmeans':\n",
    "            clusterer = KMeans(n_clusters=n_clusters, random_state=42, n_init=10, **kwargs)\n",
    "            pred_labels = clusterer.fit_predict(latent_representations)\n",
    "        elif clustering_method == 'gmm':\n",
    "            clusterer = GaussianMixture(n_components=n_clusters, random_state=42, **kwargs)\n",
    "            pred_labels = clusterer.fit_predict(latent_representations)\n",
    "        elif clustering_method == 'dbscan':\n",
    "            clusterer = DBSCAN(**kwargs)\n",
    "            pred_labels = clusterer.fit_predict(latent_representations)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported clustering method. Choose from 'kmeans', 'gmm', 'dbscan'.\")\n",
    "        \n",
    "        # Calculate clustering metrics\n",
    "        ari = adjusted_rand_score(true_labels, pred_labels)\n",
    "        nmi = normalized_mutual_info_score(true_labels, pred_labels)\n",
    "        homogeneity = homogeneity_score(true_labels, pred_labels)\n",
    "        completeness = completeness_score(true_labels, pred_labels)\n",
    "        v_measure = v_measure_score(true_labels, pred_labels)\n",
    "        fmi = fowlkes_mallows_score(true_labels, pred_labels)\n",
    "        \n",
    "        # Purity\n",
    "        cont_matrix = contingency_matrix(true_labels, pred_labels)\n",
    "        purity = np.sum(np.amax(cont_matrix, axis=0)) / np.sum(cont_matrix)\n",
    "        \n",
    "        # Silhouette Score\n",
    "        silhouette = silhouette_score(latent_representations, pred_labels)\n",
    "        \n",
    "        # Jaccard Coefficient and Accuracy\n",
    "        jaccard = jaccard_score(true_labels, pred_labels, average='macro')\n",
    "        accuracy = calculate_clustering_accuracy(true_labels, pred_labels)\n",
    "        \n",
    "        # Store the results for this set of labels\n",
    "        combined_metrics.update({\n",
    "            f'{label_names[i]}_ari': ari,\n",
    "            f'{label_names[i]}_nmi': nmi,\n",
    "            f'{label_names[i]}_homogeneity': homogeneity,\n",
    "            f'{label_names[i]}_completeness': completeness,\n",
    "            f'{label_names[i]}_v-measure': v_measure,\n",
    "            f'{label_names[i]}_fmi': fmi,\n",
    "            f'{label_names[i]}_purity': purity,\n",
    "            f'{label_names[i]}_silhouette_score': silhouette,\n",
    "            f'{label_names[i]}_jaccard': jaccard,\n",
    "            f'{label_names[i]}_accuracy': accuracy\n",
    "        })\n",
    "        \n",
    "        # Accumulate the results for averaging\n",
    "        average_metrics['ARI'] += ari\n",
    "        average_metrics['NMI'] += nmi\n",
    "        average_metrics['Homogeneity'] += homogeneity\n",
    "        average_metrics['Completeness'] += completeness\n",
    "        average_metrics['V-Measure'] += v_measure\n",
    "        average_metrics['FMI'] += fmi\n",
    "        average_metrics['Purity'] += purity\n",
    "        average_metrics['Silhouette Score'] += silhouette\n",
    "        average_metrics['Jaccard'] += jaccard\n",
    "        average_metrics['Accuracy'] += accuracy\n",
    "    \n",
    "    # Compute the average metrics if there are multiple sets of labels\n",
    "    if num_label_sets > 1:\n",
    "        for key in average_metrics:\n",
    "            combined_metrics[f'average_{key}'] = average_metrics[key] / num_label_sets\n",
    "    \n",
    "    return combined_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
