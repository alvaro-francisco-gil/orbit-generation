{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE\n",
    "\n",
    "> Scripts to use Variational Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import MetricCollection, MeanMetric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from abc import ABC, abstractmethod\n",
    "from torch import Tensor\n",
    "from orbit_generation.architectures import Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AbstractVAE(ABC):\n",
    "    def __init__(self, seq_len: int, feat_dim: int, latent_dim: int):\n",
    "        self.seq_len = seq_len\n",
    "        self.feat_dim = feat_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    @abstractmethod\n",
    "    def encode(self, x: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        \"\"\"Encode input to latent space.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def decode(self, z: Tensor) -> Tensor:\n",
    "        \"\"\"Decode latent representation.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
    "        \"\"\"Forward pass through the VAE.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def sample(self, num_samples: int) -> Tensor:\n",
    "        \"\"\"Generate samples from the latent space.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BetaVAE(pl.LightningModule, AbstractVAE):\n",
    "    def __init__(self, encoder: nn.Module, decoder: nn.Module, beta: float = 1.0,\n",
    "                 loss_fn=None, optimizer_cls=torch.optim.Adam, lr: float = 0.001, **kwargs):\n",
    "        super().__init__()\n",
    "        AbstractVAE.__init__(self, encoder.seq_len, encoder.feat_dim, encoder.latent_dim)\n",
    "        self.beta = beta\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sampling = Sampling()\n",
    "        self.loss_fn = loss_fn if loss_fn else self.default_loss_fn\n",
    "        self.optimizer_cls = optimizer_cls\n",
    "        self.lr = lr\n",
    "        self.save_hyperparameters(ignore=['encoder', 'decoder'])\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_metrics = MetricCollection({\n",
    "            'total_loss': MeanMetric(),\n",
    "            'reconstruction_loss': MeanMetric(),\n",
    "            'kl_loss': MeanMetric()\n",
    "        })\n",
    "        self.val_metrics = MetricCollection({\n",
    "            'total_loss': MeanMetric(),\n",
    "            'reconstruction_loss': MeanMetric(),\n",
    "            'kl_loss': MeanMetric()\n",
    "        })\n",
    "        self.train_metrics.to(self.device)\n",
    "        self.val_metrics.to(self.device)\n",
    "\n",
    "    def encode(self, x: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, z: Tensor) -> Tensor:\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
    "        z_mean, z_log_var = self.encode(x)\n",
    "        z = self.sampling(z_mean, z_log_var)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, z_mean, z_log_var\n",
    "\n",
    "    def reconstruction_loss_by_axis(self, x: Tensor, x_hat: Tensor, axis: int) -> Tensor:\n",
    "        loss = torch.mean((x - x_hat) ** 2, dim=axis)\n",
    "        return loss.sum()\n",
    "\n",
    "    def default_loss_fn(self, x: Tensor, x_hat: Tensor, z_mean: Tensor, z_log_var: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        reconst_loss = sum(self.reconstruction_loss_by_axis(x, x_hat, axis) for axis in range(3))\n",
    "        kl_loss = -0.5 * torch.mean(torch.sum(1 + z_log_var - z_mean ** 2 - torch.exp(z_log_var), dim=1))\n",
    "        return reconst_loss, self.beta * kl_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch[0] if isinstance(batch, list) else batch\n",
    "        x_hat, z_mean, z_log_var = self(x)\n",
    "        reconst_loss, kl_loss = self.loss_fn(x, x_hat, z_mean, z_log_var)\n",
    "        total_loss = reconst_loss + kl_loss\n",
    "\n",
    "        # Update training metrics\n",
    "        self.train_metrics['total_loss'].update(total_loss)\n",
    "        self.train_metrics['reconstruction_loss'].update(reconst_loss)\n",
    "        self.train_metrics['kl_loss'].update(kl_loss)\n",
    "\n",
    "        # Log training metrics\n",
    "        self.log('train_total_loss', total_loss, on_step=False, on_epoch=True)\n",
    "        self.log('train_reconstruction_loss', reconst_loss, on_step=False, on_epoch=True)\n",
    "        self.log('train_kl_loss', kl_loss, on_step=False, on_epoch=True)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        if batch is None:\n",
    "            return None\n",
    "\n",
    "        x = batch[0] if isinstance(batch, list) else batch\n",
    "        x_hat, z_mean, z_log_var = self(x)\n",
    "        reconst_loss, kl_loss = self.loss_fn(x, x_hat, z_mean, z_log_var)\n",
    "        total_loss = reconst_loss + kl_loss\n",
    "\n",
    "        # Update validation metrics\n",
    "        self.val_metrics['total_loss'].update(total_loss)\n",
    "        self.val_metrics['reconstruction_loss'].update(reconst_loss)\n",
    "        self.val_metrics['kl_loss'].update(kl_loss)\n",
    "\n",
    "        # Log validation metrics\n",
    "        self.log('val_total_loss', total_loss, on_step=False, on_epoch=True)\n",
    "        self.log('val_reconstruction_loss', reconst_loss, on_step=False, on_epoch=True)\n",
    "        self.log('val_kl_loss', kl_loss, on_step=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer_cls(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def sample(self, num_samples: int) -> Tensor:\n",
    "        z = torch.randn(num_samples, self.latent_dim).to(self.device)\n",
    "        return self.decode(z)\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        self.train_metrics.reset()\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        if self.trainer.val_dataloaders:\n",
    "            self.val_metrics.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class cBetaVAE(pl.LightningModule, AbstractVAE):\n",
    "    def __init__(self, encoder: nn.Module, decoder: nn.Module, beta: float = 1.0,\n",
    "                 loss_fn=None, optimizer_cls=torch.optim.Adam, lr: float = 0.001, **kwargs):\n",
    "        super().__init__()\n",
    "        AbstractVAE.__init__(self, encoder.seq_len, encoder.feat_dim, encoder.latent_dim)\n",
    "        self.beta = beta\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sampling = Sampling()\n",
    "        self.loss_fn = loss_fn if loss_fn else self.default_loss_fn\n",
    "        self.optimizer_cls = optimizer_cls\n",
    "        self.lr = lr\n",
    "        self.save_hyperparameters(ignore=['encoder', 'decoder'])\n",
    "\n",
    "    def encode(self, x: Tensor, cond: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        Encodes the input tensor along with the condition into mean and log variance tensors.\n",
    "        \"\"\"\n",
    "        return self.encoder(x, cond)\n",
    "\n",
    "    def decode(self, z: Tensor, cond: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Decodes the latent tensor along with the condition back to the original data space.\n",
    "        \"\"\"\n",
    "        return self.decoder(z, cond)\n",
    "\n",
    "    def forward(self, x: Tensor, cond: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass for conditional BetaVAE.\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var = self.encode(x, cond)\n",
    "        z = self.sampling(z_mean, z_log_var)\n",
    "        x_recon = self.decode(z, cond)\n",
    "        return x_recon, z_mean, z_log_var\n",
    "\n",
    "    def reconstruction_loss_by_axis(self, x: Tensor, x_hat: Tensor, axis: int) -> Tensor:\n",
    "        \"\"\"\n",
    "        Computes reconstruction loss along a specific axis.\n",
    "        \"\"\"\n",
    "        loss = torch.mean((x - x_hat) ** 2, dim=axis)\n",
    "        return loss.sum()\n",
    "\n",
    "    def default_loss_fn(self, x: Tensor, x_hat: Tensor, z_mean: Tensor, z_log_var: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        Default loss function combining reconstruction loss and KL divergence.\n",
    "        \"\"\"\n",
    "        reconst_loss = sum(self.reconstruction_loss_by_axis(x, x_hat, axis) for axis in range(3))\n",
    "        kl_loss = -0.5 * torch.mean(torch.sum(1 + z_log_var - z_mean ** 2 - torch.exp(z_log_var), dim=1))\n",
    "        return reconst_loss, self.beta * kl_loss\n",
    "\n",
    "    def training_step(self, batch: tuple[Tensor], batch_idx: int) -> Tensor:\n",
    "        \"\"\"\n",
    "        Performs a single training step.\n",
    "        \"\"\"\n",
    "        x, cond = batch  # Extract input and condition from batch\n",
    "        x_hat, z_mean, z_log_var = self(x, cond)\n",
    "\n",
    "        # Compute losses\n",
    "        reconst_loss, kl_loss = self.loss_fn(x, x_hat, z_mean, z_log_var)\n",
    "        total_loss = reconst_loss + kl_loss\n",
    "\n",
    "        # Update training metrics\n",
    "        self.train_metrics['total_loss'].update(total_loss)\n",
    "        self.train_metrics['reconstruction_loss'].update(reconst_loss)\n",
    "        self.train_metrics['kl_loss'].update(kl_loss)\n",
    "\n",
    "        # Log training metrics\n",
    "        self.log('train_total_loss', total_loss)\n",
    "        self.log('train_reconstruction_loss', reconst_loss)\n",
    "        self.log('train_kl_loss', kl_loss)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self, batch: tuple[Tensor], batch_idx: int):\n",
    "        \"\"\"\n",
    "        Performs a single validation step.\n",
    "        \"\"\"\n",
    "        if batch is None:\n",
    "            return None\n",
    "\n",
    "        x, cond = batch  # Extract input and condition from batch\n",
    "        x_hat, z_mean, z_log_var = self(x, cond)\n",
    "\n",
    "        # Compute losses\n",
    "        reconst_loss, kl_loss = self.loss_fn(x, x_hat, z_mean, z_log_var)\n",
    "        total_loss = reconst_loss + kl_loss\n",
    "\n",
    "        # Update validation metrics\n",
    "        self.val_metrics['total_loss'].update(total_loss)\n",
    "        self.val_metrics['reconstruction_loss'].update(reconst_loss)\n",
    "        self.val_metrics['kl_loss'].update(kl_loss)\n",
    "\n",
    "        # Log validation metrics\n",
    "        self.log('val_total_loss', total_loss)\n",
    "        self.log('val_reconstruction_loss', reconst_loss)\n",
    "        self.log('val_kl_loss', kl_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configures the optimizer for training.\n",
    "        \"\"\"\n",
    "        return self.optimizer_cls(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def sample(self, num_samples: int, cond: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Generates new samples from the latent space using the provided condition.\n",
    "\n",
    "        Args:\n",
    "            num_samples (int): Number of samples to generate.\n",
    "            cond (Tensor): Conditional input for generating samples. \n",
    "                        Must have the appropriate shape to match the model's requirements.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Generated samples in the original data space.\n",
    "        \"\"\"\n",
    "        if cond is None:\n",
    "            raise ValueError(\"Condition tensor 'cond' must be provided for sampling.\")\n",
    "\n",
    "        # Ensure the condition tensor matches the number of samples\n",
    "        if cond.size(0) != num_samples:\n",
    "            raise ValueError(f\"Condition tensor must have batch size {num_samples}, but got {cond.size(0)}.\")\n",
    "\n",
    "        # Sample from a standard normal distribution for the latent space\n",
    "        z = torch.randn((num_samples, self.encoder.latent_dim), device=self.device)\n",
    "\n",
    "        # Decode the latent vectors into the data space using the condition\n",
    "        generated_samples = self.decode(z, cond)\n",
    "        return generated_samples\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        self.train_metrics.reset()\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        if self.trainer.val_dataloaders:\n",
    "            self.val_metrics.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
