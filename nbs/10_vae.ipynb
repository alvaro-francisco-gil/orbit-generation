{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE\n",
    "\n",
    "> Scripts to use Variational Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import MetricCollection, MeanMetric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from abc import ABC, abstractmethod\n",
    "from torch import Tensor\n",
    "from orbit_generation.architectures import Sampling, InceptionTimeVAEEncoder, InceptionTimeVAEDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AbstractVAE(ABC):\n",
    "    def __init__(self, seq_len: int, feat_dim: int, latent_dim: int):\n",
    "        self.seq_len = seq_len\n",
    "        self.feat_dim = feat_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    @abstractmethod\n",
    "    def encode(self, x: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        \"\"\"Encode input to latent space.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def decode(self, z: Tensor) -> Tensor:\n",
    "        \"\"\"Decode latent representation.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
    "        \"\"\"Forward pass through the VAE.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def sample(self, num_samples: int) -> Tensor:\n",
    "        \"\"\"Generate samples from the latent space.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BetaVAE(pl.LightningModule, AbstractVAE):\n",
    "    def __init__(self, encoder: nn.Module, decoder: nn.Module, beta: float = 1.0,\n",
    "                 loss_fn=None, optimizer_cls=torch.optim.Adam, lr: float = 0.001, **kwargs):\n",
    "        super().__init__()\n",
    "        AbstractVAE.__init__(self, encoder.seq_len, encoder.feat_dim, encoder.latent_dim)\n",
    "        self.beta = beta\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sampling = Sampling()\n",
    "        self.loss_fn = loss_fn if loss_fn else self.default_loss_fn\n",
    "        self.optimizer_cls = optimizer_cls\n",
    "        self.lr = lr\n",
    "        self.save_hyperparameters(ignore=['encoder', 'decoder'])\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_metrics = MetricCollection({\n",
    "            'total_loss': MeanMetric(),\n",
    "            'reconstruction_loss': MeanMetric(),\n",
    "            'kl_loss': MeanMetric()\n",
    "        })\n",
    "        self.val_metrics = MetricCollection({\n",
    "            'total_loss': MeanMetric(),\n",
    "            'reconstruction_loss': MeanMetric(),\n",
    "            'kl_loss': MeanMetric()\n",
    "        })\n",
    "        self.train_metrics.to(self.device)\n",
    "        self.val_metrics.to(self.device)\n",
    "\n",
    "    def encode(self, x: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, z: Tensor) -> Tensor:\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
    "        z_mean, z_log_var = self.encode(x)\n",
    "        z = self.sampling(z_mean, z_log_var)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, z_mean, z_log_var\n",
    "\n",
    "    def reconstruction_loss_by_axis(self, x: Tensor, x_hat: Tensor, axis: int) -> Tensor:\n",
    "        loss = torch.mean((x - x_hat) ** 2, dim=axis)\n",
    "        return loss.sum()\n",
    "\n",
    "    def default_loss_fn(self, x: Tensor, x_hat: Tensor, z_mean: Tensor, z_log_var: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        reconst_loss = sum(self.reconstruction_loss_by_axis(x, x_hat, axis) for axis in range(3))\n",
    "        kl_loss = -0.5 * torch.mean(torch.sum(1 + z_log_var - z_mean ** 2 - torch.exp(z_log_var), dim=1))\n",
    "        return reconst_loss, self.beta * kl_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch[0] if isinstance(batch, list) else batch\n",
    "        x_hat, z_mean, z_log_var = self(x)\n",
    "        reconst_loss, kl_loss = self.loss_fn(x, x_hat, z_mean, z_log_var)\n",
    "        total_loss = reconst_loss + kl_loss\n",
    "\n",
    "        # Update training metrics\n",
    "        self.train_metrics['total_loss'].update(total_loss)\n",
    "        self.train_metrics['reconstruction_loss'].update(reconst_loss)\n",
    "        self.train_metrics['kl_loss'].update(kl_loss)\n",
    "\n",
    "        # Log training metrics\n",
    "        self.log('train_total_loss', total_loss, on_step=False, on_epoch=True)\n",
    "        self.log('train_reconstruction_loss', reconst_loss, on_step=False, on_epoch=True)\n",
    "        self.log('train_kl_loss', kl_loss, on_step=False, on_epoch=True)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        if batch is None:\n",
    "            return None\n",
    "\n",
    "        x = batch[0] if isinstance(batch, list) else batch\n",
    "        x_hat, z_mean, z_log_var = self(x)\n",
    "        reconst_loss, kl_loss = self.loss_fn(x, x_hat, z_mean, z_log_var)\n",
    "        total_loss = reconst_loss + kl_loss\n",
    "\n",
    "        # Update validation metrics\n",
    "        self.val_metrics['total_loss'].update(total_loss)\n",
    "        self.val_metrics['reconstruction_loss'].update(reconst_loss)\n",
    "        self.val_metrics['kl_loss'].update(kl_loss)\n",
    "\n",
    "        # Log validation metrics\n",
    "        self.log('val_total_loss', total_loss, on_step=False, on_epoch=True)\n",
    "        self.log('val_reconstruction_loss', reconst_loss, on_step=False, on_epoch=True)\n",
    "        self.log('val_kl_loss', kl_loss, on_step=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer_cls(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def sample(self, num_samples: int) -> Tensor:\n",
    "        z = torch.randn(num_samples, self.latent_dim).to(self.device)\n",
    "        return self.decode(z)\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        self.train_metrics.reset()\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        if self.trainer.val_dataloaders:\n",
    "            self.val_metrics.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class InceptionTimeVAE(BetaVAE):\n",
    "    def __init__(self, encoder: nn.Module, decoder: nn.Module, beta: float = 1.0,\n",
    "                 loss_fn=None, optimizer_cls=torch.optim.Adam, lr: float = 0.001, **kwargs):\n",
    "        # Call BetaVAE's constructor\n",
    "        super().__init__(encoder=encoder, decoder=decoder, beta=beta,\n",
    "                         loss_fn=loss_fn, optimizer_cls=optimizer_cls, lr=lr, **kwargs)\n",
    "    \n",
    "    def encode(self, x: Tensor) -> tuple[Tensor, Tensor, list]:\n",
    "        # Override to return z_mean, z_log_var and indices_list\n",
    "        z_mean, z_log_var, indices_list = self.encoder.encode(x)\n",
    "        return z_mean, z_log_var, indices_list\n",
    "\n",
    "    def decode(self, z: Tensor, indices_list: list) -> Tensor:\n",
    "        # Override to accept indices_list and pass them to the decoder\n",
    "        return self.decoder.decode(z, indices_list)\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
    "        # Override forward pass to handle encoding and decoding with indices\n",
    "        z_mean, z_log_var, indices_list = self.encode(x)\n",
    "        z = self.sampling(z_mean, z_log_var)\n",
    "        x_recon = self.decode(z, indices_list)\n",
    "        return x_recon, z_mean, z_log_var\n",
    "    \n",
    "    def sample(self, num_samples: int, indices_list: list) -> Tensor:\n",
    "        z = torch.randn(num_samples, self.latent_dim).to(self.device)\n",
    "        return self.decode(z, indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
